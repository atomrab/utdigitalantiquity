
1.1. Why Paperless: Technology and Changes in Archaeological Practice 1996-20161
John Wallrodt, University of Cincinnati
Introduction
The documentation process for academic field projects is constantly changing.
Academics are not bound by the same strict documentation practices of CRM firms. The
requirements of the host countries in which we work allow a great deal of flexibility. Academic
archaeologists (as opposed to CRM archaeologists) are also in a near constant state of
experimentation. The various PIs have their own research interests that might propel them to
push the envelope in terms of remote sensing, excavation technique, and environmental survey,
to offer some examples. Even a single PI can run two consecutive projects of the same type,
temporal focus, and geographic region, and adjust their research design, sometimes drastically,
between projects.
As an archaeologist who has managed datasets for many short and long-term field survey
and excavation projects in the Mediterranean conducted by the Department of Classics at the
University of Cincinnati and other institutions over the last two decades, my task is to take into
account the PI’s research design and expectations for data recording, the project’s resources,
team members’ collective technological comfort levels, and overall project culture, to develop
the best documentation methodology possible. There is no single industrial approach to
academic archaeological documentation processes. Instead, each project has a unique
1 This essay should be seen as a companion to my 2015 keynote talk of a similar name at the Mobilizing
the Past workshop in Boston in Feb 2015, available at https://www.youtube.com/watch?v=UXWT5-
BXkeY.
2
combination of constraints and opportunities tied to research design and resources, such that the
documentation process is crafted to each individual project.
Over the past two decades I have helped to effect the progress from analog to digital field
recording for academic projects. . Almost all of these projects have been in places where there is
no electricity on the site, and often without the benefit of even a good cellular connection that
would allow data transfer over a network. With the exception of 1.5 days in Pompeii, all of the
solutions I have developed have been for offline, battery-only field projects. What follows is a
narrative concerning how we went from analog pieces of data to a more integrated digital data
model that many field projects—including several discussed in this volume—are pursuing. This
is not a review of the introduction of new technology into field archaeology, but a review of how
field archaeologists have used technology. Notably, introduction is not the same as adoption.
While my overall approach to archaeological documentation is comprehensive (that is, each step
has a purpose that leads towards better analysis, publication, and archiving), the focus of this
review is the use of digital recording by the people actually standing in the dirt
I focus particularly on the examples of Troy (1988-2002), the Pompeii Archaeological
Research Project: Porta Stabia (PARP, 2008- ), and the Keos Archaeological Regional Survey
(KARS, 2012- ). The examination of the use of technology in archaeological fieldwork from
multiple perspectives (specialists, excavators, and data managers) reveals four stages of
adoption: 1) the commoditization of hardware, 2) the early adoption of this hardware by
specialists, especially as personal equipment, 3) the increased mass of field data that required
purely digital workflows, then, finally, 4) learning from that experience and applying it to direct
digital entry inside the trench during excavation and out in the landscape during survey.
3
Pieces of Data
Archaeologists adopt technology piecemeal. Although early photography was a difficult
and costly process, it was adopted almost immediately, long before it became convenient (Harp
1975). The benefits were incalculable, but the resulting photographs were kept in sleeves,
albums, or shoeboxes separate from other records. Similarly, although various forms of
Electronic Distance Measurements (EDMs) were used early on, the resulting spatial data
gathered by surveyors and architects, and the plans that they produced, were separate from the
scaled drawings produced in the field. Forms were introduced in the 1970s as a way to
standardize the data traditionally recorded in narrative form in notebooks and they quickly
increased in number (Pavel 2010:35). As such, this proliferation of forms—long before the
ubiquity of desktop computers—predated their maximum potential. Examining the records of a
particular context on paper required an entire table to display the various notebooks, forms, finds
analysis pages, plans, contact sheets, photographs, and specialist reports.
In the past decade, the most exciting advances in field recording have mostly to do with
these various pieces of technology coming together to talk to each other. This shift has been
facilitated primarily because all of the information is now in the same state: digital. There are a
great number of things that you can do with data once it can talk to other data. Photographs, for
instance, can be recorded into a database in such a way that every subject in the photograph can
be linked to its associated data, even different types. A single image can include objects linked to
a finds table, people linked to a people table, and geography tied to stratigraphic units. Moreover,
everything we know about a photograph can be exported from that database and installed into the
metadata area inside the photograph itself, making the image file a stand-alone document with
4
everything we know about it embedded in the image, and independently searchable (Wallrodt
2011).
Early Paperless Solution at Troy (1996)
An example of the adoption of digital-born technology can be seen in the Troy
excavations, conducted from 1988 to 2002, a critical period for born-digital data as it saw the
introduction of portable networks and digital photography. Computing at Troy focused on the
metadata from the excavation. Excavators used paper forms in the field, and rather than entering
the contents of those forms into a database, they were scanned and distributed as PDF
documents.2 The Troy database recorded only data about the finds, their associated metadata
(drawings and photography), and field photography. Those finds, however, required a lot of
tracking from place to place and that required many paper forms.
The workflow for an artifact was as follows: (a) the item was given a field serial number
by the excavator; (b) it went to the BA3 registrar for entry into a master database table named
Master Behälter; (c) it was given to the PBA registrar; (d) sent to conservation; (e) given a
second inventory number and full description by the registrar; (f) sent to photography; (g) sent to
the government representative; (h) then sent either to storage in the on-site depot or in the
Çanakkale Museum.
In order to track the artifacts through these eight steps the team used ten separate forms
(picking up at c above):
2 For an overview of the field recording methodology for the Troy project see Pavel (2010:114–122) and
Pernicka et al. 2014. Pavel also has examples of the field forms used for both BA and PBA teams.
3 The Troy project was chronologically divided into two teams. While these are often referred to as the
German team (Tübingen University) and the American team (University of Cincinnati), given the
international makeup of both teams, the preferred terminology is the BA (Bronze Age) team and the PBA
(Post Bronze Age) team.
5
1 (c) UC Fundheft Form:4 To record the existence and the context of an item.
2 (c, h) Small Finds Tracking Form: This is a second list for the same finds. But this one
is meant to track the item through the conservation, registration, photography, government
review, and storage phases.
3 (d) Conservation Logs: A basic logbook for items in and out of conservation.
4 (e) Inventory Form: standard sort of inventory information for most small finds in two
pages
5 (e) Inventoried Lamps Form (4 pages).
6 (e) The Green Book: Inventory numbers had been pre-written in a hard bound green
ledger book.
7 (f) Photoliste for recording black and white negative photos and color slides.
8 (g) Final Tracking List.
9 Container Tracking Form: for recording post-inventory movement of items.
10 Inventory Addendum Form: for edits to the record.
Most of these forms were handwritten, un-sortable lists of numbers. Each of those lists
had to be consulted in order to locate an artifact (doi:10.7945/C2F30F).
In 1996, when I joined the Troy project eight years after it began, I developed the first
paperless workflow for the project, focusing on the small finds. In this new system, when
artifacts came to the registrar, the first step was to create a new record in the database. The
object’s movement through the registration process was then tracked by a series of date stamps
in the database, with a paper inventory form printed for inclusion in the files. Changes to the
4 Some form titles were in German, some in English.
6
record were entered into the database, but not transferred to the paper forms. By my second
season at the site, the entire workflow for the small finds registration was paperless, with the
exception of the conservation logs, bringing the forms down from ten to one.
At the end of the 1996 season, I wrote a lengthy report on my digital work for the project.
At the end of the document I wrote a section with the header “Science Fiction:”
As computers become more useful for archaeologists, there will be more
ways to use them. With the existing technology, the notebooks in the field
can be replaced with hand-held Newton devices with database software.
Upon entering the compound, this data can be directly imported into
FileMaker Pro and the Tagebücher (including the hand-made drawings and
scanned negatives) can be produced 100% electronically. Within a small
period of time, and a digitized plan of the site, these finds can be mapped
immediately and plans could be automatically updated throughout the
season.
Just something to think about.
Better Workflows Derived from New Hardware (1996-2000)
The paperless workflow described above was not possible in 1988 when the project
started (Dibble and McPherron 1988). The key was the development of an inexpensive portable
network, which only became available in the mid-1990s. Although Apple had developed a
proprietary network protocol named AppleTalk by 1985, it did not have regular TCP/IP
networking support until System 7 Pro (v.7.1.1) in 1993. Similarly, Windows 3.1 did not have
TCP/IP networking until 1994 (Gilbert 1995).5 Once better networking hardware became
affordable, the software had to follow. While FileMaker Pro v2 had networking in 1994, it was
not until 1995 with version 3 that it got both TCP/IP network support and a relational database
model. Since the new finds workflows relied upon multiple people accessing the database at the
same time, networking was essential to the paperless process.
5 This was initially available only for Windows for Workgroups (Young 2009).
7
Beyond inexpensive networking, the first decade of the twenty-first century brought
hardware advances that proved irresistible to field archaeologists: more powerful laptops,
wireless networks, and digital cameras. Although laptops of the early 1990s were vastly
underpowered compared to their desktop counterparts, they were absolutely necessary. This was
especially true for American projects in locations abroad where power was unreliable, and the
data had to be brought home at the end of each season. By 2000, however, performance and price
had improved enough that many academic archaeologists used laptops as their sole computer.
At the same time that laptop adoption became the norm, wireless networks also came into
use. Because wired networks required a router that had a limited number of ports, access to the
database was limited to computers connected to those ports. Significantly, wireless networking
opened up access to databases to anybody on the project with a wireless capable laptop and the
database software.
Similarly, many field projects in the 1990s experimented with digital cameras, even
though their image quality was not yet good enough to replace film. The use of digital cameras
was particularly vital to those working abroad. Film either had to be locally developed or
transported back to home for development, either method increased the chance of data loss.
Digital photography was the only way to securely check the quality of the image before
resuming fieldwork. Improved digital cameras appeared around 2000, and by 2005 digital
photography had become the norm for field projects.
Specialist Uses of Tech (1960-2010)
8
There are three factors that led specialists to increasingly rely on technology for digital
documentation and to bring their own equipment with them to field projects: large datasets, early
adoption of statistical methods to deal with those datasets, and their itinerant nature.
True to the pattern of the adoption of experimental technology, archaeologists have used
computers since the punch card days of the 1960s (Lock 2003: 9). Early uses were highly
specialized and were used for discreet data sets rather than for overall project recording
(Matheson and Koheler 1989 is a good example). During the intervening decades, with the rise
of processualism, characterized by empirical approaches focused on spatial analysis and
environmental archaeology (e.g. Binford and Binford 1968, Clarke 1968), several specialists
such as zooarchaeologists, lithic analysts, and ceramics experts adopted data collection standards
tied to statistical methodologies developed for their own subjects. For example the Knocod
system for animal bone analysis developed by Hans-Peter Uerpmann was used at Troy during the
duration of the project (Uerpmann 1978). Similarly, the BA ceramics team used coded forms for
collection of statistically useful data from their ceramics (Pernicka et al. 2014 565-573).
Other systems were also being developed. Clive Orton developed his Pie-Slice analytical
software for use with ceramics (Orton and Tyers 1990), but others found it useful for other
materials, such as faunal remains (Moreno-Garcia et al. 1996). WinBASP started in the 1970s as
a statistical package, and was expanded to meet additional uses including the creation of Harris
Matrices (Anon 1977). Although in the 1990’s specialists increasingly looked to these digital
solutions to handle what could be very large data sets, digitally-recorded data remained highly
specialized and were collected in a piecemeal fashion, rather than integrated into larger
databases. Moreover, many specialists actively resisted the incorporation of their data into the
9
master data set, for fear that project directors and other archaeologists would misinterpret and
misuse the results. Instead, specialists typically submitted season-end reports with summary data.
Similarly, post-excavation specialists also dealt with a different dataset than excavators.
Because excavators typically focus on single site analysis, usually concerning the description of
the single unit (trench) in front of them, their data is completed at the site and stays at the site
when they leave. Specialists require detailed data from multiple sites and regions in order to
assess patterning in their data sets. Therefore they wanted all of their data with them all the time.
Materials specialists’ appetites for digital data grew even further during the first decade
of the 21st century. It wasn’t until 2009 that Intel coined the term BYOD (Bring Your Own
Device), but that is exactly the principle that was a catalyst for the acceptance of digital data to
the field (Lai 2010). For example, while directors initially resisted digital photography, and
therefore used digital cameras in tandem with standard film photography, sometimes for several
years, this bias was largely overcome by the project specialists who incorporated digital-born
data into their own personal datasets. Ceramicists did not have to wait for official project
photography anymore and could take study photos of all of their objects (to their satisfaction) in
a single afternoon. Digital cameras were in use at Troy as early as 2000 by ceramicists, and the
project started using them for publishable finds photography in the following year. By the middle
of the decade the hardware had been so commoditized that most of the specialists would arrive at
Troy with their own laptops and digital cameras. They would take study photos of their objects
with their cameras and create datasets directly on their computers. When they left the project for
the season they asked for information in digital format: PDFs of things that could be scanned,
and read-only copies of the database that they could reference offline. They didn’t want
photocopies of notebooks.
10
Field projects, in turn, benefitted from this increase in digital creation in concert with
their own focus on making the core archaeological data available in database form. As project
databases became more common, and the specialists saw a greater return on the integration of
their data setss, specialist data started to be incorporated into the master data, and by the end of
the decade, it became more common for specialists to surrender their data sets for incorporation
into the whole. Not only were the data sets talking to the master field data, they were talking to
each other: the data created by the finds specialists and environmental specialists could reference
each other directly.
Uses of Tech in the Trench
While post-excavation specialists had been providing digital data for years, this type of
born-digital data entry rarely made it into the trench. There was certainly some technology in the
trench. Point and shoot digital cameras had been adopted after specialists began using them
(most by 2005). Electronic Distance Measurement (EDM) machines have been used for decades
in the field, and often by the excavators themselves (as opposed to a separate team). But the base
recording methods had not evolved since the widespread use of forms instead of narrative journal
entries in the 1970’s. While digital technology became ubiquitous on field projects, excavators in
the trenches were still using paper and pen to record their initial observations of finds and
stratigraphy.
Paper to digital has been the normal workflow almost as long as there have been forms.
There are many problems with this approach, but the single fatal flaw that affects all paper to
digital workflows is the revision process. Data that had been written, then typed, cannot be
adequately tracked when revisions are made in either direction. This was evident even in fully
11
paper-based projects, and predates the ubiquitous use of databases for field data. The field forms
for Troy, for example were photocopied and kept in three places: Tübingen, Cincinnati, and
Troy. If somebody wanted to change an earlier notebook they had to fill out a piece of paper
called the Change to Tagebücher form. That form was photocopied and a copy kept in all three
places with the original notebook. Each project had their own workaround for this problem, but
none was satisfactory.
Paper to digital is also the least efficient use of the trench supervisor’s time. The trench
supervisor maintains the notebooks, supervises the excavation, directs people where to dig, keeps
track of the many numbers created during the project, tracks the number of buckets removed,
decides when to photograph, when to draw, and when to stop digging. The trench supervisor
makes the initial stratigraphic interpretation. They write the first story of the trench. This is an
often overwhelming amount of work to ask of one person, and it is most often done in the least
efficient manner possible: by writing everything down on paper during the day and typing it up
during the evening or weekends, thereby doubling their work.
The worst part of the paper to digital workflow is that the trench data took so long to be
digitized, often months after the season ended, that errors and emendations crept into the data set.
For example: initial descriptive observations can became interpretations, so “chunky, dark, loose
fill” can become “interior of drain” when the form is typed into the database. Forms might be
typed in but sketches were most often not digitized in any meaningful way in the field. There
was no mechanism for the field drawings to be incorporated into the data set, either. The data
were not speaking to each other.
Mobile Devices (2010-2015)
12
Mobile devices were the next big hardware leap that allowed tech to get inside the trench,
but mobile devices were problematic. Some field projects had experimented with them, notably
Palm devices and field based laptops. The Landscape Research Centre (UK) has been publishing
work concerning their digital experiments since 1984, but even in their Data Flow Diagram from
2010 (Powlesland and May: fig. 45) there were lots of devices used: total station, PDA, flatbed
scanner, digitizing tablet, and laptop. The Athenian Agora also used the Palm platform to talk
directly to their total stations. But as Palm changed their hardware and OS it became difficult for
them to find the hardware that was comparable with their systems.6 The Agora workflow
described in 2009 also required that the information in the Palm be transcribed to the notebook
by hand (Hartzler 2009: 132).
Troy
I mentioned the Newton above, but it was specifically the Newton OS that I wanted to
use at Troy. That would have come in the form of the eMate, a device originally marketed
towards elementary schools. In 1995, Claris (the parent company that owned FileMaker Pro)
announced a version of FileMaker for the Newton OS.7 That software already had record-level
syncing, and in some ways was more useful than the solution we used in 2010 at Pompeii. Since
it was designed for schools, the eMate had the ability to act as a teacher/student system. The
teacher would beam (via infrared) the assignment to the students and they would beam their
answers back. In our case we wanted to collect the field data from spreadsheets on the devices
6 Hartzler (2009: 129) shows screenshots from their Palm Pilot use in 2005, right around the time that
Palm stopped making those devices. Their difficulties finding hardware is personal communication.
7 You can see a copy of the original press release at http://www.ebyss.net/pages/FMCpr.html.
13
and import them into the master database. But the Newton OS and the eMate were both
discontinued in 1998.
The Palm OS had better developer support and more software, and while some projects
used it to great effect, it suffered from a fatal flaw: all data was deleted when the device ran short
of power. The only intervening device worth considering was the Microsoft Tablet PC, a fullsized
laptop with a touch screen that required a stylus. They were heavy, their batteries lasted
only a few hours, and they were incredibly expensive.
While all of these devices were being used on some field projects, their use did not
become the norm for any significant segment of archaeological fieldwork. These were devices
that projects purchased for use for the duration of the fieldwork, they were not devices that
scholars wanted to purchase for themselves and use in their own work.
Pompeii
The iPhone was released in 2007, and in 2008 third-party programs were able to run on
the device. In 2009 the PARP team experimented with databases running on the iPhone. In 2010,
with the introduction of the larger iPad, and soon after Android-based tablets, archaeologists
finally had a device that worked all day, had no moving parts to break, did not require a network
(although having one would be nice), and had a significant enough screen size to allow direct
digital entry for any field-related task. These were the devices that scholars brought into the field
themselves in true BYOD fashion. In the first nine months of sale, Apple sold 15 million iPads;
more, they claimed, than every Tablet PC ever sold (from 2000-2011).8
8 https://www.youtube.com/watch?v=TGxEQhdi1AQ at the 5:30 mark.
14
In 2010-2012 at PARPS we used iPads to enter and edit records in the database (first FM
Touch and then FileMaker Go), draw scaled plans and profiles (with iDraw then TouchDraw),
keep a free-form notebook (Pages), and keep Harris Matrices (OmniGraffle) up to date.9 As a
result, we had our first fully digital archive of the project.
At first the data were still in pieces. They were in proxy apps: digital equivalent of their
paper counterparts. There is value in the ease of use and accuracy of the proxy apps over paper,
but they were still in digital pieces. The database recorded that there was a plan, but didn’t
actually link to it. The Harris Matrices were portable, but did not communicate with the database.
In subsequent years we learned to make the field drawings talk to the larger CAD
workflow. By using CAD output as the background for all field drawings, and keeping the scale
of the drawings at 1:1 (the software TouchDraw allowed infinite zoom which meant that we
could literally draw at full scale, which removed an entire mental process from the activity: no
more mentally scaling all measurements), we were able to feed the field drawings directly back
to the CAD operator, sometimes on the same day, so that we could address any areas of the
drawings that were difficult to interpret (Tucker and Wallrodt 2013).
What was important is that there was finally a way to get direct observation from the
trench in a digital format. The traditional workflow of paper to digital no longer applied and we
opened up the field data to immediate review by the rest of the team. With immediate access to
the form data the data managers and other members of the project became immediate editors.
The spatial team caught errors or inconsistencies in drawings that were immediately fed back to
the field team and created a process for revisions. Similarly, the ceramics team received daily
matrix information that helped them to better understand the stratigraphy and therefore better
9 The workflows for each of these is documented on Paperless Archaeology,
http://paperlessarchaeology.com.
15
process the ceramics. More importantly, units could be tagged as ‘high priority’ thereby allowing
the post-excavation specialists to readjust their priorities.
There is no standard metric for the success of a new recording process for an
archaeological project. Clearly the most important is that it satisfies the research design and can
answer the questions that the PI puts to the data. As mentioned above, that is a different
requirement for different projects. PARP is a complex project with many voices contributing to
the story of the site. Key to getting that story is the timeliness of data retrieval. What volume of
dirt was brought out of these units? Which units were “sealed” contexts? How large is this
feature? Is this type of feature related to these kinds of charcoal, fauna, pottery? Where is
everything from this context stored? In previous years at PARP these questions were time
consuming to answer. In later years, there were very quickly determined. More dirt may have
been moved during the paperless years at PARP (Ellis, this volume), but that was an unexpected
benefit. The main benefit is the speed at which anybody could receive answers from the data set
(Wallrodt, et.al, 2015).
Keos Archaeological Regional Survey Project
This improvement in the efficiency of data retrieval was also obvious to the Project
Directors at the Keos Archaeological Regional Survey (KARS) project on the island of Keos,
which started in 2012. Survey teams carried iPads pre-loaded with georeferenced satellite
photography (the imagery was from 2005) in a GIS application. Since the iPads had GPS built in,
the team leader knew exactly where they were, and drew the tract polygon directly on the GIS.10
In previous paper-based survey projects there was often some indecision concerning the exact
10 There have been several web articles written about the accuracy of consumer level GPS
devices, including the iPad. Most sources have put the accuracy at within 2m. See Hodel 2013.
16
location of the team in relation to rough paths, temporary waterways, and electrical lines that
seemed to change with surprising rapidity. Measurements and angles of movement were often
inconsistanly applied. Many pencil lines were erased and redrawn. The tablet technique at KARS
not only allowed the teams place themselves on the right side of these cartographical features
they could verify their location by counting the rows of olive trees. With a swipe to their
database app, they immediately added the same data that they would normally put on their
notebooks. Photographs taken by the iPads were automatically geotagged. The rough GIS plans
were downloaded daily, were properly snapped in the master GIS documents, and were then reloaded
into the tablets before the next day’s fieldwork. The database entries were synced to the
master database each day and any records concerning the finds that were brought back to the dig
house could be attached to those records immediately.
Conclusions
When archaeological data are unbound from their analog predecessors, they no longer
exist as discrete pieces. In digital form, through data connections and transfers, we move away
from multiple pieces of disconnected individual observations and toward a singular dataset.
Although form data are held in databases, they can be exported for visualization in spreadsheets
or other specialized software. CAD and GIS are separate applications for similar data, and the
data is easily shared between the two. With the exception of 3D data, which is beyond the scope
of this essay, any data can be printed.
Techniques of paperless data collection are still very new and are constantly evolving.
Recalling the early adopters of field computer use, we might look to what specialists are doing.
For example, voice data entry and skip logic on touch screens shows great promise for those who
17
have to enter coded data for large data sets (Austin 2013). While custom software has been in use
within archaeology as long as there have been computers, complete desktop archaeological
programs such as Intrasis11 are not the norm. For the majority of academic field projects, desktop
and laptop computer use focuses on customized uses of commercially available software, rather
than custom developed software. The two largest database programs, Microsoft Access
(Windows only) and FileMaker Pro (Windows and Mac) are middleware development platforms
that allow custom solutions to be built. This is the closest that many projects come to custom
software. Using off-the-shelf software solutions is the lowest barrier for entry for a new field
project.
Similarly, the best archaeological uses of mobile platforms that I have seen follow this
same pattern, relying primarily on off-the-shelf software, although the names of these programs
might be less familiar (TouchDraw, iGIS). As a rule, they are intentionally chosen based on their
ability to output data in the format needed to connect to other platforms. For example, at PARP,
we used TouchDraw, which can output to svg, as an intermediary step for integration of field
drawings into the CAD environment. TouchDraw can also output to pdf format for longer term
archival storage. Another example comes from the KARS survey, on which iGIS was selected
for use because it writes to what has become a standard spatial file format, shp.
From the beginning of mobile field recording at PARP, we focused on making sure the
output of the software was usable. Although some newer notebook applications with more
features than a straight word processor were available, we did not use these, because they could
not output the file in a reusable format. Similarly, the vector drawing applications we selected
had to be able to export cleanly to other file formats while preserving their layer structure. Rather
11 http://www.intrasis.com/index.htm
18
than using a standard Harris Matrix program at PARP, we relied on OmniGraffle, because it
allows export as a vector-editable pdf, even though it stores items in its own file format.
While custom-developed software is likely to increase, these solutions are not without
obstacles. The two biggest roadblocks we face in the application of custom-made desktop or
mobile software are 1) operating platform differences and 2) software maintenance needs, both
of which are tied to constantly evolving hardware. While it is conceivably easy to target a single
platform for data collection for a single field season, one must also consider not only the
diversity of devices used by various team members—such as specialists, who want to be able to
work with data on their own platforms and take it with them—but also challenges of multi-year
projects and long-term project needs. With the rapidly changing pace of advances in hardware
and operating system in the mobile space, it is not possible to be certain that specific software
will be able to function in even three years. In the past decade, we have already confronted this
problem, with the change from 32 to 64 bit architecture in desktops and the difficulty of Android
devices to upgrade to later operating systems. For example, because WinBASP did not make the
change to 64 bit architecture, it was abandoned. Hardware component makers will not stop
innovating. This necessitates changes in operating systems, and changes to the Application
Programming Interfaces (APIs) that software relies upon.
All of these considerations: custom designed vs. commercially available software, crossplatform
capability, usability, output, and data integration, are all carefully considered parts of
the overall data collection and retention scheme developed by the data architect. Because the
data management scheme is tailored to the research design and the technical acumen of the team
members, the use of mobile devices to create digital born data is a decision that each project
should make for themselves. It is the newest tool in the archaeologists’ kit and one of the most
19
exciting new tools introduced in the past two decades that has allowed us to rethink the best
practices that we use to record and interpret the past.
Acknowledgements
I would like to thank the organizers of the Mobilizing the Past workshop for inviting me to
participate and especially Jody Gordon for talking through ideas for this paper. I would also like
to thank the reviewers for their comments.

1.2 Are we ready for new (digital) ways to record archaeological fieldwork? A case study
from Pompeii1
Steven J.R. Ellis, University of Cincinnati
One of the more fundamental developments in archaeological fieldwork in recent years,
and arguably much longer still, has been the introduction of the tablet computer. No other
fieldwork tool, or even methodological approach, can be shown to have as many uses, with so
much impact, across so many of our current fieldwork recording practices. Yet while I initially
described the impact of the tablet as ‘revolutionizing’ archaeological fieldwork, now six
summers worth of fieldwork experience has given me some cause to question the impact of
tablet computing across the broader discipline.2 To be clear, I ultimately stand by the claim that
tablets like the iPad will ultimately be seen as having eventually revolutionized the ways we
record our archaeological fieldwork. The question is, however: why is it taking so long?
Systemic revolutions are normally known for their rapidity as much as their ubiquity.
1 My first round of appreciation must go to the organizers of the conference - Erin Averett, Derek Counts, and Jody
Gordon - not just for their invitation to present at the workshop of this published proceedings, but for putting
together such an extraordinary group of scholars form whom I learnt so much. The collection of thoughts in this
paper have benefitted immeasurably from the discussions of that event. More generally my ideas on digital
recording have been shaped in all sorts of ways by my interactions with Eric Poehler, Chris Motz, John Wallrodt,
Rachel Opitz, Bill Caraher, Sebastian Heath, Allison Emmerson, Kevin Dicus, Leigh Lieberman, and Gregory
Tucker: I thank them very gratefully, while also admitting there are many others besides. I take much pride in
thanking the late Steve Jobs, and the team at Apple, for his initial - and their ongoing - interest in our archaeological
research.
None of this paperless fieldwork could have been carried out without the generous assistance and support of the
Soprintendenze Archeologica di Pompei and the Beni Culturali; thanks are due to so many in the SAP, but not least
to Massimo Osanna for his continued support of our fieldwork. This research has been very generously funded by
the Semple Fund of the Department of Classics at the University of Cincinnati, where the project is based, with
additional and extraordinary support from the Loeb Classical Library Foundation, the National Geographic Society,
the National Endowment for the Humanities, the American Council of Learned Societies, and not least the American
Academy in Rome which serves as our Italian base. This paper was written at the American Academy in Rome
while I was an ACLS residential Fellow; my immeasurable thanks to everyone at the Academy and the ACLS for
providing such an unparalleled environment in which to work.
2 See, especially, the coverage of our research that was profiled on the Apple.com website for much of 2010, now
archived here (Discovering Ancient Pompeii with iPad):
https://classics.uc.edu/pompeii/images/stories/ipad/Apple%20-
%20Discovering%20ancient%20Pompeii%20with%20iPad.pdf
19
If tablet computing can be seen as transforming the ways we record archaeological
fieldwork, then its impact will have to be measured through the lens of hindsight, by those in a
generation or two or more. One aim of this paper is thus to provide the future student, interested
in (the history of) archaeological methodologies, a sense of the disciplinary reception of tablet
computers in the recording of archaeological fieldwork.3 For while there may be an inevitable
sense that computers should be used in undertaking and advancing archaeological research, there
is still considerable consternation for change in the way we do our fieldwork.
My experience over the longue durée (of barely six field seasons…) of using the iPad to record
archaeological fieldwork is unusually broad, covering several projects under my direction and
co-direction:
1. archaeological excavations:4 a large (‘big dig’) excavation of two Pompeian insulae and
their surrounds (figs 1-2). The comprehensiveness of the team’s approach to urban
excavations, as well as the scale of the site itself - some 600 years of the social and (infra-
)structural making of an urban neighborhood covering around 4500m2, 10 building plots
with 20 shop-fronts, as well as infrastructure from fountains to fortifications and from
main streets to one of the city’s busiest gates - amounted to a massive and complicated
digital recording strategy and dataset. Our use of the iPad covered excavation and postexcavation
seasons; the project’s earliest years pre-dated the iPad.
3 Said student would do well to read the thoughts on this ‘paradigm shift’ in Roosevelt et al. 2015, esp. 339-340.
See also the comments on Martin Biddle’s observations of systemic change, below (note 18).
4 The Pompeii Archaeological Research Project: Porta Stabia. This project is based at the University of Cincinnati
and the American Academy in Rome. Select publications include: Ellis (2011a); also Ellis et al. (2011; 2012; 2015);
Ellis forthcoming a, and Van der Graaff and Ellis forthcoming. For more on the project, including a more complete
bibliography, see http://classics.uc.edu/pompeii/.
20
2. architectural surveys:5 a survey of the standing remains of one of the largest structures in
Pompeii, the Quadriporticus. Our four fieldwork seasons were all undertaken with the
iPad.
3. archival and legacy data studies:6 a legacy data project, including architectural survey, of
the Panhellenic sanctuary at Isthmia, Greece.
4. and urban field surveys:7 a study of the retail landscapes of more than 100 Roman cities
throughout the Mediterranean.
Pompeii and the iPad
Before offering something of a very brief overview of my experience with tablets in
archaeological field recording, some points of clarification are necessary. The first is that the
remainder of this paper will draw mostly from my experience of using iPads on our Pompeii
excavations. The second is that our team’s use of these tablets was as a field device. This may
seem obvious, but it is a point that I have often had to clarify to (conference) rooms full of
archaeologists, some of whom have wondered, and often-enough assumed, that we had used the
iPad to replace all forms of digital technology from site cameras to office computers. Rather, we
use them mostly in the field to replace paper notebooks, paper forms, and mylar paper, while
only rarely have they supplemented computers in the field office or library. A third and broader
point of clarification is that lost to many of the current debates about going digital is the fact that
all archaeological ‘projects’ are essentially digital projects; here I think it is necessary to define
5 The Pompeii Quadriporticus Project. A project I have co-directed with Eric Poehler, and thus based out of UMass
Amherst and the University of Cincinnati. See Poehler in this volume; see also Poehler and Ellis 2011, 2012, 2013,
2014.
6 The East Isthmia Archaeology Project, under the co-direction of Timothy Gregory (Ohio State University) and
myself. See Ellis et al 2008; Ellis and Poehler 2015.
7 Ellis forthcoming b.
21
an archaeological ‘project’ only as research that is being systematically published. Unless we are
to submit photo- or carbonized-copies of our paper-based records, in their hundreds and
thousands, to archival holdings and university libraries or elsewhere, to take all of those data and
observations or ideas from the trench, site, or field to publication requires passing it through
some kind of digital filter. As blindingly obvious as that point may be, it has some resonance for
some of the following discussions. To my mind that digital filter works best - not just for
efficiency of data recording, but for the quality and quantity of information that comes from the
essentially close relationship between digital recording and engagement with the material - when
it is fitted to the site itself. The final point of clarification is that the overview that follows is
aimed at (or perhaps limited to) what are to my mind the more interesting and deeply entrenched
aspects of the use of tablets in archaeological fieldwork. It is thus not about the types of Apps we
have used or an assessment of how we used them. Besides, for the past three seasons we have
conducted so-called ‘study seasons’ with no excavations, and thus - for the most part – have had
a somewhat limited need for tablets as field devices given our in-field work arrangement which
has included everything from electricity to site-labs to air-conditioned offices.8 During this time,
which is about half the life of the iPad itself, practically every App we had ever used during the
excavations has since been significantly updated, while countless others have appeared that we
have yet to use. Even the hardware of the iPad has changed significantly enough from the
versions we used for the first three fieldwork seasons; it is now possible to take (at least) decent
photos, for example, and to do respectable photogrammetry. Even with these issues aside, much
better articles than the one I could write - or rather, could want to write - have focussed on the
8 Thanks are again due to the SAP; see note 1, above.
22
more detailed utility of Apps, iPad hardware, and, more interestingly, on calculating the ways in
which tablets have improved the efficiency, clarity, volume, and value of field data.9
What is worthwhile to point out is that our results and experiences are rather similar, or at
least familiar, to those who have actually used tablets in recording field research. The impact of
our use of the iPad on our project can be (overly-)summarized as having brought:
1. Faster and more efficient data capture, which was also cleaner and more accurate
than we had ever collected on paper. For example, of the hundreds of thousands of
words and numbers recorded on the iPad, naturally not a single one proved
illegible. The simplest measure of a spellcheck, for example, ensured that most
words were clean; and the process of respelling a word often prompted some
necessary review of the syntax of the sentence just written. Data and word searches
were especially helpful for recalling various details. More information was
recorded for every structure, trench, and context, whether in tabular form or as
written descriptions, than had been achieved with pen and paper. Moreover, that
(extra) information, from simple descriptions to more thoughtful observations and
analyses - was of a richer quality; some thoughts on gauging ‘quality’ in field
recording are below.
2. More dynamic data. The entering of more types of data improved our engagement
with the material during the recording process, as well as (immediately) fueling a
series of otherwise less obvious questions of the metadata behind the more overt
datasets and questions.
9 From among several, see in this volume: Poehler; Motz; Wallrodt; and Fee. See also, especially, Berggren et al.
2015 and Roosevelt et al. 2015, as well as Fee et al. 2013; Pettegrew et al. 2013; Poehler and Ellis 2012, 2013, 2014;
Austin 2014.
23
3. More secure data. All of our field data was regularly backed-up through the course
of a day, and in multiple places. Whereas our earlier paper-based systems saw our
documents and forms being backed up by scans and photocopies, the more
immediate system of backing up our digital data to several devices and servers
provided an arguably more stable system of data storage and security. Certainly
the newfound simplicity and speed with which our data could be backed up meant
that it was done more often than could ever have been feasible in our earlier paperbased
system.
4. Better on-site access to the data, and to so much more information besides. Even
without access to the internet, there is an extraordinary amount of data that can be
pulled up to benefit the field observations and analyses.10 The ability to draw on
such a wealth of data while still in the field is of enormous analytical benefit to the
ongoing research and recording.
The iPad thus radically transformed the ways in which we recorded, and engaged with, the
excavation of a large urban site. Many of these improvements from using tablet computers
instead of pieces of paper were probably to be expected. Other advantages were not as readily
anticipated. For example, the ability to access live data - whether from trench to trench, or
between the various teams of excavators or bio-archaeologists or conservators - caused a
heightened engagement between the different cogs of the team network; something of an
‘interdisciplinary’ communication that was more active and fruitful than our experience from the
pre-iPad years of the project.11 Another striking advantage relates to the non-technical and
simple (but not simplified) utility of so many of the Apps. Almost all of the Apps we used had
10 See, especially, Poehler and Ellis 2014.
11 On approaches to improving the communication of various sub-groups across large fieldwork teams, see Berggren
et al 2015, 436, 446.
24
familiar interfaces: for example, FileMaker for our databases, Pages for our word-processing,
and iDraw and TouchDraw for our vector-based drawing. With genuine respect to those who
have spent some years toward developing custom-built, stand-alone Apps that can handle a host
of archaeological field recording practices, our experience has been one of contentment with the
range of available Apps on the market. This was in part a product of necessity. Given our
adoption of the iPad immediately upon its release in 2010, our fleet of Apps were those ‘off-theshelf’
and immediately available.12 But with the proven effectiveness of those Apps, their
minimal cost,13 stability and technical support (and ongoing updates), and not least the fact that
the vast majority of field data for all archaeological projects is really rather simple and easily
handled by such Apps, what was once a necessity - the off-the-shelf App - has since become
something of a philosophy.
Naturally there have been some more difficult aspects along the way to recording
digitally in the field, even if their currency or impact on the project has been close to minuscule
by comparison to the number and scale of the benefits of going digital. The most significant of
these has been the integration of all parts - or rather, people - of the project; it is one thing to
convert a project from paper-based to paperless, but another to convert all of the project’s team
members to that system.14 It is a common practice for ‘specialists’ on archaeological projects, for
example, to bring with them their own rather idiosyncratic systems, honed over decades and on
12 Credit here should be given to John Wallrodt of the University of Cincinnati, who tirelessly tested and developed
our paperless system so that we were in the field with a fully-operational paperless system just two months after the
release of the iPad.
13 The cost of these Apps, constituting a tiny fraction of 1% of the project’s total budget, means that the financial
outlay on them was as beneficial to their value as it remains hardly worthy of statement. Equally only worthy of
comment in a footnote is the cost associated with the tablets themselves. As for any respectably funded project that
leads to publication, the total costs of fieldwork recording devices - whatever their type, or even their number -
should likely be close to negligible next to the overall costs of the project from set-up and excavation to postexcavation,
publication, and ongoing archiving.
14 For some of the challenges of integrating digital systems into established fieldwork projects, but from a pre-iPad
perspective, see Fisher et al. 2010.
25
multiple types of projects, to record their data. A good many of the specialists on the Pompeii
excavations maintained these time-honored, paper-based recording systems. Naturally that data
made its way into our system using more traditional, and achingly time-consuming, methods of
data-entry, and the time spent doing that was a reminder of how such resources of a project can
be better spent. The integration of paper-based records into a digital system also exposed just
how limited the range and potential utility of ‘traditional’ data can be. In part, this experience
also served as a reminder that the use of tablets leads towards, and promotes, more of a
centralized and integrated system for data structure that is beneficial for everything from datasecurity
to site-wide and multivariate analyses to the management of productivity and
publication goals.
Digital recording in archaeological fieldwork
Our experience in converting a paper-based project to a paperless one has thus been
overwhelmingly positive. As much seems true for the now several other archaeological projects
that have adopted tablets in their field recording strategies.15 But for all the ways in which tablet
computers have revolutionized the recording process of so many archaeological projects, still the
reception of tablets in field archaeology has been strikingly pessimistic and polarizing. It is
especially the sharply negative reception of the tablet that I currently find to be of more interest
than the continued detailing and explication of their value and utility, especially as much of the
reaction speaks to a romanticization of 20th-century fieldwork methodologies married to a
broader disciplinary consternation for change in the way we do things. So while an integrated
digital data system - from site to analysis to publication and archive - can be described as the
15 See note 9, above.
26
“Holy Grail”,16 still it is questioned whether it could - or rather, should - be possible to convert
the ‘complexities’ of the archaeological recording process from tried and tested blank pieces of
paper and forms to a computerized system. To be clear, the remainder of what I have to say
about the negative, or at least pessimistic, reactions to tablets in archaeology is drawn more so
from ‘front-line’ experience than from what I can learn via peer-reviewed publications; of course
it is easier and usually more approporiate to cite examples from the latter. This scenario can only
in part be pinned on the fact that the topic – if for tablets more so than digital devices per se - is
still relatively new; even so, Christopher Roosevelt and his colleagues have now shown us that a
comprehensive treatment of the topic can be made in a relatively brief period.17 But it is also part
of the aim of my contribution to this volume: that is, to guage something of the disciplinary-wide
reception to tablets in the recording of archaeological fieldwork. Many will agree that this is a
watershed moment in our approach to archaeological fieldwork. And many will also agree that
much valuable information about the immediate reception of such paradigm shifts can be too
easily lost, forgotten over time unless accounts like (but also against) this one are presented;
similarly, it was through people like Martin Biddle and Birthe Kjolbye-Biddle that we now have,
for just one example, a contemporary voice on the rapid and fundamental reorganisation of
archaeological fieldwork under the metric system.18 To wait for a more steady stream of
(potentially revisionist?) publications on our matter at hand is to risk losing the sense of how
these digital developments were played out at precisely the time of their advent. Especially
important, to my mind, is the fact that the lack of peer-reviewed publications on the reception of
tablets in archaeology currently belies the views of a rather sizable demographic in field
16 May and Crossby 2010, 49.
17 Roosevelt et al. 2015.
18 Biddle and Kjolbye-Biddle 1969. For related developments under the Winchester Research Unit, see most
recently Leighton 2015, 74.
27
archaeology who are otherwise considerably vocal – whether in classrooms or conference halls,
on site or online – about their distrust of digital devices in the recording of archaeological
fieldwork, and (so) of the data and knowledge these approaches produce.
To return to those arguments for the continued use of paper over computer, a good
number of them have, to my mind, explored the limits of logic, with complaints that range from
the naive to the more measured and constructive. Those at the former end hardly warrant
reaction. A strange but common question, for example, is how a tablet could possibly operate in
the rain - a question as easily applicable to a piece of paper as a tablet - to how secure the digital
data might be should a giant magnet fall from the sky.19 That loose-leaf paper and pencil may be
the preferred medium for recording in the midst of a rainstorm, or during some apocalyptic
magnet attack, demonstrates just how far we can often be from a reasoned discussion of
emerging field methodologies. Even so, no small amount of time has been lost in allaying these
concerns, whether in the field, at archaeological conferences, or, perhaps ironically, via debates
in (no longer live) online blog entries.
Especially common are the concerns for the (immediate and ongoing) security of digital
data; this is of course a concern that is as valid for digital as it should be for paper-based data.
Little wonder too, given our collective experience: it might be impossible to find a practicing
archaeologist of any generation who has not experienced some traumatic loss of digital data,
particularly prior to the most recent advances in cloud-based server technologies. From an
inability to open, or even find, old digital files, to the misplacing or physical breakage of floppy
disks, zip-disks, and thumb-drives, the threat of losing digital data challenges our confidence in
19 Something of this concern for how digital tools might – or rather, will not - stand up to the “rigours” of
archaeological fieldwork is encountered in the responses of archaeologists to digital pens, collected in Fisher et al.
2010, esp. 5-6.
28
converting to a fully digital system. But our collective experiences of data-loss are for the most
part generational, and arguably amateur. More than tablets, it is the related advent of cloud-based
storage that should remind us of the anachronistic nature of our memory for lost data. While an
iPad can be misplaced or break (not quite) as easily as a paper notepad or floppy disk,20 that its
data can have already, and immediately, been synchronized to any number of devices and servers
should drastically minimize most fears of data-loss, and certainly by comparison to the present
paper-based or digital systems of the past. Of course our (inevitable) inability to lose digital data
does not solve what should be the principal, omnipresent concern: that of data curation. Just as it
is not enough to simply have hard-copy datasets - they require ongoing organization and physical
maintenance - so too are digital datasets demanding of constant curatorial care. This is an
important topic for which more discussion, and a different and more developed paper than this
one, is essential.21
Slow Archaeology: deskilling and (or in?) the ‘golden age’
From among the range of concerns for digital field recording are a number of more
thought-provoking issues that are worthy, and sometimes demanding, of response. Several of
these fall under the notion that field recording with tablets threatens the once careful and
considered field methodologies of the past.22 The most convincing among the proponents is Bill
Caraher, who has championed the intellectual value of a ‘Slow Archaeology’, a kind of
archaeological philosophy that urges more caution about the speed and growing industrialization
of our fieldwork processes, a good many of which are (in)arguably associated with the shift from
20 While it has been pointed out to me that a paper notepad might survive the fall from a 4th story window better
than an iPad (for which I have some personal experience…), still it is harder to scrunch up or tear apart a tablet like
it is a piece of paper.
21 In the meantime, Eiteljorg 2011.
22 For example Caraher (this volume). Also Caraher 2013; and, in support, the blog entry of Nakassis 2015.
29
analog to digital recording tools.23 More specifically, these concerns for digital field recording
are about a ‘deskilling’ (after Caraher) of archaeological method, as well as a worry that the
efficiency brought about by digital field recording leads mostly - or rather, merely - to the
collection/creation of more and more data. Especially interesting is the idea that the use of a
tablet to complete forms, construct narratives, and draw archaeological objects and their
stratified relationships leads to a lack of engagement with the subject matter and thus ultimately
risks a deskilling of our otherwise craft-like archaeological fieldwork methodologies. To the
(well-intentioned) provocation that those of us using technology to record our fieldwork are
becoming deskilled, at least by comparison to those who record on paper, I might, in keeping
with the spirit of Caraher, tease with another: if it is not simply an assumption, where is the
weight of evidence that our broader discipline was ever very skilled at field recording in the first
place?
As hubristic as it may seem to some archaeological circles to question our broader
disciplinary skillset, the reality is that for the vast majority of data that survive from (too few)
academic archaeological projects over the past century or so, the bulk of it was not skillfully
crafted by the deft hands of the archaeological doyens who led these projects, but cobbled
together by their inexperienced students or, rarely much better, their apprenticing supervisors.24
The evidence lays in the legacy data, which too often constitutes the only - skilled or otherwise -
record of field research and the corresponding intellectual understanding of a site. And it is here
that any challenging of the archaeological skillsets of those who record with iPads, or of those
who generated the legacy datasets from paper, requires some necessary clarification: are we
23 Caraher (this volume), and 2013.
24 See Leighton 2015 on how the structure of archaeological teams can vary so markedly across contemporary
cultures (her case studies are British and Andean teams), and the impact this has on the methodologies and
outcomes.
30
targeting the quality of the fieldwork and its ‘knowledge production’, and thus, unfortunately, the
archaeological acumen of the individual or of the team, or are our critiques directed at just the
quality of the recording? There is of course a complex interconnection between doing
archaeological fieldwork and recording archaeological fieldwork. It is often the same thing, and
sometimes not. But for as long as the data and archives and (more rarely the) publications are all
that survive of the fieldwork and ideas and (more commonly the) destruction, then these datasets
represent the skilled and unskilled fieldwork methodologies and results in their entirety.
To stage our understanding of recorded fieldwork, therefore, on the notebooks of named
scholars - whether Carl Blegen, Frank Brown, Flinders Petrie, or Alfred Morley - is to deny that
the vast majority of fieldwork data survives instead from the hands of relatively inexperienced
students.25 Almost all of the recorded fieldwork for the American excavations at the Panhellenic
sanctuary at Isthmia, for example, was not crafted by Oscar Broneer or Paul Clement, but
scribbled down by well-intentioned novices (fig. 3).26 For my own legacy data project at that site,
barely 10% of the recorded, stratified contexts from the 1970s excavations can be remotely
reassembled to form an approximated matrix; these records, however, come from a period in our
discipline that should otherwise (or arguably) be seen as foundational to our understanding of
taphonomy, site formation processes, and the recording of stratified sequences.27 Even the
briefest of surveys of legacy data for so many 20th-century excavations, even if too rarely
available, shows that the experience at Isthmia is hardly unique.28 It is rare to happen upon a
legacy data project that reports skillfully crafted, paper-based datasets.29 I want to be careful here
25 On the history of diary entries in archaeology, see most recently Mickel 2015, 301-302. See also Kidder 1959;
Hodder 1989; and Pavel 2010. See also Leighton 2015 on inexperience in archaeological teams.
26 See note 6, above. On questions of ‘trust’ in the production of field records, Leighton 2015, esp. 75-77.
27 Schiffer 1972, 1987; Harris 1975. See also Biddle and Kjolbye-Biddle 1969.
28 See, for example, Bibby 1993, 110. Also Mickel 2015, 301.
29 Allison 2008.
31
to avoid the slippery slope toward unfairly deriding the archaeological acumen of past
generations.30 Exceptions exist, albeit arguably, for expertly excavated sites with all attendant
parts: accompanying and suitably skilled notebooks, datasets, and, by definition, resultant
publications and well-maintained archives. But these are surely too few to reconcile any such
notion that dependable skillsets once defined the paper-based recording of archaeological
fieldwork, or that we should endeavor to maintain those standards.
Revisionism and the infallibility of paper
A related socio-academic development connected with the consternation for tablets in
fieldwork is, to my mind, the coincidental revisionism of traditional paper recording methods.
Opponents to paperless methods now speak to an infallibility of paper, where the horrors of the
past (but also present) - be they easily lost or damaged forms, limited and physically located
copies, faded and illegible information - are now either forgotten or at least cast in a more
positive and forgiving light. Set against the fragility of a tablet, paper records are (re)imagined as
provenly dependable and indestructible (“real” and “secure”),31 robust characters in a halcyonic
vision of when archaeology was done right.32 As much as I do not want to present digital data as
perfect in every way, neither can I accept the same fantasy for paper-based records. Paper is
moreover presented as a superior medium for the many associated tasks of field recording, from
the jotting down of the simplest notes and records, to the nuanced and crafted care of site
illustration, or the transcribing of complex and intellectual thought. In this context, the cognitive
freedom of a blank page of a paper notebook is presented in opposition to the rigidly organized
30 See, for example, Matskevich’s (2011) review of Pavel 2010.
31 May and Crossby 2010, 49.
32 See, for example, some of the collected opinions on analog and digital methods in Warwick et al. 2009.
32
database fields that atomize the bits of data that are thought to be more typically collected in an
iPad.33
That there is some reflexive value in recording data and thoughts onto an open page is
undeniable,34 even if such a method, when performed exclusively, is less effective.35 But the
unstructured diary entry onto a blank page is not an exclusive privilege of the paper notebook,
and nor is the intellectual value of that kind of recording method necessarily jeopardized by the
use of an iPad. The unstructured blank page, being the best equipped feature of a piece of paper’s
arsenal, is, after all, but one of the hundreds of utilities enjoyed on a tablet. For our recording of
the Pompeii excavations, open-page diary-style entries were effectively produced in concert with
the forms and database recording. Whether reflexive or redundant, recording in this way
produced a richer body of data; each data structure, after all, whether drop-down lists and checkboxes,
or free-form textual descriptions and sketches, has (potential) value and (some)
limitations. And in reality, our post-excavation processing of the data has drawn immeasurably
more valuable information from the structured data. Still it is necessary to recognize the related
role of diary-style entries in the formation of those datasets, difficult though it may be to qualify
or quantify. So while it is true that field data is becoming more and more atomized, a scenario
that is promoted or exacerbated, depending on one’s view, by the bringing of databases into the
33 Problems in field recording have been pinned on structured forms since at least Latour 1987. More recently Pavel
2010, ch. 9 has argued for the value of forms over diary-like entries; on which see also Matskevich 2011. See also
Bibby 1993, 110.
For studies on the metacognitive value of note-taking methods, albeit based on students recording information in
classroom lectures rather than archaeologists making field observations, see Mueller and Oppenheimer 2014.
34 See Mickel 2015, 301 who argues that the diary-style entry elicits “in-depth analyses, preliminary hypotheses, and
dialogue amongst excavators as it was designed to do.” Even so, Mickel emphasizes more so the redundancy of
information between diary entries and standardized forms.
On studies for and against the metacognitive value of digital and paper-based note-taking methods, see: (those for)
Bebell and Kay 2010; Driver 2002; (those against) Sana et al., 2013; Awwad et al. 2013.
35 Mickel 2015 demonstrates how each form of recording, albeit often redundant, is essential.
33
trench via tablets, I would argue that both structured and unstructured recording should, and of
course can, be performed regardless of paper or tablet.
Digital Illustration is illustration
Some confusion and misunderstanding similarly circulates about the use of a tablet to
draw archaeological objects and their stratified relationships and contexts. There is some irony
here, given that in our experience it was digital illustration where we made some of the most
significant improvements to the quality, not just quantity, of information we could gather while
in the field; this is similiarly the case for the use of tablets for illustration at Çatalhöyük.36
Streamlined though the illustration process may now be, particularly given the utility of
templates in vector-based drawing environments, still - and critically - the drawing process is not
entirely automated. So while there is an appearance that digital illustration with a tablet is
somewhat akin to the automated process of taking a 3D laser scan or a digital photograph, in
reality the process retains the essential, ‘traditional’37 skills and values of illustration; the objects
and their stratified relationships are individually hand-drawn on-site, not (just) laser-scanned.
Digital illustration is still illustration. There is no less engagement with the trench or
architecture; rather, it could be argued that there is a yet heightened commitment to the material
given that the ability to draw directly to a vector-based layering system allows for a more
dynamic yet cleaner drawing process.38 Both accuracy and precision are thus improved, not least
because drawings can now be easily achieved at any scale, including 1:1. Thus on the one hand,
the scale and precision of digital illustration allows for more detail, as necessary. On the other,
36 Berggren et al. 2015, 443.
37 On some of these issues, see Perry 2014.
38 On the knowledge making of visual recording, see Perry 2014, esp. 194-198. On improved engagement between
excavation and recording with tablets at Çatalhöyük, Berggren et al. 2015, 443.
34
the utility of the medium allows for simple but accurate sketches that combine photographs and
other datasets. Whether through technical illustration or more free-form sketches, the value of
engaging, even slowly, with every last object and relationship is not lost to digital illustration.
A question(ing) of efficiency
Odd though it may seem to any archaeologist who has tried to balance the research goals
of a team of scholars with the many financial, administrative, and peer-academic pressures, some
of the benefits or outcomes from the increased levels of efficiency in fieldwork brought about by
tablet computers have been called to question.39 Beyond concerns that efficiency amounts to less
engagement with the trench or site, doubts have been cast as to whether the improved efficiency
corresponds with a greater understanding of the subject matter.40 That line of enquiry is at once
reasonable, even if any proposed answer - one way or the other - will prove subjective and
difficult to attest; surely any such demonstration of an improved understanding of a site that is
based on a recording system, digital or paper-based, is endlessly debatable.41 How does one, for
example, demonstrate that the ideas and analyses of a team of scholars are now stronger under a
newer recording system? Or that the intellectual value of a more traditional project, if eventually
published, is that much stronger than that of a paperless project? The measure of sound fieldwork
and recording methods must surely and always be relative to a healthy and respectable
publication record.
39 Caraher (this volume); Caraher 2015; Nakassis 2015.
40 Hopkins 2010, for example, has questioned whether the efficiency associated with these new methods represents
any kind of advance over the way sites were investigated some 150 years ago.
See also Nakassis 2015, who in response to Roosevelt et al. 2015, questions whether their ultimate contributions are
in any way better because of the efficiency of their fieldwork.
41 Again the example of Nakassis 2015, who in noting the efficiency and impressive documentation of the fieldwork
(on a granary) as outlined in Roosevelt et al 2015, questions if their efforts “get us something important… …does it
help us interpret the granary any better? It hasn’t seemed to thus far.”
35
In any case, it is hard to imagine that many archaeologists would - indeed should, as a
matter of best-practices - argue against a more efficient and productive fieldwork system. Not
only are most archaeological projects obliged to publish as much high-quality research as is
(un)reasonably possible, but the best of these projects of course want to be active and productive.
Efficiency in the way we do things is for the vast majority of projects, paperless or otherwise,
more of an aspiration than a distraction. It is a goal that does not come at the cost of intellectual
engagement, but in my experience is paid for by the time once spent in performing some of the
most time-consuming and menial but necessary duties: typically data-entry and scanning, but the
list of tedious tasks is a long one. None of this need necessarily threaten the core values that are
being attributed to a Slow Archaeology. That there is some value in the brand(ing) of Slow
Archaeology is, of course, inarguable: more time spent in the field giving thought and discussion
to the archaeology, rather than merely to recording it, is crucial to our understating of the site. In
this we should remain grateful to Caraher for (re)raising these issues, or aspirations, at a time of
great change in the way we collect data for the production of knowledge. And it should follow
that just as much be true for our published records, which should provide analysis, context, and
interpretation of the material, not just a record of it. Can I call for a ‘Slow Publication’
movement? In the meantime, to stick with the recording processes, I simply do not see that
digital recording methdologies, by definition, should pose such a grave threat to knowledge
production. For in spite of the efficiency of tablets, and true though it may be that more and more
data can be collected with them (as if an abundance of data were a problem for a discipline that
has been plagued by unpublished research projects with nonexistent datasets), it is by far the
greater engagement with the archaeology, while still in the trench or the field, that characterizes
at least my own experience of paperless archaeology. For the Pompeii excavations, and I suspect
36
as much is true for other paperless projects, the emphasis has never shifted from in-trench
engagement and analysis to some kind of robotic, single-minded (or mindless, as is the inference)
hunger for more and more data.
Our disciplinary consternation for change
Should we be surprised by the opposition to paperless archaeology? For all the new
developments that ameliorate each generation of archaeological research, still we are a discipline
that more often prides itself on our traditional ways of doing things; long-held recording systems,
for example, whose increasingly inveterate nature lends some kind of earnest but imagined
authority and quality. In some ways this is not unlike the ‘black-boxing’ of older methods,
whether weak or strong, from necessary and ongoing scrutiny.42 Some of these systemic routines
are manifest in the little grey notebooks used almost universally, and for close to a century, in
Greek archaeology (fig. 4). It is their heredity that transcends their practical qualities as sturdy,
conveniently-sized books to write things in; as much seems true of the olive-oil, motor-oil, and
feta tins that have been (re)used as artifact storage containers in the Athenian Agora excavations
from the 1930s until the present. These objects, and the systems they maintain, are continually
used - indeed, celebrated - because they have always been used. While I share the same, fond
nostalgia for objects of heritage in our field, I am as much intrigued as I am concerned by the
opposition we create between tradition and innovation in the ways we record our fieldwork.
Venerated notions of experience are ceremonially draped over the more traditional systems so as
to explain, maintain, and not least ritualize the status quo.43 The wider socio-academic
implications of what is a willful rejection of change, however, are troubling: can we really
42 Leighton 2015, 68-69. For the term ‘black-box’, Latour and Woolgar 1979, 51.
43 For the broader setting, see Morris 1994.
37
imagine that there is some intellectual value in continuing to record data in the same ways as was
done generations ago?
As convinced as I am of the values of going digital in archaeological fieldwork, I believe
it all the more important that regardless of the paper-based or paperless medium, we should
recognize the intellectual value in developing and testing new ideas in methodology rather than
maintaining and championing old ones. And while this may require a more realistic than
romantic retrospection of our discipline’s past, it also demands the kinds of debates that have
been rightly provoked by the call for (a return to) Slow Archaeology. Here we should remind
ourselves that the values associated with a Slow Archaeology are the same as those for a ‘Good
Archaeology,’ and that none of these need necessarily be the exclusive purview of a paper-based
recording system, past or present. But the methodological introspection prompted by these
debates - even if it has been aimed more squarely at paperless archaeology - is in any case
critical for a period that will inevitably be seen as the transition from paper to digital recording.
How long this transitional period lasts - one generation, or two, or more(?) - is difficult to
answer. The more important measure should be of the products of paperless (and any surviving
paper-based) archaeological projects: the quality and quantity of their data, the maintenance of
their archives, and the overall contribution of their publications and broader outreach.

1.3 Sangro Valley and the Five (Paperless) Seasons: Lessons on Building Effective Digital
Recording Workflows for Archaeological Fieldwork
Chris Motz, University of Cincinnati
On March 8, 2011 I sent a foolish email. During the winter I had played around with
creating a basic FileMaker Pro database for my iPhone that could be used in the field. I thought it
had potential and I had read about iPads being used in Pompeii the previous summer (Apple Inc.
2010; Ellis 2011), so I sent a few screenshots to my dig director and asked if she would be
interested in using such a system during the Sangro Valley Project's coming season. At most I
thought she might agree to test it out with one or two iPads and maybe switch over fully the
following year. Instead, after a brief email exchange she told me she wanted the project to go
entirely paperless in the coming summer.
My first reaction was surprise. My second was fear. What had I gotten myself into? I had
four months to develop a full excavation database, complete with syncing and new image
handling procedures. I had limited experience with FileMaker, was a full-time, first-year
graduate student, and had a part-time job. Compounding all of this was a lack of resources that
could help one build this kind of system. Excavation databases were not new, but this particular
combination of hardware and software had never been available. Furthermore, a research
database and a recording system are two different beasts. Even proper iOS app developers were
still figuring out how to design effective interfaces for tablets. Our experiment easily could have
failed.
Through a combination of long hours, help and advice from John Wallrodt (including his
blog posts on www.PaperlessArchaeology.com, which has been a valuable resource for many
other projects [Bria this volume; Butina 2014; Gordon et al. this volume] and is still the best
43
starting point for those interested in building a paperless recording system), and Google, I
managed to build a functional but unfinished system. It worked, but it was a beta-quality solution
that required constant maintenance and bug fixes. All of the critical parts worked at the
beginning of the season but I continued to add and change many elements throughout the
summer. Our field staff’s patience and their willingness to cooperate in this experiment played a
huge part in its success.
Since 2011 I have continued working on the system for the Sangro Valley Project (SVP,
directed by Susan Kane: see http://www.sangro.org). I have also developed a paperless recording
system for the Say Kah Archaeological Project in Belize (SKAP, directed by Sarah Jackson and
Linda Brown), which was deployed for the first time in the summer of 2015, and since 2013 I
have managed and continued the development of the paperless system that John Wallrodt built
(Ellis 2011; Wallrodt et al. 2015; Wallrodt this volume) for the Pompeii Archaeological
Research Project: Porta Stabia (PARP:PS, directed by Steven Ellis: Ellis this volume; see most
recently, Ellis et al. 2015; for full bibliography, see http://classics.uc.edu/pompeii/). My skills as
a FileMaker developer have grown considerably. But far more valuable are the lessons I have
learned from our successes and failures, from watching people use paperless systems, and from
the feedback they have given me.
In the first part of this chapter I will summarize the SVP’s paperless system and how it
has evolved from the initial creation and deployment in 2011, to the redesigned interface in
2012, and to a focus on documentation in 2013. I will then present some lessons learned during
the SVP’s five seasons of paperless recording (2011–2015) as well as during my work with
SKAP (2015) and PARP:PS (2013–2015). I will identify some of the most common problems
that I have encountered during the design and use of paperless recording systems and I will offer
44
some recommendations for avoiding or fixing them. Many of these problems are not unique to
projects with digital recording systems, and most of the difficulties were not technical in nature.
Rather, many of the most significant problems arose from integrating workflows: not only digital
and physical workflows, but also the workflows of different actors in the project. Finally, I will
engage with recent critiques of paperless field recording, in particular Bill Caraher’s provocative
philosophy of “Slow Archaeology,” which cautions against the (over)eager pursuit of efficiency
and promotes methods that nurture interpretative insight (Caraher 2013 [2015]; 2015b; this
volume). I will offer SKAP as a case study of how digital recording practices can help to further
our understanding of the ancient world in qualitative ways, not merely quantitative ones.
Sangro Valley Project: 1994–2010
The Sangro Valley Project was founded in 1994 and is now managed by Oberlin College
in collaboration with the Soprintendenza per i Beni Archeologici dell’Abruzzo and the
University of Oxford. The project operates a summer field school in Italy for students from
Oberlin, Oxford, and other schools. The project’s goal is to characterize and investigate the
nature, pattern and dynamics of human habitation and land use in the longue durée within the
context of a Mediterranean river valley system—the Sangro River valley of the Abruzzo region
of Italy, the territory of the ancient Samnites.
As a regional project, the SVP does not excavate at a single site. Instead, excavators
move from site to site; the duration of study at each site depends on the amount of time required
for a proper investigation, and in some seasons the project has been active at multiple sites. The
SVP also employs pedestrian survey and other methods of data collection. Therefore, the
project’s infrastructure needs to be mobile and flexible, and researchers cannot count on having
45
access to anything other than what they bring into the field. Although the SVP does have a wellequipped
computer lab with an internet connection in the dig house (generously provided by the
town of Tornareccio), there is no internet and no power in the field. These constraints did not
pose much of a problem for paper-based recording, but they were to have a significant impact on
the coming digital system.
Over its first sixteen years the SVP employed various formats to record, store, manage,
and analyze its data, as was common among archaeological projects active in the 1990s and
2000s (Betts 2012; Ellis 2011; Fee et al. 2013; Gordon et al. this volume; Houk 2012; Sayre this
volume; Vincent et al. 2014; Wallrodt this volume). Excavation, survey, finds, and sample data
were recorded on an array of paper forms in the field and in the lab, and the same information
often needed to be recorded on more than one form. At the end of each season, these were
scanned and transcribed into one of a number of digital formats that varied throughout the years
(Microsoft Access, Excel spreadsheets, and fillable PDFs). Supervisors kept notebooks that were
scanned at the end of each season but were never transcribed. Spatial data were gathered with a
total station (for excavation) and handheld GPS units (for survey). These files were incorporated
into a GIS for spatial analysis, of which the SVP was an early adopter (Bell et al. 2002; Lock et
al. 1999). Drawings were done on Mylar sheets, which were eventually scanned and turned into
digital vector drawings. Photographs were taken with digital cameras; despite being “born
digital,” they still required secondary processing. Supervisors were supposed to upload and
caption their digital photos at the end of the day, but the process frequently was deferred for a
day or two. This meant that photos were being labeled several hours or days after they were
taken, and this delay often led to errors. The dispersion and disconnection of our data made it
very difficult to get a complete picture of all the information that existed for any given area or
46
object; it promoted the introduction of errors in cross-referencing and labeling, and left the
recognition of these errors to chance; and it caused supervisors to spend much of their time
managing data rather than thinking critically about their trench, the site, or the region as a whole.
2011 Season
The opening of a new site in 2011 provided an opportunity to rethink how the project
would collect and manage data for all future work. For years the directors and staff of the SVP
had bemoaned the inefficiencies and mistakes that accompanied paper-based recording, of which
we all had been both victims and perpetrators at various times. The obvious solution was always
some sort of digital system, but nothing existed that met our needs until the iPad was introduced
in 2010 (Wallrodt this volume, who also makes clear that similar discussions had been taking
place at other projects). That email exchange in March, 2011 was the culmination of a long
search for a solution to what was, for us, a very real problem.
The paperless system that we employed in 2011 (Motz and Carrier 2013) took an eclectic
and somewhat fragmented approach, necessitated by the limitations of the software that was
available in those early years of mobile app development. Rather than using one multifunctional
app, we employed multiple pieces of off-the-shelf software (for off-the-shelf v. “bespoke”
software, see Ellis this volume; Gordon et al. this volume; Roosevelt et al. 2015; Sobotkova et
al. this volume; Spigelman et al. this volume).
The heart of the system was a custom FileMaker database. The FileMaker platform
combines moderate customization with high reliability and commercial support, making it one of
the most popular choices among archaeologists (e.g., Bria this volume; Ellis this volume; Houk
2012; Jennings 2011; Prins et al. 2014; Spigelman et al. this volume; Wallrodt this volume.
47
There are now many more options: see below). All excavation data were captured in the field
using FileMaker Go on iPads. In keeping with the SVP’s educational mission as a field school,
students always have participated in the recording process (including photography, drawing,
writing notebook entries, and filling out context, find, and sample forms) under the guidance of
the trench supervisors, who were ultimately responsible for all field recording and still performed
the bulk of it. None of this changed with the adoption of iPads. Each trench was allocated only
one iPad to avoid numbering conflicts and duplicate records. Due to the infrastructural
constraints described above, data were stored locally on the individual iPads in the field rather
than communicated directly to a central server.
The iPads were synchronized twice per day with a main database hosted on the project’s
local Mac mini server. This occurred when the teams returned to the dig house at lunch and at
the end of the day, the same times when new finds and samples were brought in from the field.
After the field data were synced with the server, specialists in the labs could then enter detailed
information about the new small finds, pottery, and environmental samples, and this information
would be available on the iPads after the next sync. The synchronization process that I used
(Wallrodt 2011a; 2011b) is not time-consuming, but it is complex and involves a series of steps
that must be performed in a particular order by the database administrator (see below on the
importance of documentation).
I also updated the SVP’s field photography workflow, moving the captioning process out
into the field in order to avoid the errors from previous years. Excavators and surveyors used
Eye-Fi cards, which are a camera memory card with built-in Wi-Fi. These cards were able to
create their own ad-hoc networks, allowing them to send photos directly to an iPad—no wireless
router or internet needed. Field personnel then added captions and labels to the images’ metadata
48
using the Photosmith app on the iPad (FIG. 1). We used the “title” field for a structured subject
code, while the “caption” field was for standard, plain-text descriptions. When the iPads returned
to the lab, the labeled photos were uploaded to the server and imported into the database, where a
set of scripts parsed the subject code to automatically link each photo with its subject record.
In addition to FileMaker and Photosmith, the SVP used a handful of other iPad apps to
assist with field recording. Several compass, calculator, and ruler apps were used in place of their
more traditional counterparts, and a clinometer app proved particularly useful to the terrace
survey team in measuring the approximate angles of slopes. Field notebooks were written with
Apple’s Pages, which allowed excavators to integrate both drawings and photos into their
accounts (FIG. 2). The project also used several drawing apps, but not in a systematic way.
Supervisors were encouraged to experiment with different apps to find what worked best for
them. We found that the vector drawing app TouchDraw was used most effectively for
annotating and highlighting contexts in photos (FIG. 3) and for keeping running schematic plans
that could easily be added to as the season went on (FIG. 4). Some supervisors drew measured
sections and plans in TouchDraw (FIG. 5). Simpler brush- or pencil-based apps were used
frequently for quick sketches.
We identified numerous benefits to the paperless recording system used in the 2011
season. There was much quicker exchange of information between the field personnel and
specialists; a significant decrease in human error through automation and controlled data entry;
improved consistency of terminology, by using pull-down menus and other structured fields;
increased efficiency and time savings by eliminating the need to scan and digitize paper records;
improved security of field data due to twice-daily syncing and backup; and an increase in the
49
accessibility of information to all staff members, due largely to the fact that records could be
accessed in both the field and the lab, whereas a paper record could be in only one place.
2012 Season
I asked the staff for feedback after the 2011 season. Much to my relief, everyone felt that
the hardware and software themselves worked well. Most of the problems the staff noted were
related to how the project used its technology. My main goal for the 2012 season became to
refine the existing paperless system and make it easier to use. The primary focus was on
streamlining workflows and improving the database’s user interface.
A key premise of the redesign was that field personnel are very busy and need to keep
track of a large number of items and activities. Therefore, any work that could be offloaded onto
the database would cut down on errors and allow the field personnel to focus on excavation and
interpretation. For example, I had the database generate the carefully structured subject codes
that we use to link a photo with its subject record. Instead of consulting a confusing text
document to determine the correct format for labeling a photo, the supervisor simply opened the
record for that subject on the database, tapped a new “camera” button in the lower left corner of
the screen, and was presented with a pop-up that listed exactly what to type into Photosmith’s
“title” field (FIG. 6). Another task that was offloaded onto the database was object labeling.
Every small find, bag of bulk finds, and environmental sample is supposed to be labeled in the
field. Field personnel were traditionally assigned the burden of remembering what information
was necessary for a variety of object types, along with the format for each label. Excavators
inevitably made errors and omissions on their labels and the task was complicated further by the
2011 version of the database, in which inconsistent layouts made it difficult to know exactly
what information needed to go on a label and where that information was located (FIG. 7). To fix
50
this I centered the redesign around new “digital labels,” which are directly analogous to the
physical labels and which gathered all of the basic identifying information into the same place
for each record type (FIG. 8). As in 2011, the excavator would create a record on an iPad when
an object was found or a soil sample was taken (FIG. 9A). They would then label the object by
either writing on the bag or putting a piece of tape on a sample bucket (FIG. 9B). But unlike
before, all they needed to do now was look at the digital record they had just created and write
exactly what they saw on the digital label. Because the find or sample was brought back to the
lab at the same time as the iPads were synced, the project’s specialists could immediately look
up the new items and identify any errors or missing materials (FIG. 9C). Since the labels were
written in a consistent way, it was much easier for the specialists to match the physical labels
with the digital record. After adopting this method, the project has had far fewer mislabeled bags
and orphaned objects. These changes to both photo and object labeling gave the excavators fewer
things to worry about. The risk of “deskilling” here is minimal, since these are skills that few
supervisors were able to master reliably (cf. Ellis this volume).
As these examples show, the design of a user interface can directly impact the
effectiveness and efficiency of associated workflows. User interface design and layout were
considerations in the first version of the database, but my priority had been building a functional
system. The result was aesthetically lackluster. Interface elements were scattered all over. There
was some organization but the design was not consistent or intuitive, which made it harder to
use. I felt that a better user interface would offer more than just aesthetic benefits, so it
underwent a complete redesign for the 2012 season. A comparison of the original and redesigned
versions of several screens illustrates the changes (FIGS. 10–12).
51
In order to produce more cohesive and intuitive user interfaces for the SVP’s 2012 season
and for subsequent databases, I have routinely employed several design principles, of which I
will highlight four. The first is to develop a consistent visual language. This can take many
forms. For example, I used color coding to help differentiate between various data and interface
elements. Each record type has its own color and these colors are consistent throughout the
database. This means that when a user taps on the orange “Contexts” button in the top right of
the home screen, the orange color persists throughout the Contexts screens, just as blue
designates a Small Find and green designates an Environmental Sample (VIDEO 1).
The second principle is to utilize a clear organizational system. The more complex the
database, the more important it is to have a simple and consistent layout, as I have mentioned
above, but also a clear navigational structure. I have dealt with this in two very different ways.
When I began building the SVP’s system in early 2011 I simply copied the old paper system of
registers and records with which I was familiar from previous seasons (cf. Wallrodt this volume),
which resulted in a compartmentalized navigational structure that does not reflect how sites,
trenches, contexts, and finds are related to each other (FIG. 13). When I started working on the
SKAP database in 2014, I wanted to try something different. For SKAP I adopted a linear
navigational structure that mirrored the “real” data hierarchy and relationships (FIG. 14). In this
model the user navigates back and forth along a single “line” of data, drilling down into smaller
analytical units or pulling back out to see larger ones. Both approaches have their pros and cons,
but I think that the latter is better overall and it helps to keep clear the relationships between
different elements in the data structure, as well as the relationship between the data structure and
the physical world.
52
The third principle is simplification. Different actors in the research process often need to
see different information about the same items. When an excavator enters a new small find, all
they need to record is a brief description, a sketch, the object’s location, and their name (FIG.
15A). The finds officer needs to see all of the data recorded by the excavators and needs to enter
much more detailed information, but I keep the field and specialist data visually separated (FIG.
15B). Rather than showing everything to everybody and falling prey to the ever-increasing “data
avalanche” (Huggett 2015a; Kansa 2011: 1–2; Levy 2014), I show each person only what they
need and make clear the respective origins of the different pieces of data.
The final user interface element that I have found helpful is automation. As I mentioned
above, having the database automatically enter information and perform certain tasks frees up
staff to focus on excavation and analysis. In addition to directly entering data (tasks like
numbering new records, linking them to the correct trench or context, or entering the date) I
would include under this heading those automated tasks that do not directly enter data but do
make life easier in other ways, such as the generation of image codes that I discussed earlier.
Another example of this comes from SKAP. When a SKAP supervisor enters or changes an
excavation unit’s datum and trench orientation, she or he is provided with a visual representation
of the trench’s position (VIDEO 2). This information is also displayed on the context screen to
help excavators orient themselves when recording the thickness at various points in the context.
This automated and responsive interface element helps to ensure that elevations are recorded in
the correct location.
53
2013 Season
Due to the success of the redesign, the SVP database has remained largely static since
2012 except for occasional bug fixes. In 2013, however, I began working with the Pompeii
Archaeological Research Project: Porta Stabia, whose seasons always coincided with those of the
SVP. This meant that I would no longer be able to run the SVP’s system during the field season.
Therefore, we needed to find and train my replacement. We were fortunate enough to be
contacted by a Master’s student from Lund University, Luke Aspland, and we also roped in an
SVP alumna, Miriam Rothenberg, now a PhD student at Brown University. I began training
Miriam and Luke by email and Skype in the winter and spring of 2013, and we met for a week of
intensive training in Oberlin, Ohio in early May.
The three of us quickly discovered that a lot of the understanding of how to run the
paperless system existed only in my head, so I decided to create a set of documentation. As I
outlined at the beginning of this paper, when the SVP’s 2011 season began the database was in a
state of semi-completion. The SVP had decided to go paperless only in March 2011 and the dig
season began in early July, so the development and testing process was rather rushed. When
excavation began in early July all of the most critical elements were mostly functional and
mostly stable but I continued to refine, fix, and add numerous elements throughout the season.
Due to the incomplete nature of the system as well as my inexperience in running anything like
it, producing documentation was a much lower priority than producing a fully-featured and
stable recording system. The highly fluid and evolving nature of our procedures and of the
database itself added further barriers to generating documentation. It was not until the middle of
the second season, when the system had reached a point of stability and infrequent changes that
writing a user guide appeared on our radar screens.
54
In hindsight I wish that I had produced such documentation earlier, because it would have
made my job of running the paperless system much less stressful for the first two seasons. The
more elements you add to something—the syncing, the image handling, the various pieces of
hardware and software—the more difficult it becomes to keep it all straight in your head, let
alone to hand off the system to someone else. In addition to a user guide we created several types
of documents that have proven particularly useful. The first were files documenting the syncing
process, which always has been complex (see above). One file was a checklist of all of the steps
involved in syncing the database and notebooks (FIG. 16). The other was a chart covering
everything that can occur while syncing the database, along with what the result is and what
action needs to be taken, if any (FIG. 17). Another set of documents were workflow diagrams.
One workflow presents all the steps for image processing, and was used mainly by the database
administrator and the photographer (FIG. 18). Another chart outlines the steps involved in
recording and processing various object types and samples recovered during excavation (FIG.
19). We found that by creating these workflow diagrams we were better able to communicate to
various staff members how their physical tasks integrated with their database tasks and how their
role—be it field or lab—fit into the workflow as a whole. I made a point of generating similar
documents during the development of the SKAP database, and as a result the system has been
much more manageable in its first season (2015) than the SVP database was in either its first or
second seasons.
Problems and Recommendations
In addition to the discussion above, I would like to offer three recommendations for
improvements to workflows based on observations I have made while working with these three
55
projects. First, proactive communication with all staff members and users of the system is
critical, especially in the first season or two and especially with users who are new to the system.
Many people do not realize that the system can be changed to fit how they work, and they often
do not bring up problems that arise because they do not realize that they can be fixed. Several
times users have assumed that they had to change how they worked to fit the database, which
often results in ad hoc, improper, and inadequate solutions to easily solvable problems. For
example, if a field did not already exist, very often users would type descriptions or additional
information into whatever field they thought was appropriate, rather than asking for a new field.
Another example of an easily solvable problem is the tab order, or the order by which the cursor
moves through fields when the user presses the “tab” key; several times I have found out that an
unexpected tab order—which can be fixed in about 30 seconds—had been slowing down users
for days or weeks before it came to my attention. This was especially troublesome during the
study seasons at PARP:PS (2013–2015), when team members were engaged in the industrialized
task (Caraher 2013 [2015]; this volume) of processing large volumes of materials. I suspect that
this common user behavior—or more accurately, lack of behavior—is a symptom of most
people's experiences with computers and software being a passive one. You don’t get to change
how Microsoft Excel works. Fortunately, this is easy for a developer to remedy by actively
seeking feedback from users. In my experience they quickly learn that the system can be
changed, and before long they will offer suggestions and ask for changes without prompting.
Second, everyone must remember that the database administrator and/or developer is a
member of the excavation team, and a partner in each person’s job. It is important that the
developer understands how each person works and how that fits into the database and the entire
recording process, and it is important that each project member understands how they fit into the
56
process so that tasks or objects do not fall through the cracks (see Holtorf [2002] and Yarrow
[2008] on some interpretive implications of archaeological workflows). Diagrams and flowcharts
are helpful in this but there are a range of ways to accomplish this goal, including building
progress bars and trackers. For example, for SKAP I have built some digital flags that get raised
depending on certain actions: an excavator can check a box if a find needs to be photographed or
examined more closely, triggering a flag that is visible in that find’s parent records (VIDEO 3).
These flags help both excavators and specialists keep track of what objects need further
attention.
Third, there are things that the administrator or developer can do to ensure that the system
will run smoothly no matter who is in charge. As I mentioned above, a user guide is useful for
training field staff and documentation of the inner workings of the system is useful for both
current and future administrators. While paperless systems are effective, they are not yet simple
to run. Furthermore, a description of the recording system’s technical details should be included
with other metadata in any final repository or publication, to aid in the contextualization of the
data that it helped to produce (Atici et al. 2013; Kansa and Kansa 2013). Documentation is thus
essential at all stages of the research process.
I will return for a moment to my first two recommendations, which highlight what I see
as the central place of the database administrator or data manager within a web of team
members. Other contributors to this volume (Caraher, Ellis, and Wallrodt) have touched on the
role of digital technologies within the structures of archaeological projects, but the digital
technologists themselves have been considered only tangentially. We would be wise to confront
more directly and comprehensively how databases and data managers should fit into the broader
communication and social networks of a project (Berggren and Hodder 2003; Frankland and Earl
57
2014; also see Roosevelt et al. 2015 on using technology to facilitate intra-team communication),
but this issue deserves a fuller exploration than can be contained in this chapter.
Many of the problems that I have presented are not unique to paperless projects, but
digital recording systems make you aware of them and force you to confront them much earlier
(for a debate on the perpetual fallibility of archaeologists regardless of recording media, see
Caraher 2013 [2015]; this volume; Ellis this volume). When designing paper forms, for example,
you do not have to be explicit in how the different parts relate to each other. When you design a
relational database, you do have to be explicit in this (see Wallrodt this volume, on joining the
“pieces” of data). The same underlying problems and needs still exist in both cases. However,
with traditional methods you may not realize that you have a deep problem with your data
structure or procedures until it comes time to analyze the data.
The technological landscape has changed in the last five years, yet the early lessons retain
their value as a second generation of paperless projects is born. Early adopters like PARP:PS, the
SVP, E’se’get Archaeology Project (Betts 2012), Chan Chich Archaeological Project (Houk
2012), and Pyla-Koutsopetria Archaeological Project (Fee et al. 2013; Fee this volume) were
converts from paper, and their use of digital recording relied on incremental translations of
existing practices in order to maintain internal consistency. Now, new projects like SKAP and
the Kaymakçi Archaeological Project (Roosevelt et al. 2014) are being conceived as paperless
from the start. This freedom from existing legacy data and procedures has allowed scholars the
flexibility to redesign completely their archaeological workflows and data structures, with
exciting results (Roosevelt et al. 2014; for SKAP, see below and Jackson, Motz, and Brown,
forthcoming). At the same time, the development of commercial or open-source archaeological
software, which previously had focused on data analysis and dissemination, has turned
58
increasingly toward field recording on mobile devices (e.g., ARK [Dufton this volume], Codifi
[Prins et al. 2014], FAIMS [Sobotkova et al. this volume], iDig [Hartzler 2015], OpenDig
[Vincent et al. 2014], and TooWaste [Castro et al. this volume]). Archaeologists now have a
higher number and quality of digital tools to choose from, and I am excited to see what comes
next. Amid the often dizzying pace of technological innovation, I urge that we maintain a goal of
creating digital solutions that play nicely with human team members and with the physical
aspects of fieldwork.
Efficiently Slow Archaeology
Paperless systems are becoming more widespread and they are already revolutionizing
the way archaeological data are collected, managed, and analyzed. However, these developments
have not gone unquestioned (Huggett 2015b; Nakassis 2015). Many of the critiques—in
particular the recent push for “Slow Archaeology” (Caraher 2013 [2015]; this volume)—force us
to consider our reasons for adopting new technology and the benefits that we gain from
employing it, and thus serve a useful role in checking the blind adoption of technology for its
own sake (Ellis this volume).
I agree with many of the arguments extolling the virtues of careful, thoughtful practice,
and I believe that digital recording can promote such practice. I suggest that while some aspects
of field recording do require careful thought and attention, not every recording task is equally
deserving. The focus of “Slow Archaeology” on drawings and notebooks, two distinctly nonrepetitive
activities, supports this implicitly (Caraher 2015b). Much of the time savings found in
paperless systems are gained by eliminating the repetitive tasks inherent in the form-based
recording of a modern “industrialized” (after Caraher) archaeological project, and by centralizing
59
tasks that otherwise would be spread across multiple sheets of paper and notebooks.
Supervisors can spend a surprising amount of time manually numbering stratigraphic units and
small finds, tracking bags of materials from the field to the lab, adding up sherd counts, and
ensuring that any changes to recorded data are updated in all the relevant forms and notebooks.
A computer is able to perform these jobs more quickly and, perhaps more important, more
reliably than a human. Forcing a supervisor to expend considerable energy on these repetitive
tasks can promote their perception of the archaeological remains as a fragmented data set that
consists only of identification codes and quantifications. By shifting much of this burden, the
efficiency of digital recording can help to achieve some of the goals of “Slow Archaeology”
while still meeting the expectations of modern archaeological practices (cf. Caraher 2015b).
At the end of the day, paperless recording is merely a tool and it is up to us to decide how
to use it. The time that excavators save with an efficient paperless system can be used in a
myriad of ways: they can put more time into drawings or produce more of them; they can spend
more time teaching field school students, something that digital systems can both facilitate and
complicate (Bria this volume; Opitz 2015); they can excavate with their own hands, which many
supervisors yearn to do more and which can improve their understanding of a site; and yes, they
can simply gather more data (cf. Caraher 2015a; 2015b; this volume; Ellis this volume; Nakassis
2015; Roosevelt et al. 2015). But these systems also open up exciting possibilities for new
interpretive approaches (e.g., Roosevelt et al. 2015).
For example, during the 2015 season of the Say Kah Archaeological Project we used our
paperless system to include different world views in the recording process (Jackson, Motz, and
Brown, forthcoming). One of the goals of the project is to recognize and decenter the dominance
of modern, western archaeological visions of the material record, in order to make space for
60
Classic Maya understandings of the material world. A digital recording system can seamlessly
switch between different ways of viewing data. This flexibility enabled us to integrate emic
views in the recording process, and to give equal footing both to western, dualist ways of reading
the archaeological record and to indigenous Maya understandings of this material. Our
excavation permit from the Belize Institute of Archaeology and the umbrella project under which
we work, the Programme for Belize Archaeological Project, mandated the submission of
particular forms with the final report. Similar reporting requirements often are cited as a barrier
to the full adoption of digital archaeology in some sectors, but in many cases these can be
overcome easily by creating layouts that replicate the required forms for printing or saving PDFs,
as we did (see Spigelman et al. [this volume] for an example of success within CRM, but cf.
Dufton [this volume] on operating within the constraints set by the City of London). Using a
digital recording system allowed us to meet these recording requirements while also collecting
additional types of data, but without the increased workload and conceptual divide of two
physically separate forms. The efficiency we gained by transitioning to digital recording freed up
time and space for excavators to turn their attention to the additional types of data that we are
collecting; the increased efficiency directly facilitated the addition of these new elements. Our
experience indicates that paperless systems allow for nimble movement between multiple ways
of seeing and recording, a capability that can radically shift our understanding of archaeological
sites and materials even while in the field, allowing interpretive insight to occur simultaneously
with the excavation process and in-field planning and execution.
Conclusion
61
The community of paperless projects has grown quite a bit since 2010, as has the
community of people developing paperless recording systems. This volume is evidence of that
growth. There are now many more resources available to those who are developing apps and
databases for tablets: Apple provides excellent documents like the “iOS Human Interface
Guidelines,” FileMaker has posted videos and a variety of guides, and countless websites offer
resources both for general mobile development and specific to FileMaker. However, the lessons
that we learned in those first few years are still valuable and it is from that perspective that I have
tried to offer some insight into building an effective paperless archaeological recording system.
We as archaeologists should no longer be satisfied with just getting a paperless system to
function successfully, although that is certainly no small feat. We need to continue
experimenting and thinking about how to make these systems work as an integral part of the
research process. It is not enough for developers or administrators to possess technical skills;
they need to have visual design skills and to be able to communicate effectively through the
system. They need to work with specialists and excavators, not be tyrants. Digital recording
systems can streamline fieldwork, improve the quality and quantity of data collected in the field,
significantly reduce errors and misunderstandings, and facilitate new interpretive approaches, but
they require careful and thoughtful preparation and implementation, and I hope our experiences
will help others to implement paperless recording systems successfully.
Acknowledgements
I would like to thank Susan Kane (Sangro Valley Project), Steven Ellis (Pompeii Archaeological
Research Project: Porta Stabia), Sarah Jackson (Say Kah Archaeological Project), and Linda
Brown (Say Kah Archaeological Project), as well as all members of these projects for their
62
support. None of this work would have been possible without them. The opinions and
conclusions expressed here are my own and do not necessarily reflect the opinions of the
research projects or their directors. My final thanks go to the editors of this volume and the
anonymous reviewer for their helpful comments.
63

1.4. Mobilizing the Past at the Athienou Archaeological Project, Cyprus:
A Case Study of DIY Digital Workflows on a Long-term Field School Project1
I. From Paper to Paperless: Lessons from a Quarter Century of Data Recording in the
Malloura Valley
During its first two decades, the Athienou Archaeological Project (AAP, established
1990) developed a robust excavation recording system that closely documented stratigraphic and
artifactual data via integrated paper and paper-to-digital methods. In the trenches at the primary
site of Malloura, paper forms were used to record field notes, while in the lab in the town of
Athienou, the paper-based information was typed into digital data. This system served AAP’s
unique pedagogical and research goals because it utilized a meticulous recording system and
archaeological workflow that were user-friendly for both staff and field-school students, and
provided both quantitative and qualitative information in written, drawn, and photographic form
for all contexts, architecture, samples, and finds. The manual secondary input of paper-based
data into digital formats (e.g., transferring Excavation Unit notebooks into Microsoft Word and
entering field forms into a FoxBASE relational database) further provided the project with a
large, queryable, and complementary (and duplicate) digital dataset.
Yet in 2016, AAP finds itself moving towards a more paperless system, dependant still
upon the same meticulous data recording system, yet now that data is mostly born digital on site.
Today, trench supervisors and students record daily excavation notes, take and annotate images
and videos, and consult project documents and reports on mobile tablet computers. In some
ways, little has changed. AAP’s longstanding recording system and workflows are still there, yet,
1 We would like to thank the anonymous reviewer for constructive and helpful comments on this chapter. These
observations have added to the chapter’s clarity and strengthened our argument. All errors remain our own.
2
the project’s DIY (“do-it yourself”) movement into digital workflows at the advent of mobile
computing devices in the form of Apple iPads betrays quantitative and qualitative changes to the
ways that AAP staff members do archaeology at the trowel’s edge and the conclusions that can
be made about Malloura’s past. The recording medium has begun to affect the nature of
excavation as well as its message.
This chapter explores the contexts, motivations, and decisions that influenced the shift to
on-site mobile computing at AAP, so that other field school projects grappling with the question
of whether and when to “go digital” might learn from AAP’s experiences. Since many scholars
would now claim that “we are all digital archaeologists” or “excavation is digitization” this
seems a particularly pressing methodological transition to examine (Morgan and Eve 2012: 523;
Roosevelt et al. 2015: 325). We discuss how even a modest-sized project without full-time
digital technologists can transition to a DIY, tablet-based, recording system that engages a hybrid
mix of digital and paper-based workflows, and how our experiment impacted our goals of
improved data recording, site interpretation, and teaching new digital skills. Although our
discussions of interpretive improvements mainly derive from the authors’ own reflections, our
pedagogical successes are supported by both written surveys and recorded team conversations
focused on trench supervisor experiences. Based on 25 years of experience with technology in
archaeology, we evaluate the pitfalls and potentials of integrating digital methods into fieldschool-
oriented projects with limited IT infrastructure, specific funding requirements, and unique
pedagogical and research goals.
3
II. Festina Lente: Methodology, Data Recording, and the Role of Technology on the
Athienou Archaeological Project in the Pre-Tablet Era
In this section we contextualize AAP’s methodological focus and data recording
workflow during the first twenty years of research in order to shed light on how and why the
project became an early adopter of tablet-based mobile computing in the trenches.
Through a multidisciplinary project that combines undergraduate field and laboratory
training in archaeological methods (excavation and survey) with research analyses, since 1990
AAP has been investigating long-term culture change in the Malloura Valley of central Cyprus’s
Mesaoria plain. The valley served as a settlement locus for nearly 3000 years, beginning in the
early first millennium B.C.E. and lasting until the Byzantine, Frankish, Venetian, and nineteenth
century C.E. Ottoman period. This long occupation, coupled with the diversity of archaeological
remains encountered (domestic, religious, industrial, and funerary), makes the valley an ideal
training ground in archaeological methodology (Toumazou et al. 2011; Toumazou et al. 2015a)
(Figs. 1 and 2).
More recently, the project has focused on the excavation of a Cypro-Geometric through
Roman-period sanctuary at the site of Malloura (Fig. 3); our excavations have shed new light on
first millennium B.C.E. Cyprus, especially the nature of votive religion in the hinterlands of the
island. Yet Malloura has also proven to be a stratigraphically complex site because it was
frequently looted in the recent past. Thus, because of the site’s archaeological importance and its
complex stratigraphy, an exacting system of on-site data recording has always been a key part of
AAP’s modus operandi. Furthermore, throughout the project’s history, AAP has also emphasized
the archaeological training of undergraduate and graduate students as part of its raison d’être,
and students have travelled to Cyprus to learn the craft of excavation, stratigraphic analysis and
4
description, and in-trench illustration and measurement. As a result, a significant proportion of
AAP staff time is devoted to on-site or classroom instruction while the majority of project funds
are dedicated to student travel, room and board, and educational expenses.
It is within these logistical parameters that AAP has focused on two fundamental goals,
both of which impact project decision making in terms of methods and data recording: achieving
an understanding of the long-term history of the Malloura Valley, and training students in
archaeological field techniques. Improvements in both areas are always desired, especially via
technological means, but they must not compromise the exactitude of archaeological research or
the quality of pedagogy. Festina lente, or “make haste, slowly,” might characterize AAP’s
deliberative process when it comes to the incorporation of technology into its data workflows.
When AAP began in 1990, AAP Director Michael Toumazou developed an approach to
excavation that stressed a meticulous paper-based method of data recording and analysis,
coupled with a secondary input of certain data into digital formats (e.g., fieldnotes were retyped
into a word processing program and data forms, initially in the FoxBASE (now in FileMaker
Pro) database, a program that lacked web-based functionality). As a result, like many projects
(see e.g., Dibble and McPherron 1988; Ancona et al. 1999), AAP actually embraced “digital”
elements in its workflows from an early date in an effort to improve data quality and
manipulation; however, these methods were lab-based and mainly focused on data duplication,
preservation, and rudimentary analysis (querying). For the most part then, AAP developed a data
workflow that was primarily paper-based and unique to the Malloura site, and which has since
permitted interpretation from the macro to micro levels as outlined in AAP’s standardized
Handbook of Excavations (for an overview excavation methods, see Toumazou and Counts
2011: 71-75).
5
In terms of AAP’s site-specific methodology, the Malloura Valley has been mapped onto
a Universal Transverse Mercator (UTM) grid, and areas to be excavated have been divided into a
number of smaller units allowing for precise, controlled excavation. The top-level spatial unit on
the site is the “Excavation Unit” (EU [commonly referred to as the “trench”]; typically ranging
in size from 3x2m to 4x4m), which was followed by “Stratigraphic Unit” (SU [commonly
“locus” or “stratum”) a smaller, defined unit based on features and soils (Fig. 4). SUs in cultural
levels are typically broken down into distinct “Square Meter Units” (SMUs) in order to permit
better horizontal stratigraphic resolution. As excavation progresses from the plowzone to cultural
levels, meters above-sea-level (MASL) elevations are measured from a known datum point using
a dumpy level and stadia rod, and all SUs, finds, architecture, and samples are recorded relative
to precise x, y, z, coordinates.
Traditionally, such locational precision has allowed EU supervisors to record stratigraphy
and finds in an exacting manner using a variety of paper-based forms, hand-drawn sketches and
photographs, and notebooks. SU forms record key data pertaining to the unit’s location,
stratigraphic position/nature (e.g., looters’ pit/stratified), features (walls, hearths etc.), soils,
organic and inorganic remains, ceramics, and objects, as well as references to associated photos
and drawings (Fig. 5); a grid permits easy drawing of the SUs horizontal limits and any features.
SMU forms provide further resolution and also include a gridded drawing that records the
SMU’s architectural features and in-situ artifacts. Object forms connect the field’s data to the lab
by providing an object’s key stratigraphic information, which is then integrated with the
chronological and typological results of lab-based analysis. Photography (initially film-based,
later replaced by digital) and longhand drawing/sketching complement all field data. Finally,
every EU supervisor maintains a detailed field notebook (which was once paper-based, but is
6
now confined to mobile tablet computers) in which they record the full process of excavation and
interpretation so that it can be used for writing a synthetic final report and Harris Matrix.
In general, the AAP’s established system of data recording succeeded in recording
Malloura’s complex stratigraphy, impressive finds, and architecture in a manner that has allowed
graduate student supervisors and undergraduate excavators to internalize excavation skills in a
gradual manner. Yet the general reliance on paper (and even when digitized, duplicate paper
forms remained) in its many formats created logistical and interpretive difficulties in terms of
storage and collating that made long-term management and rapid synthesis for on-site decision
making complex. The time that was consumed in locating forms from a series of binders on-site
(there was no way to access the database at Malloura) inhibited the collating of sheets, and hence
the rapid on-site recognition of certain archaeological relationships. In addition, in the lab, the
time required for the digitizing of paper-based data affected the duration of object analysis and
site-wide stratigraphic synthesis.
To sum up the relationship between methods, data, and technology’s role at AAP, it is
clear that during the project’s first 20 years the goal was to create archaeological workflows that
rigorously recorded Malloura’s ancient past, helped students engage with “hands-on”
archaeological research, and integrated a modicum of computing tools aimed at strengthening
data collating, integration, and analysis. AAP was thus always “tech-friendly” and willing to
entertain changes to its workflow when the technology was affordable and could enhance project
goals. Yet, even though digital tools were employed since its inception, AAP did not progress to
a more paperless stage partly because of the harsh conditions of working on the Malloura site for
eight hours a day in extreme summer heat. The Malloura Valley is sunny, hot, dry, dusty, and
windy, lacks a local power source, and has no internet connection. Laptops were simply not
7
robust enough in terms of battery power and design to stand up to the site’s extreme
environment, and the project’s FileMaker’s database would be of little use remotely without a
web-based interface and internet access. As a result, there was still a digital divide between the
site (entirely paper-based) and the lab (a hybrid between paper and digital). In addition, because
of the recopying of data that was required, lab time that was spent on replicating paper notes
arguably decreased the time reserved for interpretive tasks like drawing and artefact analysis.
Thus, despite AAP’s willingness to engage with technologies that would facilitate data entry and
analysis, technological innovations outside of archaeology would have to occur in order to help
AAP cross the divide that separated digital data recording and analysis in the lab from recording
that took place “at the trowel’s edge.”
III. “We are all digital archaeologists”: AAP and the Advent of “Paperless” Workflows
The decision to adopt paperless, born-digital field recording methods at AAP was based
on AAP’s goals and existing attitude to technology as well as revolutionary changes that had
begun to occur in archaeological computing (see also Levy 2014; Roosevelt et al. 2015: 326). By
the late 2000s, in tandem with the information technology revolution, progress in lowering the
cost of nanotechnology led to the development of relatively cheap, light-weight, touch screenenabled,
internet-ready and camera-equipped, mobile computing devices with long battery lives
(e.g., iPhones). These devices were soon followed by the first tablet computers with the launch
of the Apple iPad in April 2010. Because tablets were portable, user-friendly, and could be
synched to existing databases via web-based apps, archaeologists started to recognize their
ability to integrate tasks into fieldwork that had once only taken place in the lab. Within a year,
Apple iPads had begun to provide archaeologists with durable, portable computing devices that
8
could be used effectively in the field to record excavation data and function as “digital
notebooks.” It was this development that spurred the first attempts at “paperless” excavation
recording workflows, methods that are now becoming ubiquitous on archaeological sites and
that—according to some scholars—are indicative of a greater paradigmatic shift in
archaeological practice (Roosevelt et al. 2015: 339-40).
The first major Mediterranean project to experiment with iPads as portable digital
recording devices in the field was The Pompeii Archaeological Research Project Porta Stabia
(PARP:PS). Steven Ellis and John Wallrodt devised a DIY, mobile data-recording system
wherein trench supervisors were issued iPads equipped with “off-the-shelf” apps that could
record, integrate, and analyze excavated field data and upload it to servers for long-term digital
storage (Pompeii Archaeological Project Porta Stabia 2013; see also the chapters by Wallrodt
and Ellis, this volume). Besides Apple’s built-in iOS applications, like iBooks and Camera, their
original workflow included a database application, FM Touch, a digital drawing app, iDraw, a
word processor app, Pages, and a flowchart app, Omnigraffle, used for creating Harris matrices.
PARP:PS integrated these apps into an on-site digital workflow wherein excavation data were
recorded and stored locally on iPads in Pages and FMTouch and then periodically uploaded to a
server-based database via scripts so that lab-based specialists could access and annotate it in near
real-time.
In the spirit of Web 2.0 data sharing and hacks, Wallrodt reflexively blogged about
PARP:PS’ system on his weblog, Paperless Archaeology (http://paperlessarchaeology.com). In
addition to general observations about the tablets’ user-friendly nature, their durability in the
field, and how much written and photographic data they could record, Wallrodt also provided
instructions as to how to develop a DIY, digital workflow that would require little technical
9
know-how, yield a richer archaeological narrative, be cost effective, and would teach novice
archaeologists digital skills and new ways of manipulating stratigraphic data.
PARP:PS’ pioneering work is important to acknowledge here because it was through
AAP assistant director Jody Gordon’s reading of Wallrodt’s blog, and the DIY-nature of the
system that AAP decided to “go digital.” This process of knowledge sharing and easy
adoption/adaption is also important to note, since it underlines how all archaeology is becoming
“digital archaeology” in the Web 2.0 age (Morgan and Eve 2012; Caraher 2014b; Morgan 2015).
In short, we mean that archaeological methods and practices can now be shaped by digital means
(e.g., even this ebook), and that devices’ and programs’ utility and interoperability open the door
to many ways to address archaeological goals and problems. For most projects, as Steven Ellis
has argued, a “digital filter” is inserted at some stage (Ellis 2015). Thus archaeology’s very
transformation into a “digital” discipline that permits the enhancement of research goals even
within existing logistical limitations influenced AAP’s decision to move towards digital
workflows and provided a “kickstart” to our thinking about digital archaeology’s benefits.
Convinced by the PARP:PS system’s presumed ease-of-use, the next key step in AAP’s
decision to “go digital” involved rationalizing the perceived benefits of converting to digital data
recording (most significantly, born-digital data captured on-site without paper
complements/duplicates) with respect to the project’s goals of understanding the Cypriot past
and training students. If these goals were not satisfied or enhanced via mobile computing, then
changing our successful system would be out of the question. Wallrodt had highlighted many of
the benefits of mobile data recording in Paperless Archaeology; however, since 2011, many
other scholars (e.g., Motz and Carrier 2012; Wallrodt et al. 2013; Prins et al. 2014; Ellis 2015;
Roosevelt et al. 2015) have argued that utilizing tablets and creating born-digital files produces
10
more data, better data with less human error, preserves it in more places, easily integrates it into
existing digital file types, permits immediate intra-site and eventual inter-site analyses via
relational databases, and democratizes data by streamlining it so that it can be easily shared
between team members or even the public through digital archives affiliated with linked open
data or even blogs (Whitcher Kansa et al. 2007: 193-194; Morgan and Eve 2012: 526; Prins et al.
2014: 196; Roosevelt et al. 2015: 342). These digital advantages promised improvements over
the existing paper-based field recording system that might offer better interpretations of
Malloura’s archaeology.
In terms of project logistics, scholars have argued that time is saved by utilizing digitalborn
notes and forms while the relatively low cost of outfitting a project with the basic
components of tablets, a desktop computer with a relational database, a high-end digital camera,
and a series of off-the-shelf—or even open-source—apps (Motz and Carrier 2012: 29; Ellis
2015; Roosevelt et al. 2015: 339; 341; see also Sobotkova et al., and Dufton, this volume) also
makes paperless archaeology practical. Internet connectivity enhances the process, but is not
always required or available. Another logistical benefit is that the technology is user-friendly (at
least for most off-the-shelf tablet-based apps) in that it can be easily taught and implemented by
field supervisors without programming skills (Bria 2016). Likewise, the devices’ usability
encourages projects to recruit staff and students who are inherently technological in their
thinking and training, and through this process, a project’s technological knowledge-base can be
enhanced. Finally, based on these logistical advantages, a move to digital recording for AAP also
seemed to mesh well with the project’s financial and time restraints.
Recent studies have further indicated that the interpretive and pedagogical benefits of
paperless archaeology vary according to a project’s implementation scheme (Bria 2016; Opitz
11
2015). However, when first considering adoption in 2011, the AAP identified several benefits
based on PARP:PS’ experience, which have since been supported by other projects. As
mentioned, the time saved from digitizing paper records permits other research activities as well
as teaching, while the rapid accessibility and searchability of the data beyond the lab and
especially on-site promotes its sharing and interpretive power (cf. Morgan and Eve 2012: 525).
In terms of pedagogy, the on-site entry of field data and the immediate accessibility of existing
project files (which can easily be preloaded) and online databases (with internet access), provides
excavators with new transferable skills, from the ability to use mobile devices and apps (Bria
2016; Opitz 2015), to the ability to multitask with several programs to solve stratigraphic
questions, to the ability to think volumetrically or in terms of wider project workflows (Wallrodt
et al. 2013; Roosevelt et al. 2015: 339). Hence, traditional post excavation activities, such as
intra-site comparisons of materials, can now take place on-site during excavation (Opitz 2015).
Digital workflows with real-time updateable databases also contribute to novel forms of groupthink
integration between excavators, artifact specialists, and IT professionals wherein multiple
team members can offer rapid insights on excavations (Morgan and Eve 2012: 524; Wallrodt et
al. 2013). These interactions are also deemed to contribute to reflexive re-evaluations of the
interpretive value of the workflows as they develop (Berggren et al. 2015). Taken together, these
perceived pedagogical benefits promised to enhance the AAP’s goal of preparing college
students for archaeological careers, which by the 2010s, would require some literacy in on-site
mobile computing.
Yet, before describing how the AAP constructed its digital workflow, it should be
pointed out that the complete abandonment of paper-based excavation recording or uncritical
adoption of new technologies may be accompanied by unforeseen scholarly risks. Some scholars,
12
like Caraher (2015; and this volume), have argued that digitization can result in deskilling, while
others, like Nakassis (2015), have questioned whether the time saved by digital data entry truly
results in better stratigraphic interpretations or engagements with other archaeological tasks (e.g.,
lab-based object analysis). In 2011, however, the perceived benefits of experimenting with
paperless archaeology were great enough that the AAP began to consider how digitizing its onsite
practices might enhance its project goals. As a result, AAP soon decided to follow the
PARP:PS model and to experiment with a DIY digital workflow using Apple iPads.
IV. Crossing the Digital Rubicon: Towards Digital Data Recording at the Trowel’s Edge at
Athienou-Malloura
Having discussed why AAP decided to adopt born-digital workflows in data recording on
site, this section describes how the implementation of a DIY, near-paperless archaeological
workflow successfully enhanced our project’s goals. At present, there are three main ways to
implement digital archaeology: first, the use of fully digital bespoken devices, apps, and systems
(e.g., FAIMS; see Sobotkova et al., this volume); second, fully digital DIY workflow solutions
that leverage proprietary and existing systems and devices (e.g., ARK, see Dufton, this volume);
and third, a combination of the two approaches that also involves some paper (e.g., PIARA, see
Bria, this volume). With limited IT personnel and funding for technology, AAP opted to follow
the third route and to develop a DIY approach using off-the-shelf apps along with paper-based
legacy forms.
In an ideal world where all archaeological projects had unlimited funding and access to
technical equipment and trained support personnel, bespoken digital archaeology systems with
custom-built apps might logically represent the best way to turn paper-based archaeology into
13
paperless. In reality, however, DIY digital workflows that utilize off-the-shelf apps, like those of
PARP:PS, play a key role in democratizing the use of digital archaeologies (Daly and Evans
2006: 5; Morgan and Eve 2012: 527). Recently, William Caraher blogged about the importance
of an “archaeology DIY” that has “its roots in the improvised and ad hoc approach to challenges
in the field, limited resources, and difficulties accessing tools designed for every circumstance
from remote locations” (Caraher 2014a). Overcoming these challenges with DIY solutions is
important because it can assist the further implementation of digital methodologies that can
improve data capture and analysis for a range of project types (see Faniel et al. 2013: 4; Watrall
2011: 171-172). For AAP in particular, the DIY nature of current mobile computing played a
role in the project’s decision to go digital and how our hybrid paper/digital workflow would be
developed. Such a philosophy granted us the “maker space” to assemble a series of devices and
apps that would fit our time restraints and budget, while simultaneously enhancing our research
and teaching goals. Thus, as AAP’s experience outlined below shows, the DIY nature of mobile
computing in archaeology, along with the increasing durability and usability of the devices
themselves, is one of the key factors driving its widespread adoption.
Based on PARP:PS’ successful experiment with paperless archaeology (Pompeii
Archaeological Project Porta Stabia 2013), and AAP’s festina lente approach to technological
integration, AAP decided to beta-test a single iPad 2 (16 GB) during the 2011 season. The field
testing was undertaken by assistant director, Jody Gordon, who had followed PARP:PS’
experiment online (Fig. 6). Since PARP:PS’s system was only a year old and untested elsewhere,
AAP decided to progress cautiously and not abandon its well-tested paper-based methods until
Gordon had tested the technology and developed a protocol that would function on-site and
integrate with the project’s legacy data. Thus, AAP’s paper-based system was retained in 2011,
14
while Gordon—who was not an IT specialist—experimented with a single iPad 2 to test its onsite
usability. The iPad was not used for full-time excavation recording during this trial season,
but rather was used periodically to test its functionality vis-à-vis data recording needs and
Malloura’s harsh conditions.
Gordon equipped the iPad 2 with many of the same off-the-shelf apps used by PARP:PS.
He took field notes in Pages (an especially rapid process with a Bluetooth keyboard), tested
digital drawings (particularly EU plans and vector tracing of objects) using iDraw, drew
flowcharts with Omnigraffle, and utilized Numbers for basic elevation calculations. He also
tested the quality of the still and video digital cameras, as well as the feasibility of annotating
digital imagery. The iBooks app proved to be a useful repository for reference .pdfs from the
Handbook of Excavations to previous trench reports, to baulk and artifact drawings, to scanned
images. These formerly paper-based resources, typically housed in the lab, were now accessible
on site. A database program was not initially tested, however, since our FileMaker database was
not yet web accessible, there was no on-site internet, and we did not have the IT personnel to
monitor daily synching of the database records via USB to the master lab database. Nevertheless,
in terms of the other more standard files generated on site (e.g., .pdfs of the daily notes),
synching the iPads to both the lab registrar’s desktop and a field-based laptop via USB was
straightforward, while cloud-based data transfers in the wi-fi-enabled lab were also successful.
Besides the lack of database functionality, the iPad performed well for all of these tasks, and the
successful file transfers assuaged data-loss and preservation concerns. Files were actually saved
in more places than before and were in digital format should they ever need to be stored in a
permanent and publically accessible digital repository such as Open Context (Kansa and
Whitcher Kansa 2011: 59-61).
15
In terms of overcoming traditional physical issues that had formerly plagued laptops on
site, Gordon tested the ergonomics of touchscreen typing and reading, and subjected the
lightweight iPad to Malloura’s heat, light, and dust conditions intermittently for eight-hour
periods. These “stress” tests were supplemented by functionality experiments employing a USB
wireless keyboard, the use of anti-glare screen protectors, and a relatively heavy-duty Belkin
Folio case, and when the iPad was not in use, it was carefully stored within a backpack in the
shade to protect it from damage and overheating.
These on-site experiments revealed to the AAP leadership the iPad’s overall ability to
contribute to project goals. In terms of positive results, the iPad withstood Malloura’s heat and
dust and maintained its power supply for an entire workday as long as it was charged the night
before. Apps like Pages and Omnigraffle were user-friendly and permitted the incorporation of
text and images, while iBooks allowed for the accessing of reference images and files in a
manner that facilitated intra-site decision making. The iPad’s video camera could record site
tours (which, although the iPad had a weak microphone, provided a completely new and highly
descriptive source of field data), and the tablet’s photographic and written data could be
regularly backed up to a laptop in the field or in the lab. In terms of negative results, some
recording elements were more elusive or ineffectual. Digital drawing was a complicated matter.
iDraw was useful for drawing trench outlines, but sketching finds with shading was more
difficult. Photos taken by the iPad were of a good enough quality to be used for daily notes and
annotations, but they were not of an archival quality, and so a high pixel-rate digital camera still
had to be used. A database app was also not integrated because we at first lacked an IT staff
member to make it web accessible and Malloura lacked internet. Finally, typing on a reflective
16
screen under direct Mediterranean sunlight proved difficult (cf. Fee et al. 2013: 53), and so
recording under a sunshade using a Bluetooth keyboard became a preferred method (Fig. 7).
This DIY combination of programs, accessories, and workflow hacks ultimately proved
that a user-friendly mode of digital archaeological recording using iPad tablets could be achieved
at Malloura—even by non-IT specialists—and that it could provide AAP with more, and likely
better, data, save time, and teach students the basic rudiments of on-site archaeological
computing. From this experimental process, the AAP’s version of a “digital notebook” emerged.
The “paperless” notebook consisted of digital notes, photos, and drawings combined within the
Pages app, and replaced the traditional paper-based EU notebook (Fig. 8). At the same time, Kyo
Koo, an academic technologist, was recruited to make the AAP’s database web-accessible, so
that it could be accessed in the lab—and ideally on site—by utilizing a Wi-Fi equipped mobile
device. Koo migrated the database to a web server and developed a web application through
which our staff could access the database via web browsers on mobile devices (Fig. 9; Koo et al.
2013).
In 2012, based on our successful 2011 beta-test, AAP implemented digital data recording
in the field using iPads as part of its standard procedure (Toumazou et al. 2015b). Newly
released, and relatively affordable (under $600 USD), iPad 3s (32GB) with improved processors
and cameras were issued to each of the four trench supervisors, who would use the devices along
with the traditional database sheets (e.g., SU, SMU, Object) that could not be digitized due to
lack of database access on site. Our immediate goals consisted of introducing supervisors to iPad
use, standardizing our digital workflows via the creation of a protocol, and most importantly, not
losing any data (cf. Berggren et al. 2015: 443). We also recognized that conversion to digital
workflows would be a gradual process that would involve some paper, at least until additional
17
full-time tech staff and funding could be integrated into project logistics. The resulting recording
system might be best described as “hybrid-paperless” because combining both digital and paperbased
recording.
Assistant director Gordon thus wrote a protocol with an introduction to the iPad and with
a discussion of how different apps could incorporate much of our paper-based recording
procedures (for written protocols, see also Motz 2015).
The protocols described both operating system basics, as well as how to multitask
between apps, but, most importantly, outlined the following workflow for the hybrid-paperless
recording system. Upon opening an SU, a supervisor would initiate a paper-based SU sheet that
would be stored in a binder and utilize the worksheet throughout the SU’s excavation to record
stratigraphic and artifactual data. If SMUs were utilized, then SMU sheets would also be used.
Again, these paper sheets were required as our FileMaker database was not available on site, and
their data would be subsequently entered into the database in the lab by the supervisor. Another
paper notebook, specifically designed for artefact and trench sketches (although these could be
photographed later incorporated into the digitized notes) would also be employed because of the
difficulties associated with tablet-based illustration.
Yet apart from these paper-based forms, the overall EU notebook narrative would be born
digital—or “paperless”—and would be recorded into a template in Pages. This narrative would
also incorporate elevations from Numbers as well as annotated photos (of trench features or
artefact sketches), scaled, digitized SU top plans (imported from iDraw) and evolving Harris
matrices outlined in Omnigraffle. Moreover, reference documents that used to be exclusively
paper-based, such as the AAP Handbook of Excavations, the new iPad Protocol, archived
excavation reports, and trench photos and drawings, were accessible in the iPad’s iBooks .pdf
18
repository (see also Fee et al. 2013: 53; Berggren et al. 2015: 443.). When not in use, iPads were
to be stored in Belkin Folio case and then within a backpack in the shade to prevent physical
damage and overheating. At the end of a workday, the paper-based files were deposited within
their respective binders in the lab, while the “digital notebook” was saved as an archival .pdf and
stored on the supervisor’s iPad, on the registrar’s computer’s hard drive, and in the cloud when
supervisors emailed the .pdfs to the registrar who then deposited them on AAP’s Google Drive
account.
As discussed above for born-digital workflows, the AAP workflow provided the
following immediate benefits. Based on our existing budget, the iPads were a relatively cheap
purchase at around $2500 US for four units (and they have been used in all subsequent seasons).
Second, they were user-friendly. No supervisor complained about using the tablet’s apps (aside
from iDraw), and all were able to master the workflow. A typical supervisor response was
similar to the following, “The transition [to digital recording] was fairly easy and the device is
user-friendly, with some idiosyncrasies that need to be learned.” In addition, although IT
personnel would have helped, the entire workflow was DIY and was straightforward enough to
be set up by a non-IT specialist. Third, since supervisors were more used to typing and using
such devices in their daily work at home, voluminous descriptions of on-site work were created
that were now enhanced by photos, photographed sketches, iDraw drawings, and elevations
based on formulas (strengthening calculations). Annotated digital images (shaded with different
colors and with text and arrows) particularly elaborated on the written narrative and enriched its
explanatory power (Fig. 10). Fourth, several supervisors personally communicated that they had
learned new, more integrated, ways of recording using the iPad’s camera and apps, and that they
could work and make decisions faster based on the ability to reference and search previous days’
19
.pdfs as well as previous years’ images and final reports. One supervisor provided the following
testimony:
“Looking back, I would say it caused me to document the excavation more closely,
particularly through photography. It also made me more confident in my decisions about
stratigraphy. Having daily overhead images of the trench gave me time to analyze what
was going on in the trench after the day’s excavation was done which allowed for further
analysis that I would not have had without an iPad.”
Fifth, time (often up to two hours) was also saved since “born-digital” note-taking replaced the
time previously devoted to retyping paper-based notes in the lab, and this time could now be
used for object sketching and other tasks. When asked about whether time was saved, one of our
supervisors stated, “YES! It saved so much time because I didn’t have to be redundant by
copying notes. The app for elevations also saved time by having the machine do the math.”
Sixth, data was preserved in multiple, more sharable, ways beyond simply paper, moving AAP
data closer to its reposition in a permanent digital repository. Thus, digital workflows quickly
began to enhance AAP’s twin goals. First, a larger amount of more descriptive and visual data
was being produced that could be studied in more depth by more people. Second, students were
learning new ways to record and interpret site stratigraphy.
Based on these results, the 2012 season was a success in terms hardware/software utility,
student supervisor learning curve, and data collection and preservation. Thus, during the 2013
excavation season, we attempted to further enhance our digital recording system by establishing
an internet connection at Malloura so that we could search and upload data on site. Our part-time
academic technologist enhanced the FileMaker web app for uploading notes and images so that
we could try to use a battery-powered, 3G, unlocked SIM-card-based wireless router (We3G
brand) with an internet "hotspot" that could be accessed by the iPads. Unfortunately, it soon
became clear that only a 2G wireless signal was available at rural Malloura and that it would be
20
too slow for efficient data recording (cf. Motz and Carrier 2012: 25-26). Thus, SU, SMU, and
Object forms continued to be recorded on paper in the field and then typed digitally in the lab
following traditional practice. Paper also continued to be used for object drawings; yet
supervisors did improve their skills at image annotation in iDraw. For video recording, we
solved an earlier problem of weak iPad microphone receptivity by utilizing a Panasonic
Bluetooth microphone that allowed the speaker to stand twenty meters away from the
videographer and still render clear sound. Following a study season in 2014, during the 2015
excavation season we continued to use our existing hybrid paperless workflow of digital
recording for notes, and paper recording for forms and drawings.
V. Mobile Computing and the Enhancement of Archaeological Interpretation and
Education at AAP
Based on four seasons of experimentation with a hybrid-paperless on-site digital
recording system, this case study of AAP’s digital workflow illustrates that our ability to
progress in terms of our twin goals of better site interpretation and teaching students the
rudiments of archaeological fieldwork has been enhanced. This progress has been possible
because of the many ways that mobile computing on site can enrich overall archaeological
workflows.
A primary argument for engaging in digital archaeology is enhanced data preservation
(Faniel et al. 2013, 3; Berggren et al. 2015: 443; Roosevelt et al. 2015: 325-326). If data will be
lost, then relatively durable paper should not be abandoned. Over three years of tablet-based data
recording at AAP, no files have ever been lost, all are backed up to multiple hard-drives and the
cloud (Google Drive), and no iPads have been broken. We are now preserving our data in more
21
formats and more places than ever before, and the use of archival digital formats like .pdf
prepare it for possible future placement in a long-term digital repository.
The AAP’s experience, like that of PARP:PS (Wallrodt et al. 2013), Gabii (Opitz 2015),
and Pyla-Koutsopetra (PKAP; Fee et al. 2013), has also shown that tablet computers are userfriendly
and their apps easy to learn. Student supervisors are therefore quickly able to use the
devices to capture more information about a trench than was previously possible. More
information is retained because students can often type faster than they can write, and the visual
data provided by the ability to take a photo and rapidly insert it into a descriptive excavation
narrative enriches supervisor descriptions. For example, with regard to the transition from paper
to digital recording, one of our student supervisors remarked that,
“The transition was very easy and the device very much user-friendly. The majority of
functions were easy to pick-up, especially after having used a smart phone. The apps,
especially pages and numbers, were fairly intuitive. iDraw was the only app slightly more
difficult to use.”
Furthermore, although we have not yet been able to implement the stringent data
protocols built into the mobile databases of projects like Sangro Valley (Motz and Carrier 2012:
27) or Kaymakçi Archaeological Project (Roosevelt et al. 2015: 333), our use of Numbers
spreadsheets for recording spatial data has also increased its facility and integrity.
As has proven the case with annotating digital photos on other projects (e.g., Bria 2016;
Berggren et al. 2015: 437-438), the ability to integrate imagery with interpretative note-taking
rapidly has helped our supervisors document and better understand and complex site formation
processes and architectural remains. In particular, iDraw’s photo annotation capabilities
represent increasingly invaluable tool for stratigraphic recording. By allowing supervisors to
mark up trench photographs with visual layers annotated with writing, polygons, and drawings
iDraw has added a new visual dimension to describing excavation processes. For example, if an
22
architectural element like a wall has to be disassembled, each stone can be photographed and
annotated in situ using the iPad and iDraw, and then this cumulative visual data can be inserted
into a narrative describing the excavation (Fig. 11a, 11b). Another instance might be the
annotation of Roman lamp or votive statuary find-spots within a specific trench or the
stratigraphic layers that overlaid Malloura’s main altar (Fig. 12). Such a visual/literal narrative
can enrich a supervisor’s ability to document the excavation process and interpret its results.
Moreover, like the searchable databases used on site by some internet-ready projects, the
iPad’s ability to store archival images and reports has put many years of legacy data at the
supervisors’ fingertips within one portable device. Thus as many projects have noted (Berggren
et al. 2015: 443), this immediate access to information has enhanced AAP excavators’ ability to
access rapidly existing project data, especially in terms of the locations of artifacts (e.g.,
fragments of limestone discovered in multiple trenches), or architecture (e.g., spatial data on the
likely position of the sanctuary’s boundary wall). For example, several looters’ pits at Malloura
are quite large and can be found in EUs that do not share baulks. Through the iPad’s ability to
store vast numbers of .pdfs, a supervisor can easily compare images of pits discovered in nearby
areas, even in previous seasons, that may also be appearing in their own trench. The ability to
make such stratigraphic realizations rapidly on-site can quickly enhance decision-making with
regard to how to excavate an SU. Such a task was previously impossible when paper reports
were confined to binders in the lab.
On the project level, having such information in a digital, searchable format has helped
the directors rapidly synthesize information about where and when the site has been affected by
looting, the design of the Malloura’s Hellenistic-Roman peribolos wall, the make up and use of
the site’s central altar, and the location and nature of Roman activity. Certainly, other tools, like
23
a GIS, could be used to display this data; yet such systems require skilled staff members who
might not be available or affordable. Hence, in the absence of such tools and personnel, the
“digital notebook” has gone a long way in converting AAP’s long-standing meticulous datasets
(i.e., static paper forms) into dynamic and rapidly collated interpretations of Malloura’s past. In
this way, crossing the “digital Rubicon” has helped with the swift production of synthetic site
reports, conference papers, and even recent journal articles (see Toumazou et al. 2015a).
Based on both written surveys and year-end discussions with our trench supervisors, as
well as the experience of assistant director, Jody Gordon, who has recorded at AAP using both
paper-based and digital methods, it is clear that even a hybrid-paperless workflow has led to
progress in our ability to understand Malloura’s past. Yet, this experience has also highlighted
some common problems with digital archaeology “at the trowel’s edge.” The most obvious issue
is that going fully paperless is difficult and must be handled gradually, especially on projects
with legacy data and pre-existing effective workflows. At AAP, for example, the difficulty of
mastering digital drawing (at least on iPads) and maintaining internet connectivity (as well as the
costs associated with full-time IT personnel; Roosevelt et al. 2015: 341) has forced us to retain
paper-based drawing and paper forms, at least until more effective mobile drawing or modeling
programs appear and internet connectivity becomes reliable onsite (for advances in modeling,
see Olson and Placchetti 2015; Counts et al. 2016).
Further problems seem to be related to the hardware itself, which has led to
methodological complexity. A major issue with iPads at Malloura appears to be the reflective
sun glare emitted by the screens that makes typing in the trench extremely difficult (Fig. 13; cf.
Fee et al. 2013: 53; Roosevelt et al. 2015: 334). Moreover, our supervisors (in recorded team
discussions) have complained that the iPads frequently overheat rendering them unusable for
24
approximately 20% of a typical workweek. One supervisor said that it was the most problematic
aspect of mobile computing, “Being able to type on the screen and be in/near the trench was
difficult. Because of the sun, we had to type under the shade tarp, which meant we were not
always in the trench with the students.” Both of these hardware issues affected the devices’
usability and often caused supervisors to have to abandon their trenches so that they could work
under a sunshade; an action that detracts from our pedagogical goal of teaching undergraduates
excavation techniques. Despite these complications, however, none of our supervisors believed
that the time out of the trench was extreme or that we should abandon the use of tablet
computers. Instead, they unanimously argued (in surveys and recorded discussions) that the
tablets’ benefits—especially image annotation, and the ability to multitask and create an
illustrated daily narrative—outweighed hardware issues, permitting them to craft descriptively
richer trench interpretations.
Based on these observations, one of the main benefits of adopting hybrid paperless
workflows has been the enhancement of AAP’s goal of training college students in
archaeological methods. Yet, it should also be pointed out that, unlike projects like Gabii (Opitz
2015), our undergraduate students are not provided with tablets. Instead, like Bria (2016), we
agree with Caraher (2015) that “archaeological skills are grounded in archaeology, not the
attendant technologies relevant (or even vital) to the field” and advocate that undergraduates still
need to learn the basic, paper-based rudiments of archaeological excavation. Hence, although our
undergraduates are often asked to do data entry on their supervisors’ tablets, our field school still
concentrates on providing undergraduates with a thorough training in excavation techniques,
which involve recording daily notes in paper-based journals, and drawing sketches of objects and
trench plans.
25
On the other hand, for our graduate student supervisors, we feel that gaining competence
in technological tools that improve on-site data collection and analysis should now be a key part
of their archaeological training. Furthermore, given the increasing ubiquity of paperless
workflows in archaeology, we feel that such experiences prepare students for future projects
where mobile devices will be standard tools. We also believe that utilizing digital devices helps
students to “think digitally.” By becoming proficient with apps, databases, and devices, we have
found that our graduate students, like the students at PIARA (Bria 2016) or Gabii (Opitz 2015),
gain transferable, technical and critical thinking skills (see also Burdick et al. 132-134) that can
be used for intra-site archaeological analyses and are widely used in careers outside archaeology.
Although most of our supervisors were literate with mobile devices before they used them on
site, one of our supervisors could state that she “learned about how multiple apps can be
successfully utilized to solve problems.” Overall, we feel that such competencies are valuable in
the Information Age, where archaeological careers are in short supply and nearly every
profession requires some ability to organize, analyze and visualize data within a digital
framework.
Lastly, despite the project’s educational successes, this case study of AAP’s experiment
with paperless archaeology also reveals some pedagogical issues. First, some aspects of a borndigital
process take more time for training than a six-week field season allows. As discussed,
digital drawing, relational database creation and management, and data storage maintenance are
three areas that are too difficult to teach supervisors rapidly (although cf. Wallrodt’s creation of
“homework” exercises for supervisors learning app-specific skills on his Paperless Archaeology
blog [https://paperlessarchaeology.com/]). Another issue is that some students do not
immediately grasp how digital recording improves on paper-based tasks. As many projects have
26
argued about communication (Opitz 2015; Motz 2015), students need to be informed of the
entire digital workflow—either through protocols, meetings, or classes—so that they understand
how the digital process enhances archaeological work. A related issue is that some staff
members—especially from the pre-mobile computing generation—resist using the technology,
even as younger students are urged to adopt it (Zubrow 2006: 13; Caraher 2015). Although such
resistance to technological change is common throughout history (for resistance to digital
humanities more recently, see Greetham 2012), such disunity can have an effect on team-based
learning goals as students question the validity of technology adoption and use.
VI. Mobilizing the Future?: Making Haste Slowly with Paperless Archaeology at AAP
“I think that mobile computing (which is obviously a very general term) is and will be an
enormous part of the way we’ll interpret archaeological data in the future. The key is to
avoid the “technology for technology’s sake” approach, which is why pilot projects like
the last few field season are important – to determine what aspects of these new
technologies actually provide a benefit to the discipline.”
Survey Response from An AAP Trench Supervisor
The adoption of a hybrid-paperless on-site workflow at the Athienou Archaeological
Project can be deemed a successful endeavour because it has enhanced our project goals of
understanding the Cypriot past and archaeological education. In addition, it has underlined the
efficacy of DIY digital archaeology. AAP operates within specific logistical parameters with
regard to funding, staffing, and research—parameters developed over 25 years of experience in
Cypriot archaeology—and our experience has shown that, based on a careful decision making
process, certain technologies and workflows can be employed that are both cheap and userfriendly,
and that provide better ways to understand Malloura’s complex stratigraphy.
27
When compared with the experiences of other archaeological projects engaged in
implementing born-digital workflows, it seems that AAP has encountered similar benefits and
problems. One observation is that there are many ways to engage in digital archaeology: from
complete bespoken systems like TooWaste (see Castro et al., this volume) and FAIMS, to fully
digital DIY like KAP and PARP:PS, to mixed DIY systems like PIARA, PKAP, or AAP. It is
also apparent that all methodologies seem to have their pros (e.g., providing students with new
“digital” skills and providing archaeologists with more and better data), as well as their cons
(e.g., possibly de-skilling archaeological practitioners and creating a data “deluge” that still has
to be studied by subjective human interpreters; Bevan 2015). Yet, one thing that is becoming
increasingly clear is that a shift—like the one witnessed at AAP described above—is occurring
in archaeology as the portability, durability, and utility of mobile devices affect archaeological
practices. Projects can choose to engage with this shift or not; however, as the chapters in this
volume illustrate, change is in the air, and it will arguably affect the way students learn and
researchers do archaeology for many years to come.
Given this fluid atmosphere of change, it is important for projects like AAP share their
experiences while learning from others so that best practices can be developed that enhance
paperless archaeology’s power to interpret humanity’s past and guide its future. By comparing its
methods to those of other projects, there are several ways that AAP can improve its engagement
with paperless archaeology. Inexpensive improvements, such as the adoption of blue-tooth/or
Wi-Fi-enabled digital cameras capable of geo-tagging (like the Samsung Galaxy cameras used
by KAP; Roosevelt et al. 2015: 334), might improve the quality of iPad image annotation.
Creating bespoken forms in FileMaker (e.g., Motz and Carrier 2012: 26-27), using a customized
app like PKAP’s “PKapp” (Fee et al. 2013: 51-53) or “Codifi” (Prins et al. 2014: 195-197), or
28
testing an online app like Evernote (Fee et al. 2013: 53; Roosevelt et al. 2015: 335) for recording
excavation narratives might improve the organization and quality of the digital notebook.
Alternatively, future project grant proposals could center on procuring funds for enhancing
AAP’s digital workflow through the creation of a local area (or even relayed) network at
Malloura (cf. Roosevelt et al. 2015: 332-333), the further development of AAP’s web-based
database (Koo et al. 2013), and the development of a holistic plan for long-term, open access,
online data sharing and digital data stewardship (Whitcher Kansa 2007; Morgan and Eve 2012;
Ashley 2015). Overall, based on the AAP’s recent engagements with paperless archaeology, the
prospects for DIY tablet-based digital workflows seem bright across the discipline. As a project
and team, we look forward to improving our workflows in reflexive ways that both intersect with
innovative developments in digital archaeology and enhance our project’s goals.
29

1.5. Enhancing Archaeological Data Collection and Student Learning with a Mobile
Relational Database
Rebecca Bria and Kathryn E. DeTore
This paper reviews the benefits and challenges of using a digital data collection
protocol to teach archaeological methods to university students. In particular, it reflects
on the three seasons during which the Proyecto de Investigación Arqueológico Regional
Ancash (PIARA) taught an archaeological field school in rural Peru using a mobile
relational database and tablet system designed to document, manage, and analyze
excavated data. First, the paper provides a brief introduction to the PIARA research
project and field school at the archaeological site of Hualcayán (highland Ancash, Peru;
Figure 1). Second, the paper reviews the project’s mobile digital database system,
emphasizing how it was used during the field school. Finally, the paper puts forth
evidence suggesting that students who use a digital and relational database can develop
analytical skills that enhance the way they perceive the multiple dimensions of the
archaeological record. In particular, it suggests that students who used the database were
better able to contextualize their empirical observations and more quickly visualize
chronological and spatial relationships between the materials and features at Hualcayán.
The PIARA Archaeological Project and Field School
PIARA began in 2009 as the primary author’s doctoral dissertation research
project at the archaeological site of Hualcayán, and has since grown into a collaborative
80
project and field school involving dozens of archaeologists and students. Hualcayán has
an exceptionally long history: nearly 4000 years of continuous prehistoric occupation
from approximately 2300 BC to at least 1450 AD. The majority of the research at
Hualcayán has focused on changes in ritual practice that occurred with the rise and
decline of a regional religion and political network called Chavín, and the emergence of a
subsequent culture called Recuay (900 BC – 700 AD). In particular, fieldwork has been
centered on the excavation and material analysis of a central platform mound and its
surrounding structures to examine how local people ritually constituted and transformed
their community after Chavín. Complementary field research has been conducted at the
site in pre-Chavín-era temples in the mound, in domestic areas, and in Recuay and post-
Recuay tombs called chullpa and machay. As such, a major focus of PIARA’s
collaborating student and professional scholars has been the bioarchaeological study of
Hualcayán’s human remains, addressing questions related to diet, health, violence, body
modification, and migration.
In 2011 the PIARA project expanded into an archaeological field school in
collaboration with the National University of Ancash (UNASAM) in Huaraz, Peru.
Between 2011 and 2013, PIARA taught eight field school sessions that were four to six
weeks long. Managed by a team of six to ten staff members, each session had from
thirteen to twenty-two students, who came mostly from the United States and the United
Kingdom, totaling 138 international students over three years. We also taught
archaeological methods to 45 Peruvian students, most of whom were from UNASAM or
the Universidad Nacional Mayor de San Marcos in Peru’s capital city of Lima. The field
school focused its student training on excavation methods, total station mapping,
81
bioarchaeology, ceramic analysis and illustration, and basic GIS skills. Each field school
session concluded with a series of student-led research projects that were conducted and
presented in groups of three to five students. These projects were designed around the
students’ analytical interests and were shaped by a set of themes—such as ritual practice
and religious authority, sacred landscapes, community organization and politics, and
social memory—that the students explored during the field school through readings,
lectures, and discussions.
In an effort to both support the project’s research objectives and benefit student
learning, PIARA designed a relational database, which used touchscreen tablet computers
to manage field and laboratory data (Figure 2). The decision to develop a mobile
relational database for PIARA was directly inspired by the pioneering and publicized
work of John Wallrodt and Steven Ellis of the Pompeii Archaeological Research Project:
Porta Stabia (PARP:PS; see chapters by Ellis and Wallrodt, this volume). Although it was
not the first project to incorporate mobile computing or relational databases in the field
(e.g., Spinuzzi 2003; Zubrow 2006), PARP:PS was one of the first to employ the
lightweight and portable iPad tablets to collect their data. Via his Paperless Archaeology
blog (paperlessarchaeology.com), John Wallrodt provided detailed explanations for his
digital data collection and management workflow and generously provided the PARP:PS
Filemaker database as a download. Using the PARP:PS database as a model, we also
designed a relational database for field and laboratory data collection using Filemaker
Pro, which was loaded onto iPad tablets via the mobile Filemaker Go application.
Michael Ashley and his experienced team at the Center for Digital Archaeology
(codifi.org) supported us by generously providing technical and practical advice during
82
the initial phase of development. Overall it took us approximately four months—which
included considerable trial and error as we learned how to use Filemaker—to design a
working version of the field database. It then took another month to design the core
functionality of the laboratory database. However, over the past four years, as the project
matured and as new collaborators joined PIARA, we have regularly added to and
streamlined the database. Therefore, several additional cumulative months of work have
produced the version presented here.
The PIARA Mobile Database
Objectives
After exploring both established and experimental digital workflows for
excavation and artifact analysis, as well as reviewing approaches to digital archaeology
more broadly (e.g., CoDA 2011; Cross, et al. 2003; Ellis and Wallrodt 2011; Evans and
Daly 2006; Kansa, et al. 2011; Wallrodt 2011), we recognized three principle advantages
to developing a customized mobile database system for the PIARA project and field
school.
The first reason we developed the mobile database was to streamline and
systematize the data entry process to improve speed and accuracy (cf. Motz). On the most
basic level, using a digital format to record data would speed our data collection by
eliminating the need to type paper records into a computer at the end of the day or season.
A digital format would also consolidate all related information about a specific record
onto a single digital “page”; that is, we could dynamically add unlimited information to
existing records without the physical limitations of paper (cf. Ellis 2016). Furthermore,
83
by digitizing data as it was collected, we could address, as part of our research design, the
growing need and responsibility to archive archaeological data digitally (Ashley, et al.
2011; McManamon and Kintigh 2010). Beyond these more straightforward benefits of a
digital format, a Filemaker database in particular could standardize our form responses by
presenting value lists as pop-up menu choices (Figure 3). These standardized responses
would minimize student (and crew chief) confusion as they learned the terminology
needed to record archaeological data correctly and according to the PIARA protocol. This
would eliminate the need to memorize or look up the possible responses for a particular
field and instead focus attention on performing the analysis of the archaeological context
or attribute being examined (cf. Motz 2016). More precisely, students could make
comparisons between a pop-up menu’s available responses, and have the proper
terminology available to discuss the archaeological remains with their crew chief.
Because Filemaker allows users to edit these pop-up menus, crew chiefs would also have
the flexibility to add values to the menus in the field as needed—for example, if an
unexpected category of data is discovered. Finally, with Filemaker’s adaptable interface,
we could also add images next to pop-up menus to help users choose an appropriate
response (Figure 3). Overall, we recognized that these standardized value lists and visual
guides would increase data accuracy and minimize the “data cleaning” activities that are
typically needed when analyzing data that are produced by a variety of archaeologists and
students.
Second, we developed a mobile digital database to relationally link data as they
were collected (cf. Wallrodt 2016). A relational database eliminates redundancy because
an infinite number of fields (i.e. attributes) can be linked to a single context or artifact
84
record by designating relationships between the tables that contain these data (Keller
2009). These relationships also make it possible to easily search and sort the range of
visual and textual information that is associated with excavated contexts and artifacts.
Perhaps most importantly, we wanted this searchability and the visibility of relationships
in the data to be available during everyday fieldwork, so that the excavation crew could
make more informed decisions and more robust interpretations. More specifically, by
cross-referencing and linking data in a mobile relational database, we could provide the
excavation team with a comprehensive understanding of the archaeological record that is
not possible by flipping through paper forms attached to a clipboard. As the field school
progressed, we increasingly realized how this functionality enhanced student research
skills, which will be reviewed in greater detail below.
Third, we developed a digital database to associate directly the more objectivelycollected
data, such as photographs, with the more interpretive and subjective data that is
the principal work of archaeologists—that is, context descriptions, artifact attributes,
drawings, and notes. These different types of data and media that pertain to an excavated
context or artifact are traditionally kept in separate locations: forms and drawings in a
clipboard, photographs in a camera, notes in a notebook, and attributes in a spreadsheet.
By combining the capabilities of a mobile tablet—a device capable of creating,
manipulating, and viewing these diverse data and media types—with the relational nature
and clear interface of a Filemaker database, we would be able to consolidate and integrate
these data in ways that would be impossible with paper methods. More precisely, we
sought to design a tool for crew chiefs and students to easily document and review their
findings quickly and with a high level of visual detail (for example, by allowing image
85
and text data to be created, sorted, searched, and viewed in multiple formats), and also
help them better understand and recognize relationships between excavated contexts and
their artifacts (for example, by linking all photographs, drawings, and descriptive
attributes of excavated contexts in a relational manner). By integrating these diverse
visual and textual data in a relational database, we also sought to break down the
interpretive boundaries between these diverse media and their archaeological discourses
(Shanks 1997:99).
From Design to Implementation
Because Hualcayán lies in a rural area of the Andes with frequent power outages
and unreliable internet, we encountered some difficulties and limitations when
implementing a mobile database system at the site. Although inconvenient at times,
power outages posed only a minimal problem except in extreme cases, mainly because
the iPads (generations two and three) had a relatively long battery life of about 10
hours—which could be used conservatively in order to last two full workdays if needed.
All seven iPads (increased from five in 2012) were charged daily, making it rare that an
iPad did not have power if an outage occurred. In designing the database’s operational
protocols, however, the lack of a 3G or greater internet signal at Hualcayán posed the
greatest limitation. Without internet, it was impossible to link data across iPad devices in
real-time. We explored the idea of broadcasting a local Wi-Fi network as a substitute, but
the mountainous terrain, and the vast distance between the field house and the different
excavation units (called “operations” by the PIARA team and in the database) made such
a system impractical for our budget. Therefore, we found it necessary to create separate
86
database files for each excavation unit, which were loaded onto individual iPads and
managed by each unit’s crew chief, who worked with a team of approximately four
students at a time (see also Motz 2016). This system worked very well for us, with the
only additional limitation being that artifact analyses had to be conducted on separate
database files in the laboratory and then linked to the excavation databases at a later date.
An unforeseen benefit to keeping these database files separate was that their sizes stayed
manageable and any corruption in one database—which happened occasionally if files
were improperly closed—did not affect the entire dataset. Backups were made
approximately twice per week with little data loss over three years. A designated staff
member throughout the season managed these backups, and a single charging station
ensured that iPads would be both backed up and charged each night. The authors
conducted introductory workshops with students and crew chiefs at the beginning of the
field school, and then the crew chiefs worked closely with the students on a daily basis to
record their finding in the field and laboratory, rotating the various data entry
responsibilities throughout the week.
Several linked forms constitute the PIARA field database, which are accessed
primarily via a series of blue buttons at the top of the main layout, which turn green when
selected. First, all the general information for each excavation unit, such as its location,
size, grid layout, dates of excavation, general photographs, Harris Matrix, crew chiefs,
drawings, and overall interpretations, is entered into the “Operation” (i.e. unit) form
(Figure 4). The “Contexts” form, however, is the central hub for recording and viewing
excavation data (Figure 5). Contexts were our central unit of analysis: a context number
was assigned to any soil or architectural feature, such as a fill, floor, ash lens, or wall
87
section. Thus, all excavated materials (e.g., artifacts, carbon samples, and human
remains) were linked to unique context numbers in a one-to-many relationship—that is,
context records were entered only once, and all excavated data was associated with one
of these context records through linked tables (Figure 6). The remaining buttons to the
right of “Contexts” navigate to forms where these linked data can be entered and viewed.
In particular, these forms provide space to inventory and describe the different types of
artifacts and materials recovered during excavation, including our “General Collections”
(i.e. all materials collected in bulk), “Special Artifacts” (i.e. highly diagnostic or unique
materials collected individually), Carbon Samples (carbon for C14 dating), and “Human
Remains.” Two additional buttons, “Photo Registry” and “Digital Media,” provide areas
to record the photographs and drawings or videos of the unit’s contexts, respectively.
Finally, the database provides areas for excavators to monitor and visualize their
progress. First, a “Daily Log” button navigates to a field diary where excavators can add
general notes about each day’s activities along with photos and videos that visually
document the excavation’s progress (Figure 7) In the daily log and in context
descriptions, students and crew chiefs would precede their notes with their initials in
order to preserve their authorship and to capture multiple perspectives in the trench. In
addition, a context completion checklist ensures that all required activities, such as
inventorying artifact bags or taking photographs, elevations, and soil samples, are
complete before beginning a new context. Conditional formatting changes from red to
green on the Contexts form when this checklist is completed, which provides an easy way
for crews to check the status of their work (Figure 8; cf. Motz 2016). Also, a simplified
matrix form provides space where archaeologists can enter the associated contexts that
88
are earlier, later, and equal to (i.e. same as) a particular context being recorded (Figure 9).
Upon entry, the database will display the linked brief descriptions of those associated
contexts, which helps excavators remember what features the contexts numbers represent.
In so doing, excavators can better visualize, at a glance, how different contexts are related
in the matrix. Excavators then use these simplified matrix guides to construct a master
Harris Matrix for the unit as they excavate, using the flowchart application Omnigraffle.
The database is designed such that the excavation data can be entered and viewed
in several layouts and locations (Figure 10). For example, within the Special Artifacts
table, all ceramic artifacts can be isolated and also sorted by their location in the grid (i.e.
their Suboperation). Sorting the data in this way allows users to examine vertical and
horizontal relationships between artifacts of a particular type. In addition to viewing these
data in aggregate as tables, records can be viewed individually, which is the preferred
layout when users first add the artifact to the database or if they wish to view photographs
of artifacts already entered. To make it easier to isolate the materials of a particular
context, we also displayed artifact registries as tables on the Contexts form, linking
individual artifacts to the specific context records in which they were recovered. These
linked artifact registries are accessed in a series of tabs visible on the Contexts form,
where they can be edited as well as viewed (Figure 11). This built-in redundancy adds a
high level of flexibility to how data are entered, viewed, and sorted. It also makes it
possible to quickly view relationships between a variety of data types and with just a few
clicks on the digital touchscreen.
We used a variety of applications on the tablets to create digital plan and profile
drawings, sketches, and annotated photographs that were then imported into the
89
Filemaker database. We primarily used iDraw to create scaled drawings on the iPad,
which has precision drawing capabilities and can manipulate textual, photographic, and
vector data in distinct layers. Scaled digital drawings were often time-consuming to
complete, however, especially for students unfamiliar with both archaeological mapping
and vector drawing (cf. Gordon et al. 2016; Ellis 2016). To speed the process of making
plan maps, we simply created “scaled sketches”—or sketches drawn on a premade grid
that corresponded to the 1x1 m suboperation nails placed in the excavation unit—to
locate contexts in space. Because each context was precisely recorded with a total station
and photographed for georeferencing in GIS, these scaled sketches provided enough
accuracy to visualize spatial relationships in the field (Figure 12).
We also used iDraw to produce annotated photographs for in-field visualization.
Each context was photographed at an oblique angle, outlined and labeled, and then
imported into the context’s record in the database. This technique, while simple, proved
critical for interpreting contexts that were difficult to visualize using two-dimensional
drawings, such as juxtaposed construction events in the ceremonial mound. For example,
“singular” construction events, such as the placement of fill, were rarely executed by
placing a uniform layer of soil and stone. Instead, the ancient builders laid distinct soils
and stones in different areas to fill the platform. To carefully understand this process of
construction, and to avoid mixing artifacts from discrete activities, we assigned each
distinct soil its own context (Figure 13). These annotated photographs became essential
to how teams maintained clarity and control over provenience and stratigraphy as they
excavated. They also helped the author decode the sometimes awkward context
90
descriptions made by students and staff long after the season ended (cf. Gordon et al.
2016).
We also used the text annotation features of iDraw and the application Photogene
to swiftly apply labels to individual artifacts and human remains on photographs. These
text labels were particularly useful for recording small and commingled remains where a
measured drawing at each stage of recovery would have been impractical (Figure 14). In
these situations, we only created scaled drawings of the top and bottom of the context and
used annotated photographs to document the location of the small remains as we
collected them. By recording finds in this way—at each level and stage of recovery—we
could then reconstruct their depositional sequences by simply sequencing the images.
Moreover, these annotated photographs were often visually clearer than abstract twodimensional
drawings. They were also far easier to produce, which minimized
differences in students’ drawing abilities. That is, while all students learned to create
scale drawings, only some were particularly adept drawers. Virtually all students could
quickly and accurately create text annotations, however, which maintained the data’s
precision yet ensured that everyone got regular practice recording their observations
visually. Moreover, these acts of photographing and annotating were instructional
moments in which students could reflect upon their role in representing and constructing
a narrative of the past (Shanks 1997; Shanks and Svabo 2013).
The PIARA field database is complemented by a laboratory database for artifact
attribute analysis. Without an internet or Wi-Fi connection at Hualcayán, this laboratory
database remained separate from the field database so that both field and laboratory work
could be advanced simultaneously. Nonetheless, Filemaker’s capabilities make it fairly
91
simple to link these databases by cross-referencing unique context and artifact bag
numbers at the end of the field season. The artifact analysis database uses similar
elements as the field database, including fields for photographs and drawings, analysis
guides, and pop-up menus to aid both students and professionals in completing the
analysis with precision. We also found that by accompanying an artifact’s attributes with
a variety of visual fields for its photograph in situ, its photograph after cleaning, and its
illustration—instructors can not only monitor any inventory issues that arise during the
artifact’s processing (e.g., the mixing of bag tags after washing), but also they can check
a student’s analysis for errors or consistency in attributes such as form, decoration, and
estimated period (Figures 15 and 16).
In sum, the mobile tablet and the relational database enhanced how the PIARA
team recorded and interpreted the archaeological record because it: (1) linked all data to
excavated contexts in a one-to-many relationship, (2) provided multiple ways to view,
sort, and enter the data, and (3) incorporated a high quantity of digital drawings and
annotated photographs. The systematic, visual, and relational nature of the database also
made it possible for new crew chiefs and students to quickly familiarize themselves with
previously excavated data by simply scrolling through the existing context records while
examining the unit in the field—something that is near impossible to do in a short amount
of time while flipping through paper forms. In fact, the high visual content and relational
links of the PIARA database proved essential to how we maintained consistency in our
excavations, particularly in the units that were excavated by different teams over the
course of two or three years.
92
Enhancing Student Learning in Archaeology with a Mobile Database
Archaeologists have widely recognized that the digital recording of data on
mobile tablets improves productivity and precision. Yet beyond these virtues, PIARA’s
experience using relational databases with high visual content on mobile tablets suggests
that these technologies are much more than a means for efficient and precise data
collection in archaeology. Rather, they also increase critical thinking and analytical skills,
particularly for students who are first learning archaeological research methods (see also
Gordon et al 2016; Stewart and Johnson 2011). These dual benefits—efficiency and
analytical thinking—reflect the debate over whether digital technologies simply aid in
productivity or whether they alter the way we think. For example, there are debates over
whether Geographic Information Systems is a tool or a “science” that gives researchers a
new spatial awareness and analytical sensitivity (Hall 2014; Reitsma 2013; Wright, et al.
1997). More broadly, scholars have debated the degree to which digital technologies are
changing human analytical abilities (Bennett, et al. 2008; Prensky 2009; see also chapters
by Caraher, Ellis, and Motz, this volume) Regardless, most scholars agree that digital
technologies, such as relational databases, are more than simply tools for efficiency—
they are tools for thought (Shaffer and Clinton 2006)—and therefore we should at least
consider the ways that digital technologies might bolster (or hinder) the process of
learning and doing research (Zubrow 2006).
In our experience, the mobile database enhanced our students’ understanding of
the material and spatial relationships in the archaeological record because it allowed for
“computational thinking” throughout all phases of data collection and analysis. Broadly
defined, computational thinking is the process by which relationships between complex,
93
abstract, or large sets of data can be analyzed and visualized using the analytical
concepts, software, and/or hardware of computers (Wing 2008). Since personal
computers became commonplace in university settings decades ago, archaeologists have
regularly employed relational databases and other computational tools to organize,
analyze, and visualize their data (e.g, Reilly 1989). Yet only recently have they used
mobile tablets as part of an in-field data collection strategy for excavations (e.g., Austin
2014; Berggren, et al. 2015; DeTore and Bria 2012; Ellis and Wallrodt 2012; Fee, et al.
2013; Houk 2012; Pettegrew 2012; Roosevelt, et al. 2015; Sharp and Litschi 2014;
Tripcevich and Wernke 2010; Vincent, et al. 2013). Still, although scholars have explored
the effectiveness of using digital archives and 3D simulations in university classrooms
(e.g., Agbe-Davies, et al. 2014), few have discussed how mobile databases can be used to
enhance student learning and research skills in the field (e.g., Stewart and Johnson 2011).
A detailed account of the field school’s final student projects illustrates how the
PIARA relational database and mobile tablet system enhanced student learning. During
the field school, a student’s abilities to conduct research and think critically were most
clearly revealed as they completed their final research projects. For this final project, the
students collected, analyzed, researched, and presented the analysis of excavated remains.
All of these stages of the final project were conducted on the PIARA iPads: relevant
databases were loaded in Filemaker Go for students to edit and reference, pdf resources
were made available in iBooks for students to perform literature reviews, and the students
prepared their presentations in Keynote. At the end of the project, groups presented their
findings by plugging their iPad directly into a projector. Students were required to
contextualize their findings within the culture history of the region and site, and then
94
interpret the results within a theoretical framework to draw out the broader impacts of
their original research. For example, students could have chosen to examine changes in
the social dynamics of feasting by looking at trends in the forms, designs, and
distributions of ceramic vessels through time, either in a particular excavation area or
between discrete structures. Or they could have tested whether periods of known
community reorganization were associated with changes in labor-related stress by
analyzing patterns of degeneration on human vertebra from tombs at Hualcayán.
Students were encouraged, but not required, to use the database as an analysis tool
as they conducted their final research projects. With each year of fieldwork, the
database’s usefulness as an analytical tool increased as the project’s data expanded.
Therefore, by examining and comparing students’ use of the database in their final
research projects between 2011 and 2013, and also by comparing the student projects that
incorporated the database to projects by students who only examined and discussed the
data they had themselves recorded in the laboratory (e.g., ceramic attribute analysis from
a particular context), we could gauge how well the students could research, understand,
and contextualize their data. We assessed the students by evaluating whether they were
making first, second, and third order relations in the data. First, were the students linking
the different associated materials of a particular context? Second, were they making
connections between the materials or conditions in different contexts of the same unit?
And third, were they recognizing similar patterning across the site (between units)? We
also evaluated whether and how the students forged links between the data they had
collected and the data collected before they arrived to the project.
95
We consistently found that the students who used the PIARA database excelled in
all these dimensions of comprehension. In particular, students who used the database
were more able to identify links between discrete contexts and data types than the groups
who relied on less formal observations of unit and site-wide patterns, such as those
gained through everyday excavation experience, discussions with instructors, and
lectures. Similarly, students who used the database produced more substantive and
empirically supported conclusions than those who simply analyzed a discrete dataset
without contextualizing these data. Finally, comparisons between the final projects
revealed how students who used the database began to think in a relational manner about
the data they were analyzing and presenting.
A few examples illustrate how the relational database enhanced students’ research
skills during their final projects. In the first example, two groups, one in the 2012 field
season and another in 2013, performed attribute analysis on a sample of ceramics from
excavation unit Operation 7. Broadly, the research objective for each group was to
identify and examine the activities of Recuay feasting within a particular structure. While
both groups used the database to enter and organize their ceramic attribute data, the 2013
group also used the database to select an appropriate sample for their project, and then to
compare their ceramic data to other excavated materials. Although both groups produced
valid results, there were marked differences in how the students both approached and
summarized their data.
In particular, the 2012 group became interested in their final project—Recuay
feasting in Operation 7—after their excavations in the unit revealed a context with
extensive burning, ceramics, and animal bones. To examine the hypothesis that feasting
96
occurred in this space, they performed an attribute analysis of approximately 40
decorated diagnostic ceramics from the context, primarily to identify ratios of serving and
cooking vessels and the prevalence of decorative styles. They grouped the ceramics by
vessel form, and also compared the decorative styles from the context to documented
types. Given the high percentages of finely decorated serving wares in this context, they
concluded that their analysis indicated feasting, and to further contextualize their
findings, the group discussed their own observations, which were made during their
excavations of burned areas and refuse scatters in Operation 7.
In contrast, the 2013 student group began their research by identifying an
appropriate sample to analyze with the database. Choosing to begin the research by
exploring the database was in part because the excavation of several units, including
Operation 7, was not continued in 2013 (instead, the 2013 students gained excavation
experience in mortuary contexts). Thus, starting with a broad interest in examining
Recuay feasting, the students first explored the database by performing simple sorts and
queries to reveal differences between contexts, particularly in the quantities and
distributions of decorated vessels. These functions not only identified which contexts had
a high probability of ritualized consumption activity, but the sorting of ceramic styles
also provided an estimated terminus post quem or terminus ante quem—that is, the latest
and earliest possible period to which a context can date—for particular structures and
layers. In addition to exploring the distributions of ceramic styles and forms, the
functions were used to explore the relative quantities of faunal and lithic remains from
these contexts. Even though formal analyses had yet to be conducted on these materials,
inventories and preliminary counts and weights provided a general indicator for potential
97
food preparation and consumption activities associated with these materials. The students
used these data to choose an appropriate sample that had a high quantity of decorated
ceramics, as well as high quantities of faunal and lithic remains. Once an appropriate
sample of ceramics was chosen, the students completed their attribute analysis. By
combining their results with the estimated quantities and types of associated faunal and
lithic artifacts from the analyzed context, the students were able to push their analysis
beyond a descriptive presentation of form types and styles in their final presentations.
That is, in addition to presenting their findings from ceramic attribute analysis, they were
able to explore how the ceramics formed part of a feasting assemblage. In particular,
they postulated that serving vessels, such as decorated bowls, were highly associated with
the bones of large animals, which pointed to the probable consumption of camelid meat.
They also associated these finds with the presence of lithics, such as cores, flakes, and
hammerstones, which suggested that food was likely prepared in the same space as
consumption activities. Finally, by comparing the soil descriptions (i.e. presence/absence
of ash and burned earth) in different areas of the structure, and by reviewing which
suboperations in Operation 7 contained the identified artifact assemblage, they also
proposed that the feast likely extended across most of the structure’s interior.
Although the students were aware that their results were preliminary, the
members of the 2013 group expressed how the database gave them insight into how
archaeologists draw together multiple lines of evidence to contextualize and substantiate
their findings. Furthermore, the 2013 example shows how the database made it easier for
the students to visualize and understand contexts that they did not excavate and to explore
the project data on their own. Although the students used the field inventories and special
98
artifact registries that were created during excavations, rather than data from formal
analysis (which had yet to be completed by specialists), they were able to gain key
insights into how various materials constituted the feasting assemblage. The students
demonstrated how using a relational database allowed them to identify preliminary yet
valid associations between discrete datasets that archaeologists traditionally take weeks
(or even months) to identify, particularly when having to read through notebooks, review
sketches, and wait for specialists to complete their material analyses before these
preliminary associations can be made. Moreover, by adding to and analyzing data from
the project’s database, as opposed to completing a fabricated workshop exercise, both
groups recognized that they were producing results that, even in a small way, contributed
to the advancement of the research project overall. Several students returned to
Hualcayán to complete undergraduate and graduate theses to expand upon their field
school projects. For example, one student from the 2013 group used her group’s findings
to prepare a grant proposal to return to Hualcayán and conduct undergraduate thesis
research on Recuay feasting (McAllister 2015).
Students training in bioarchaeological field methods employed the database in
other ways to enhance their final projects. First, because we photographed, identified, and
sided human skeletal remains in the field as they were recovered from comingled burials,
analyses such as minimum number of individuals could be immediately estimated by
sorting and counting how many specimens existed for a particular bone element and side.
Other rapid preliminary analyses included determining sex and age ratios or evidence for
trauma. Student groups would use the sorting results to narrow the topic of their final
research project according to what datasets might produce both interesting and relevant
99
results. For example, if a group of students was interested in examining questions related
to violent trauma, and the preliminary sorting of the data suggested there were no
juveniles or females present in a sample, then a study of how trauma rates differed by age
group or sex was eliminated as a productive focus of the research project. Though similar
preliminary analyses could be performed in an Excel spreadsheet, the database made it
possible to easily relate their bioarchaeological findings to other data such as tomb
location, associated artifacts, and stratigraphic levels. They were also able to compare
human skeletal assemblages between different tombs at the site. This made the database a
superior tool for accessing and processing large sets of data in short amounts of time
(Figure 17). Furthermore, the execution of sorting and querying tasks is less tedious with
a database that can be explored by students on their own, via a single application, and on
a tablet that can be passed around. In several cases, field school students were encouraged
to present their exceptional bioarchaeological work from these final projects at
professional conferences, which they co-authored with PIARA supervisors (e.g.,
Calabria, et al. 2014).
These examples reveal how the relational database provided a powerful and
immediate analysis tool for students. They reveal how, by creating relational connections
between discrete datasets such as excavation forms, inventories, and previously analyzed
data, the database helped students not only collect, but also contextualize their data in the
laboratory. Moreover, the examples reveal how the database allowed students to quickly
explore patterns in the data as a preliminary step, rather than end product, of their
research project. Without the relational database, the exploration of initial patterns in the
100
data may have constituted the entire final project’s analysis rather than form the
foundation of more complex research questions.
Conclusions
In sum, PIARA’s use of digital technology not only aided the archaeological
project’s in-field and laboratory data collection procedures, analyses, and interpretations,
but it also advanced the analytical abilities of our student archaeologists. The PIARA
example illustrates how using a mobile tablet equipped with relational databases,
readings, and a variety of programs to collect and illustrate findings—in our case, an iPad
with Filemaker Go, iBooks, iDraw/Photogene, and Keynote—can provide students with
an all-in-one powerful and collaborative tool to collect, prepare, and present research.
PIARA’s experience also suggests that when students use a mobile relational database,
their ability to recognize and interpret complex relationships between archaeological
materials, contexts, and features is enhanced because the database allows them to
examine broad patterns in the data with relative ease.
Future expansions of our mobile data collection and student instruction protocols
will focus on incorporating mobile GIS and Photogrammetry into our workflow (cf.
Berggren, et al. 2015; Roosevelt, et al. 2015; Tripcevich and Wernke 2010). Recently, we
began to create 3D photogrammetric models of excavated architecture at Hualcayán (e.g.,
Figure 18). In the future, these models—which are more expedient, precise, and less
abstract than polygons produced with a total station or outlines drawn on photographs—
will be produced for each excavation context. Furthermore, because photogrammetry is
becoming a common and essential tool for archaeological research, students will also
101
learn how to process and use these models. As part of our workflow, the
photogrammetric models will be loaded onto the iPads once they are created, and be used
as analytical guides for students and crew members as they excavate, as they
contextualize their analyses in the laboratory, and as they tour the archaeological site for
the first time. We will also use these 3D models to bring Hualcayán’s ancient past to life
for local schoolchildren during educational workshops. To this end, and in an effort to
involve local children in the preservation and representation of their community’s
heritage (cf. Bria and Cruzado 2015), we have begun to teach high school children how
to photograph and produce photogrammetry models of reconstructed artifacts from
Hualcayán (see also Sayre, this volume). Finally, other future directions will seek to
incorporate data from multiple sites in highland Ancash into a regional database (cf. Gero
2006), with a focus on creating a pedagogical tool for Peruvian and international
students.
As technology continues to change and students become researchers, the
computational tools currently available will change in directions that are difficult to fully
anticipate. Tools such as relational databases make it notably easier to explore and
interpret larger data sets. The way PIARA students were able to explore the project
database may be, in part, tied to their generation’s collective immersion in digital
technologies (Palfrey and Gasser 2013). For the current generation of college students,
the mining of digital data has always been a common exercise, for example, when surfing
the internet or searching a library database. Nonetheless, while skills in the manipulation
of “big data” may be more intuitive for the current generation of students, there is an
increased need for students to understand how relational databases are constructed, in
102
order to be data producers rather than mere data consumers. Although relational
databases have long been essential to archaeology, it may be increasingly important for
archaeological instruction, in field schools and graduate-level coursework, to incorporate
a database design component.
Still, approaches to data recording and analysis are highly varied between
researchers across the globe, and instructors cannot predict the kinds of projects students
will assist on or lead in the future. Therefore, instructors may consider teaching students
how to be resourceful in low-tech (and low-budget) environments by ensuring
competency in “traditional” as well as digital methods. After all, archaeology can be done
with a few rudimentary tools. Yet as technology continues to change and expand, there is
a growing need for archaeological field schools to teach the foundations of digital data
collection, management, and analysis. By intentionally incorporating digital approaches
into student training, instructors can actively prepare students to participate in the current
and coming digital era of social science and humanities research.
Acknowledgements
We sincerely thank the Mobilizing the Past workshop organizers for their
invitation to participate, and to all workshop participants for their insights and feedback
on the PIARA database project. Michael Ashley and the Center for Digital Archaeology
selflessly and enthusiastically gave us their time and advice throughout the project. Beth
Grávalos and Elizabeth Cruzado Carranza also contributed considerable time to the
development of the laboratory databases, and Emily Sharp assisted in the design of the
human remains database form. Thanks are also due Anna Guengerich, Steve Kosiba, this
103
volume’s editors, and anonymous reviewers for their helpful feedback during the
preparation of this paper. Final thanks go to the many PIARA students, crew chiefs, and
other collaborators who patiently worked with us as we improved the database each year.
Final appreciation goes to the community of Hualcayán, who have warmly hosted the
PIARA project in recent years.

1.6. Digital Archaeology in the Rural Andes: Problems and Prospects
Matthew Sayre
Introduction
The prospects for digital archaeology are exciting and they can broaden our sense of
community archaeology. The opportunity to expose new generations of students and community
members to the stirring analytical possibilities that digital archaeology can provide opens up new
areas for dialogue. As technology changes rapidly, and we train new generations of students who
have never had the experience of using a film camera, we must be aware that this can lead them
to assume that slow archaeology or paper recording are simply antiquated. However,
archaeologists, of all people, should realize that older technologies often continue to be useful. In
this chapter I attempt to present and investigate these issues in an accessible manner. The two
major issues addressed are the process of implementing digital recording methods and our
project’s effort to engage in a community focused effort to decolonize digital archaeology.
I initially describe the attempts of the archaeological project at Chavín de Huántar in Peru
to move fully into digital recording of archaeological data (for similar topics see Ellis, Motz, and
Wernke et al. in this volume). There were pragmatic and theoretical difficulties in our attempts
to transition into a digital program. The pragmatic and theoretical concerns did overlap and some
of the theoretical difficulties could also be regarded as ethical issues.
Many of the problems that our project experienced in converting to digital recording
methods were related to the particulars of the site. As will be described below there are distinct
concerns that arise working in a rural setting in the developing world, many of these issues
would not emerge in the same way if our project were situated near an urban center in the “First
117
World.” While many of these issues arise due to economic inequality there are also issues about
who gets to use advanced technology and how archaeologists can decolonize the acquisition and
processing of data.
The Project at Chavín de Huántar, Peru
Chavín de Huántar is a UNESCO World Heritage Site that was inscribed in the UNESCO
list in 1985 (Figure 1). Its early inclusion on the list was in recognition of its tremendous
importance in the history of the Andean region as well as in the history of Peruvian archaeology.
The site and similarly named culture principally developed between 1200-500 BCE (Rick et al.
2011). It is recognized that the site functioned as a ceremonial and pilgrimage center that
attracted people from across the region. This site is composed of an elaborate stone temple,
constructed plazas, and surrounding ritual facilities. The ceremonial and monumental nature of
the site is visible in its fine stonework, elaborate iconography which depicts anthropomorphic as
well as zoomorphic imagery from across the region, as well its internal gallery system and
extensive canal network that runs across the site and connects it to other water movement
features at the boundaries of the temple (Burger 1995; Rick 2008). Sites of this complexity often
have formally separated ritual space along with evidence of inter-regional interaction (Rowe
1963; Moore 2005).
The Stanford Project began work at the site in 1994 and although the early years of the
project were devoted to the then novel technology of theodolite mapping (Kembel 2008) the
group has moved beyond mapping and now encompasses many different aspects of
anthropological and archaeological research. The project has expanded over the years and there
has been a consistent emphasis on including new technologies that permit more accurate
118
recording of spatial and archaeological data (Ristevski 2006; Kembel 2008; Contreras 2009;
Rick et al. 2011). Initial work at the site focused on the monumental center but later projects
have expanded to include encompassing areas (Mesia 2012; Contreras 2015; Sayre et al. 2015).
The project has included archaeologists from around the world, but the majority of the
professional team is Peruvian and there are many local workers on the project who have
developed expertise over decades of fieldwork. This on-the-job training shares similarities with
the archaeological field school experience but the local excavators oftentimes come from
farming families. As such, they come to the project with extensive expertise working with local
soils and sediments.
In the rural Andean region of Peru there are many areas with high levels of poverty
(Matos Mar 1984). Much of the wealth of the country since colonial times has been concentrated
on the coast and in the capital of Lima. This has left the highlands as a region that has suffered
both economic and racial injustice. Up until the 1960s inhabitants of the highlands were
commonly referred to as indians (indios), which was considered a pejorative term (Matos Mar
1984). Currently people in the region commonly refer to themselves as peasants (campesinos), a
term that was preferred by government officials. Many aspects of the project at Chavín are
impacted by this history of working in an under-resourced region with a history of mistreatment
by coastal elites.
Our Experience with Digital Recording
The Chavín archaeological project was an early adopter of digital recording techniques,
beginning with its use of laser theodolites in the 1990s. Many of the problems that arose with the
early adoption of digital technologies were inherent to the process of applying recently
119
developed software to a new region. The software that our team, in particular John Rick of
Stanford University, was trained in in 2011 was the PC based REVEAL Program
(Reconstruction and Exploratory Visualization: Engineering meets ArchaeoLogy). The program
was significantly deployed in the 2011 field season.
Reveal’s developers state1 that it is a system for streamlined powerful sensing, archiving,
extracting information from, visualizing and communicating, archaeological site-excavation
data. Reveal is available open source to the archaeology community. It provides core Computer-
Vision/Pattern-Recognition/Machine-Learning Research with applications to archaeology and
the humanities. The website2 describes this process, “…REVEAL Analyzer provides the
excavator, researcher, or student with integrated multi-format access to the tables, photographs,
and 3d models in the database. Exploring and filtering the data in plan view, 3D view, photo
view, or tabular view generates automatic back-end queries to extract, format, and display
relevant information from the database.” While this program is admirable in its ambition and
scope, we encountered some difficulties applying this program to fieldwork in the rural Andes.
Many of the complications that arose were due to differences in archaeological practice
around the world. Much of the Reveal program appears to have been developed with the
terminology and techniques of Mediterranean archaeology in mind. These different standards
and methodologies around the world lead to different definitions of artifacts, site types, and soil
counts. For example, trenches and spits are typical spatial excavation areas in the Mediterranean
whereas many projects in the Americas rely on spatial units of varying sizes. The denotation of
units is also an issue as more and more projects in the Andes are moving away from using
standardized unit sizes (such as 2 x 2m units) and moving towards using the locus system of
1 https://vision.lems.brown.edu/project_desc/Reveal Accessed August 30, 2015
2 https://vision.lems.brown.edu/project_desc/Reveal Accessed August 30, 2015
120
excavation which permits users to easily construct Harris Matrices (Harris 1979). This difference
also raises the issue that in Peru some governmental authorities prefer to see standard unit areas
when they inspect excavations whereas others require the use of the locus excavation system and
the completion of a Harris Matrix at the end of the season. Another difference in techniques is
that in the Andes archaeologists routinely use bucket counts in order to document the density of
finds, in this case the Reveal program allowed for baskets of dirt which did not seem to connect
immediately with density computational outputs. The Chavín project typically uses 10L buckets
to measure soil volume. These examples highlight the tension that exists between standardized
group software and bespoke systems designed by individuals for use by a small and specialized
excavation team (for more specialized discussions of this issue see Serrano et al. and Dufton in
this volume).
There were issues with the Reveal software that arose at our field site that would likely
not be major issues in regions of the world with reliable internet access. The lack of reliable
access led to syncing problems and the inability to synchronize data files easily with Dropbox
accounts. In general, a significant advantage to digital recording of archaeological field data is
the capacity to export data files into online databases. If this is possible it enables specialists to
access field data immediately as well as help all members of the field team avoid the double duty
of entering paper field forms into databases that are generally stored online. The project was
unfortunately unable to avoid this double recording of forms.
Some of the strengths of the Reveal software were compelling enough to make our team
excited about future possibilities. The software had great compatibility with PC based tablets and
the software synchronized well across desktops and laptop computers. This is always an issue in
areas with limited access to wireless internet. Once a local intranet was established many of the
121
problems of synchronization were resolved. Additionally, the tablets were compatible with
Windows and access to other operating systems in Peru can be difficult to manage.
One final issue was how to create documents for government review agencies. This
matter arose as many forms are recorded in both Spanish and English. While the original forms
are all in Spanish some of the team members (primarily North American undergraduate students)
are monolingual English speakers and we consistently have to translate content into Spanish.
This problem continues to exist and will likely not be eliminated by technology. This double
work of translation may eventually be solved by translation software, but for now the manual
entering and translating of paper field forms into databases is still more clearly managed by
having one sole typed final form. This is another example of a workflow that is more
complicated than it has to be and it is something that could be resolved by future technological
advancements.
Early Adopters, Students, and the Value of Digital Methodologies
The varied backgrounds of excavators on projects are something that all larger excavation
teams will encounter. This is a particular issue on field schools where participants are just
beginning to learn archaeological terminology. These people work alongside seasoned
professional archaeologists who record differences in micro-stratigraphy. As directors train
students in new terminology and skills the means by which they record those notes may be less
of hindrance to the students than the challenge of fieldwork itself (see Ellis this volume for a
critical discussion of this issue).
The collection and correction of written forms is a standardized practice on most projects
and this is an area where the online management of group files facilitates work. If supervisors
122
have access at all times to students’ field forms they can correct and add notes at any point in
time. As we train students in field note taking and digital methodology it is possible to show
them that these skills are applicable outside of archaeological excavations. The ability to
synthesize, store, and process large amounts of digital data is a skillset that is transferable to
many other fields. This is part of the advantage of being early adapters of new technologies; the
skills learned in a class setting can then be taken outside of the classroom and integrated into
private and public sector occupations (cf. Bria this volume; Kansa this volume; Opitz this
volume).
As I have previously discussed, field schools are an example of the flipped classroom
(Sayre 2014). In these settings students are taking material from lectures and books and applying
it to a real world context. Their supervisors are responsible for answering questions and guiding
them along the learning process so that they can begin to identify stratigraphic changes and
significant finds on their own. The goal of developing independent and self-guided learners is
one that melds well with the digital domain. As information is recorded and uploaded to digital
databases it enables new learners to pose questions of their peers and supervisors, thus creating a
more open and questioning community of archaeologists than would be possible if field
excavators were simply recording their notes in field notebooks that would solely be reviewed by
their immediate supervisor.
One area of laboratory work where we have rapidly implemented digital methodologies
has been in the recording and processing of architectural and ceramic data. These two types of
cultural material traditionally required specialists to spend tremendous amounts of time drawing
in the field and in the laboratory. As digital photography and photogrammetry have become
increasingly more advanced over time we have been able to spend less time drawing these
123
objects and more time creating accurate three-dimensional models of artifacts, ceramics, and
walls (Figure 3). The team members who specialize in creating these models can take these
digital skills and apply them to many domains. This was a central topic of the documentary that I
helped to produce,3 which seeks to present the importance of archaeology to a broad public.
Technical Advantages
There are many advantages to a switch to digital archaeology. While this chapter has
emphasized some of the difficulties of this work, in particular those that arise while working in a
rural setting in a developing nation, one of the reasons why this transition is occurring is because
there are significant benefits to changing practices.
The real-time processing of data, both visual and textual, is important. As threedimensional
visual data becomes more nuanced and detailed it will permit researchers to ask new
questions of the spaces that have been excavated and how those spaces relate to the broader
world around them. The syncing of written records with online databases will provide access for
remote researchers, in particular specialists who are not always on site, to provide insights and
ask question of field researchers. It will also permit fluid exportation of visual and textual data
for final reports and for academic research. The relative ease with which researchers can share
their data with the public could lessen the tendency of contract and academic archaeology to
produce grey literature that is not easily accessible to interested parties.
Digital archaeology also provides the possibility of creating a more environmentally
sustainable archaeology. The lower reliability on paper will lessen the impact on the environment
and the increased emphasis on digital tools could lead more projects to invest in solar digital
3 www.intothefieldfilm.com
124
chargers and other means of providing clean energy for archaeological field and laboratory
projects. While this transition has not yet occurred a fully digital project may feel greater need to
make this change. However, this does not mean that there are still not social issues involved in
the transition to digital recording.
“No One Steals Paper”, or Digital Archaeology Within a Developing World Context
Digital archaeology does not solely exist in the ethereal “series of tubes” that is the
internet; rather, its application and practice occurs in real world settings. For example, when I
first came to the town of Chavín de Huántar in Peru in 2002 there were less than five telephones
in town. Soon the number of fixed lines expanded and people began to construct internet cafes.
Over the years these cafes converted into gaming and chat centers as the internet connections
were too slow to engage in any serious work. This change was soon followed by the introduction
of cellular phones, which soon became the dominant means of communication in town. They still
are the primary means of communication with the outside world as there is still very little
reliable internet access. While our project has established a good intranet system, there is still
little access to outside connections.
The local population continues to have little connection to email or cloud services. This
lack of availability prevents our project from being able to reliably store terabytes of
archaeological/visual data online. Limited connections prevent us from engaging in some of the
more compelling aspects of digital archaeology, such as the immediate uploading of visual data
onto cloud platforms that are accessible by outside researchers working offsite. While we
currently maintain databases that are accessible after the field season, there is a positive impact
to the lack of cloud access one the site as it makes it necessary for project members to come to
125
the site and interact with their fellow archaeologists. These in-person moments can lead to
conversations and correlations that may not have happened if people were not physically present
on the project site.
There are a number of cost requirements that have also impeded the project’s transition to
a fully digital program (see Ellis this volume; Serrano et al. this volume). Some of the hardware
costs will be clear to all researchers but some of the costs vary based upon the location and local
realities of the project site. For example, a major international project working at pre-ceramic
sites on coastal Peru has stated that they anticipate having a three-year replacement timeline for
all hardware (John Rick, personal communication 2015). This rapid replacement timeline is
partially a result of working in a desert environment where dust and wind negatively impact the
preservation of equipment. However, field archaeology is always hard on equipment and dirt is
omnipresent at archaeological field sites. A three-year timeline for replacing all tablets, desktops,
and field computers is a high cost for most academic or contract archaeology projects.
One particular concern that arises in many places in the developing world is that class
difference that becomes apparent when archaeologists are seen carrying tablets and digital
equipment around town in local communities. The value of this equipment, which routinely is
above a thousand dollars per instrument, is beyond the purchasing power of almost all people in
the developing world. For example, the daily wage in many areas of rural Peru is routinely less
than US$10 a day (Zambrano et al. 2014), and many people do not have access to paid labor
positions. Thus, there are many members of these communities who get by on less than $5 a day
(Matos Mar 1984; Zambrano et al. 2014). This wealth discrepancy can lead to tensions with the
local community who can begin to view the archaeological project as a wealthy influx of
outsiders with little knowledge of how difficult life can be for common people in their
126
communities. It could also attract the unwanted attention of criminal elements that exist in all
communities around the world.
One particular concern in recent years in Peru has been payroll robberies (John Rick,
personal communication 2015). A Peruvian project on the coast of Peru experienced such an
event in recent years (John Rick, personal communication 2015). Local community members
learned the payday of local field workers and realized that the cash payments were being
delivered once every two weeks by truck. This truck was stopped at gunpoint on the road and
robbed. Quite clearly, no member of an archaeology project wishes to put any member of the
project in the face of deadly harm. While some payments can now be made directly into bank
accounts, it is also clear that there is not too much of a distinction between cash robberies and
robberies focused on hardware and equipment. This is why some members of the archaeological
community (John Rick, personal communication 2015) say, “no one steals paper.” The
recording of excavation data on paper limits the amount of visible valuable equipment in the
field and also adds to the sense that the work is academic in nature and is not engaged in
ostentatious displays of wealth.
Decolonizing Archaeological Practice
There are inherent social tensions in almost all realms of archaeological practice. These
tensions are often magnified when archaeologists work abroad and they can be further
compounded when a group of archaeologists from the global north works in the global south.
This is the case with our project, where the directors of the project are Peruvian and North
American. While the permitting process for all fieldwork in Peru is managed and granted by the
cabinet level office of the Ministry of Culture, there are also non-bureaucratic concerns that have
127
to be addressed. Some of these concerns center around economic inequality and access to
technology.
The Chavín project works in a rural Andean town where many of the local inhabitants
lack formal work. When formal work does exist it routinely pays less than the official minimum
wage of 750 soles (roughly US $230) a month. This leaves a community composed of workers
who generally earn less than US $5 a day. While many members of the local community grow
and raise most of their food they also seek to own technology and material goods that connect
them to the broader world.
The Chavín archaeological project uses standard technology for their research. These
include personal computers, desktops, digital cameras, tablet computers, theodolites, and
scanning machines. Each of these pieces of equipment generally costs over US $1,000. This
represents almost half a year’s salary for many members of the local community and
undoubtedly causes tension. Many members of the archaeological project find it awkward when
a local community member asks them how much their camera, phone, or shoes cost, but it must
be acknowledged that these are natural questions that provide useful information to people who
need to negotiate their salaries and other forms of compensation with people who are coming
from other areas of the country or from abroad. The differences in income and access to material
goods can lead to problems and adversely affect community relations.
One of the means by which our project director has attempted to enhance community
relations is by making sure that members of the local community are trained in the use of
advanced technology. Beginning in 2003, Dr. Rick began to hire local high school students to
learn how to use digital cameras and to process the images that they took on project computers
using sophisticated software. The removal of expensive equipment from the archaeologists’
128
hands and its placement in the hands of local community members visually displayed how
technology can be democratizing (Figure 2). In this case, trust and openness with local
community members led to an increased sense of trust. In addition, many of these local students
took the digital skills that they learned and applied them in other careers.
If we are to decolonize archaeology we must go beyond simply handing the camera over
to a different set of hands. The local campesino has more to offer than day labor. As workers
collaborate together on the excavation process many local insights should be added into the
interpretation process. Some of those insights involve training outside archaeologists to view the
landscape and environment through local eyes. An additional means of decolonizing the
discipline, and turning to more community-based research has been simply to ask what the local
community would like from the archaeological project. In our case the answers have varied
tremendously, everything from language lessons to enhanced business contacts with the tourism
industry have been requested. As the project responds to the needs and requests of the
community they expand the scope and importance of the project.
In the end much of the research at the site has been guided by the words of previous
Chavín project director Luis Lumbreras (1981:6):
“La arqueología no es, como no lo es ninguna ciencia, una etérea actividad académica aislada de los
problemas de la sociedad donde se desarrolla; es, y siempre ha sido, un instrumento activo de la lucha
social que [...] sirve para cohesionar y dar sustento a la clase social que la utiliza. La Arqueología es arma
de opresión cuando sirve para justificar la explotación de los campesinos indígenas de nuestros países,
desarrollando teorías que muestran su inferioridad histórica frente a los invasores europeos y su proclividad
a la decadencia. Es arma de opresión cuando saluda y engrandece el pasado para denostar el presente,
creando la retrógrada convicción de que ‘todo tiempo pasado fue mejor’ [...] Es arma de opresión cuando
convierte en objeto al sujeto histórico. La arqueología, en cambio, es arma de liberación cuando descubre
las raíces históricas de los pueblos, enseñando el origen y carácter de su condición de explotados; es arma
de liberación, cuando muestra y descubre la transitoriedad de los estados y las clases sociales, la
transitoriedad de las instituciones y las pautas de conducta. Es arma de liberación cuando se articula con las
demás ciencias sociales, las que se ocupan de los problemas de hoy, y muestra la unidad procesal de la
historia en sus términos generales y en sus particularidades regionales o locales” Luis Lumbreras 1981:6
Archaeology is not, as it is not any other science, an esoteric academic activity isolated
from the problems of the society in which it develops; it is and it has always been, an
129
active instrument of social struggle that [...] serves to unite and support the social class
that uses it. Archaeology is a weapon of oppression when it justifies the exploitation of
indigenous peasants in our countries, while developing theories that show their historical
inferiority to the European invaders and their proclivity towards decadence and decline. It
is a weapon of oppression when it enhances the past to insult the present, creating the
retrograde conviction that 'all the past was better' [...] it is a weapon of oppression when it
converts an historical subject into an object. Archaeology, however, is a weapon of
liberation when it discovers the historical roots of the people, teaching them the origins
and character of their current exploited status; it is a weapon of liberation, when it reveals
the transience of states and social classes, the transience of institutions and patterns of
behavior. It is a weapon of liberation when it joins with the other social sciences, those
dealing with the problems of today, and shows the procedural/processual unity of history
in general terms along with its regional and local particularities."4
Much of this chapter has focused on the real world problems and benefits of switching to digital
platforms. As the quote from Lumbreras makes clear we must always be cognizant of the fact
that the knowledge we produce has real world implications and the tools that we use in
developing that knowledge can also serve similar ends.
Conclusion
As Sonya Atalay (2012: 2) stated: “If we problematize archaeology’s future, three
important considerations come to the forefront: the issue of relevance, the question of audience,
and concerns about benefits.” Digital archaeology must also confront these three issues. One
might argue that the relevance, audience, and benefits of digital archaeology are primarily
designed for and associated with wealthy universities. However, this chapter has attempted to
demonstrate that digital archaeology is relevant to a broader public and community audience
than just academics in the global north. There are many publics who find digital methods to be
both relevant and beneficial to their communities. However, these communities are not always
4 Translation by author.
130
naturally included stakeholders in these conversations and this is an issue that must always be
acknowledged and addressed.
The chapters in this volume come from a conference that convened a broad array of
researchers in an attempt to formulate future best practices. While many of the other chapters in
the volume directly engage with some of the technical tools involved in the transition to digital
archaeology, this contribution has hopefully added more of the human element into the picture.
We must remain committed to working in communities and creating scholarly work that engages
with, and is influenced by, the people and communities that surround us.

1.7. Digital Pompeii: Dissolving the Fieldwork-Library Research Divide
Eric E. Poehler, University of Massachusetts Amherst
Sometime before October 31st 1766 excavation began inside a porticoed building in the
south of an area that would soon become the archaeological site of Pompeii (FIG. 1). The pace
of work to clear the building was swift but episodic as crews were frequently reassigned to more
exciting discoveries in the early years of Pompeii’s rediscovery. Moving in bursts along the
southern colonnade, the excavators seemed to be able to move at least 140m3 of material in a
week, before halting for nearly two months. Another burst of activity pushed to reveal the
southeast corner, and the first half of 1768 was spent clearing the eastern colonnade (Pagano and
Prisciandaro 2006: 58-64). Excavation of the northern and western colonnades is not specifically
dated in the archival records, but images show that into the 1780s a great mound of volcanic
debris at least four meters high still covered much of these areas and persisted into the first
decade of the 19th century (FIG. 2). In the course of those excavations, stunning images and
artifacts were revealed including real and painted armaments that would give the Quadriporticus
its colloquial name: the Barracks of the Gladiators (FIG. 3).
The precise date when excavation in the Quadriporticus was completed is not terribly
important as the volume of material removed was astounding, however long it took to remove:
over 15,000 cubic meters of earth, ash, and lapilli were removed, as well the trees that grew atop
the buried city. On average, 18th-century excavators (and we should hesitate to call them
archaeologists) removed at least 300m3 of material each year from the Quadriporticus, but that
average dramatically underestimates the pace of work. We know that at times they could shift
two-thirds of that in a single week: from Feb. 14th to Feb. 21st, 1767, an estimated 212 cubic
170
meters of the southern exedra and its adjacent colonnade was cleared (Pagano and Prisciandaro
2006: 60). By contrast, modern excavation at Pompeii is excruciatingly slow. In eight years of
research on the pre-79 CE development of insulae VIII 7, 1-15 and I 1 (FIG. 4), the Pompeii
Archaeological Research Project: Porta Stabia (hereafter, PARPPS), directed by Steven Ellis,
excavated forty trenches below the final Roman levels exploring 770m2 of the 2,660m2 of these
humble city blocks, removing about 1,150m3 of material (see Devore and Ellis 2005, 2008); Ellis
and Devore 2006, 2009, 2010); Ellis et al. 2011, 2012, 2015). The PARPPS excavation seasons
are only five weeks long, so the average pace of excavation is 29m3 per week, or 10% of the
average rate of the Bourbon excavators. The volume of material culture that Ellis and his team
recovered in those eight years, however, dwarfs the half-century of objects recovered in the
Quadriporticus. While only eighty objects were recorded in the Quadriporticus (concentrated
almost entirely in the first three years; Pagano and Prisciandaro 2006, vol. II, 259-60), PARPPS
recovered more than 280,000 objects. Moreover, Ellis and his team identified and documented
over 4,500 individual stratigraphic units to which these finds belong and relate giving on average
an archaeologically meaningful distinction to every 0.25m3 of soil and doing so 114 times a
week (Ellis, pers. comm). By contrast, the archival records of the Quadriporticus make no useful
mention of any distinction in what they were digging through.
Between 2010 and 2013 I directed a non-invasive, born-digital, architectural analysis
project in the Quadriporticus with Ellis to decode the construction and life history of this
remarkable structure that had existed for over two hundred years in both the ancient (c. 130BCE
– 79CE) and modern (1766 – present) eras. In addition to understanding the building, part of our
research design was to test how far one could extend and how much one could gain from noninvasive
techniques and technologies. Our plan included the use of excavation data from
171
PARPPS, but permitted no new trenches. In the four, three-week campaigns of the Pompeii
Quadriporticus Project (hereafter, PQP) we recorded over 2500 stratigraphic units reflecting
changes to the masonry, décor, and function of the Quadriporticus and documented another
1,700 SUs within the seventy-seven columns of its colonnades. On average we identified and
documented more than 350 stratigraphic units per week.
Workflow is Dataflow
The point of this unequal and perhaps even unfair comparison is to draw a stark,
unmistakable line around an obvious statement: as the priorities of archaeological research have
changed so too have our methods, techniques, and results. The dominant trend, at Pompeii and
elsewhere, has been an ever-widening gulf between the decreasing volume excavated and the
density of material recovery and documentation. Indeed, the PQP recorded as much stratigraphic
information as any other research project without excavation at all. While modern research
projects have fewer infrastructural and logistical challenges compared to early modern
excavations in managing smaller labor forces for shorter periods, our ethos of information
maximization has replaced these with an enormous data management load. Today, every project
has a database and most have an organizational chart of personnel that is at least implicitly a map
of dataflow through that project: from excavators to trench supervisors to object specialists to
directors (e.g., see Wallrodt, Motz in this volume). On the front line of excavation are spatial
people, taphonomic specialists (i.e., excavators) who faithfully record every aspect of a trench,
but who also give up much of their object analysis to the next layer in the flow of evidence. It is
the object specialists who provide final identifying, functional and chronological information to
the artifacts recovered. In some cases it is first up to the trench supervisor to minimally
172
reintegrate the specialist’s spot reports back into excavation practice. Ultimately, it is the project
director’s responsibility to reunite the space of a trench and the objects ripped out of it within a
historical narrative that explains the social forces in the past that brought these material realities
into being. There are still more processes and personnel on a modern research project. Many
projects have an artifact registrar, spatial specialists (who work with survey instruments, CAD,
GIS, etc.), and now dedicated information technologists to deal with the constant flow of data
and metadata in archaeological research.
In addition to and in place of these information specialists some projects have looked
longingly toward the revolution in portable computing and information technologies. These
devices and software (particularly tablets and drafting apps) have allowed archaeologists take the
work of data management back to the trench edge and make it the point of origin for precise and
accurate digital recording. As many contributions to this volume demonstrate, we have already
witnessed the first part of the revolution of our discipline: the transformation of archaeological
methods of data collection and, to a lesser extent, how such data are accessed and deployed in
the field. iPads are everywhere, and though as the flavor of the moment they will be superseded,
they are not going away.
Such is the formulation of modern archaeological practice: dense networks of technology
and personnel enmeshed within an ethos to collect more evidence from smaller trenches using
less invasive methods. It is within this context that I want to explore what I believe will be a
second act in our revolution in digital archaeological practice. Put simply, in the very near future
an entirely new set of tools and an enormous dataset for archaeological inquiry will also arrive at
the trench edge: the library. In theory it is a good thing to bring all information to bear on a given
inquiry, but in practice we know that it is not only impossible, but often counterproductive to try
173
to employ every method or apply every dataset to a given problem. Breaking down the
geographical wall between fieldwork and library research – the hundreds to thousands of miles
separating the field site and the university – is well underway, but its impact on how
archaeologists do research is yet unknown (or rather, yet undecided by us).
Technology > Method > Interpretation
In what remains of this article I want to very briefly outline two projects that I direct that
scratch the surface of this second act in digital archaeological practice in order to explore very
briefly what the future might look like. These examples demonstrate the value of doing archival
research in the field and that soon a visit to Pompeii can mean a tour through its bibliography as
well. The mechanisms by which we deliver secondary materials to the field are already being
built and now we must begin to question how to incorporate books and articles (at least) into our
actual fieldwork practices. To do this we need to begin to imagine not only the possibilities, but
also the impediments: when do we dig and when do we read? Most importantly, if we are going
to integrate a significant component of secondary source material, we must also ask: where will
we find the time to do so?
The first project, the Pompeii Quadriporticus Project, has already been introduced as part
of the opening discussion on the increasing elision between fieldwork practices and information
management. In this context the PQP’s use of more than 186 archival images in the field to
identify and document changes to the building that occurred in the two and one half centuries
since its initial excavation are also relevant to the fieldwork-library question. These images were
loaded in both an offline database and in an online (and now defunct) platform called DM, which
provided a set of basic markup tools for drafting and annotation onto the images themselves as
174
well as creating links between images (Poehler and Ellis 2014a: 3-4). It was during the process
of examining these archival images and creating an absolute (by the dates of the images)
sequence of modern architectural changes to the Quadriporticus, that we first noticed that a few
important components of the building’s architecture had been removed. The most obvious
removal was the large fountain that several artists and cartographers had depicted in the northeast
corner of the portico prior to c. 1837 (FIG. 5).
Less obvious was the circular, colonnaded structure that had once existed – or was still
under construction - in the center of the Quadriporticus. Hints of this tholos-like structure were
first noticed as curious stray column drums along the edge of the unexcavated central mound and
in the column standing in the tunnel excavated through it (FIG. 2). It was only when looking for
images of the lost fountain that we noticed a circle of column drums surrounding a cylindrical
altar or puteal (Poehler and Ellis 2014a: 4-6). That some circular structure inhabited the middle
of the Quadriporticus was not surprising to us: our GPR results had already proven its existence
(FIG. 6). A cursory examination of early maps of Pompeii (and an over-abundance of caution),
however, had convinced us that these subsurface structures were related to the center of a
modern cruciform garden design imposed on the interior of the colonnade (Poehler and Ellis
2012: 3-4). The combined weight of imagery from both the 19th and 21st centuries, however,
could not be ignored and caused us to change our interpretation. Interestingly, another image
with evidence for the circular structure was identified by Steven Ellis while in the audience at the
“Mobilizing the Past” workshop. The drawing by Gudeson, made from his 1840s balloon flight
over Pompeii, shows – when highly magnified or when projected onto a 30 foot screen – a
circular projection in the center of the Quadriporticus (FIG. 7).
175
For the PQP, the impact of having and interrogating archival materials in the field – in
databases on our iPads and in online markup environments (DM) - was both immediate and
enormous. Suddenly, our building possessed a structure not seen in nearly 180 years and changed
that building’s basic appearance from Hellenistic gymnasium to 2nd century CE Macellum. It is
the aspiration of the second project I direct to make this kind of discovery from in-field archival
and secondary source research possible for every building at Pompeii. The Pompeii Bibliography
and Mapping Project (http://digitalhumanities.umass.edu/pbmp/) is the attempt to graft a
bibliographic catalog of more than 20,000 references onto an online Geographical Information
Systems map(s) with thousands of spatial objects. On their own, each component creates a new
tool for researching the city that has never been available in digital form. Together these datasets
offer an unique opportunity to explore at once the physical, cultural, and narrative landscapes of
the most important site in the world of Roman archaeology. By collocating spatial and
bibliographic information within a single representation, users can find information about the
ancient city in a particularly intuitive manner – by simply clicking on the space of one’s interest.
The true value of the PBMP, however, will come as a querying tool. Attaching the
bibliographic data to the GIS permits one to use spatial categories to sort through thousands of
citations that might be related only by the locations referenced in those texts. Moreover, because
one can sort the bibliography first by the size or variety of a building type (e.g., a house or its
area in m2), its locations in the city (e.g., insula 1 of Region I), and their relationships to other
kinds of structures (e.g., workshops), unique and powerful questions that once took weeks to
generate the data for will now only take minutes. It is in such experimentation that I hold the
greatest hope for the PBMP and where I expect that its use in the field will be the most novel
(see Poehler 2014b for an example). Certainly, the ability to quickly find materials on topics
176
related to one’s fieldwork will be valuable, but greater still will be the ability to create maps and
bibliographies of comparanda for the features and finds discovered in the course of
archaeological research.
While the PBMP will have an important impact, it is important to recognize that we
already choose from among many possible aspects of research moment by moment while in the
field: from excavation, to primary and secondary analyses, to phasing and contextualization, and
finally to report and publication writing. To put this more simply:
We collect data;
We analyze them;
We interpret them;
We synthesize them;
We narrate them.
These activities are natural allies in a process of understanding the past and there are
many reasons why doing all these aspects in the field makes sense. But the purpose of this
reductive adumbration is to make easier the task of considering the times when we currently
introduce information from secondary sources and where we might add still more in the future.
So when do we think we would want read secondary sources now?
1. Excavation: when discovering an unusual feature (e.g., a kiln or soil
layer).
2. Artifact analysis: when discovering an unusual object (e.g., rare material
or form).
3. Synthesis: when the combined data lead to a surprising result (e.g., when
discovering your building is another building).
4. Writing: when making an argument supported by facts (i.e., all the time).
Currently, at the moment of excavation, there are relatively few opportunities to
incorporate library resources. Excavation, or equally pedestrian survey or masonry analysis, is
177
primarily a manual process of sampling, collection, and recording that tends to limit the subjects
relevant to read about. Background information on the geology or later ancient and modern
histories of a location seems an appropriate topic to investigate while digging (or equally in
preparation for digging). The discovery of an important feature, such as a the kiln found near the
Porta Stabia in 2012 might also drive an excavator toward secondary source materials to help
understand the function, distributions, and known forms of other excavated kilns (Dicus 2014,
66-67; Ellis et al. 2015: 2-5). The study of unusual objects at the level of artifact analysis would
also benefit from a direct connection to sources of comparanda for identification, dating, and the
determination of function. Looking further to the future, we should imagine consulting not only
standard reference materials of canonical types, but also multiple examples from previously
excavated sites in the form of narrative, detailed imagery, and three dimensional models (FIG 8;
see contributions by Ashley and Kansa in this volume).
In the future, the point of synthesis seems a natural place to expand our use of library
resources in the field. Synthesis is an all too neat word for the sloshing back and forth between
individual interpretations of data and the arguments they are meant to support. Such messiness,
however, makes room for other peoples’ interpretations, for comparanda, and for unexpected
parallels. I suspect that this will be one activity expanded by access to a library in the field. At
the same time, it seems equally likely that the some of the research burden for making initial
identifications and interpretations of objects, features, or soils will fall to the trench supervisor
during the workday. Those excavators who can generate not only an interpretation of the trench’s
stratigraphy, but also equally synoptic bibliographies on the fish vats, bar counters, drains, or
beaten earth streets will make a valued contribution to the stage of synthesis and writing.
178
Pay it Forward: Doing more with more
How, then, will we “pay” for the extra time needed to do secondary source research in the
trench or at the specialist’s desk or at the dig house dinner table? That is, how will we replace the
lost time for digging, analysis, interpretation, etc. or, more likely, for sleep or relaxation?
Certainly excavating fewer trenches is a possibility, but studying them with less intensive
methods is not. Another answer will be to find efficiency elsewhere in the process. For example,
for the PQP, it was in part the speed at which we could document (not make) our interpretations
of each wall in a drawing that bought the time to do both the archival research and the detailed
examination of the columns in the Quadriporticus. What once took an hour to an entire day for
two people to accomplish – stringing a baseline, setting up a drafting board and mylar, taking
scores of individual measurements by hand and shouting them to draftsperson who transposed
then into a scale drawing – now could be done by a single person in thirty minutes using the
camera and a drafting app on the iPad. Additionally, because the PQP closely and intentionally
paralleled the processes of archaeological workflow (organization of fieldwork practices) and the
dataflow (organization of data derived from fieldwork practices) we made thousands of
archaeological observations instantly ready to be combined not only with the observations from
other walls but also from rooms and even whole sections of the building. For us, an explicit goal
was to reach a stage of interpretation and synthesis beyond an individual wall while still in the
field. To do this we utilized the expertise created within our staff who had just analyzed that wall
a digital infrastructure that had contained explicit linkages between evidence and its
interpretation, and we “paid” for the time to synthesize our interpretations with the increased
speed in graphically recording those interpretations.
179
If the PQP were to be started 10 years from now, I imagine we would put greater
emphasis on reading about the implications of our initial observations and interpretations, such
as understanding the rest of the great “Altstadt” sewer (FIG. 9) that passes through the
Quadriporticus or the use of specific construction techniques and materials in the rest of
Pompeii. Certainly, in this imagined future I might have tackled the archival and bibliographic
research in search of the tholos structure the very week the Ground Penetrating Radar results
were received, rather than two years later. Finally, I imagine that we would build time to
accommodate the most important analog tool we will still be using, the human brain and all its
psychological conditioning and quirks. This is really Bill Caraher’s topic and you can read more
about “slow archaeology” in this volume. Though I have no doubt the future will be “slower”
than it is today, I am equally sure that the time for such reflection will come, ironically, on the
back of efficiency somewhere else in the fieldwork system.
To sum up: the library is coming to a future trench near you. With it are possibilities and
pitfalls yet unimagined. This paper has tried to illustrate a few ways the introduction of published
scholarship (but only hinted at published, open data archives) might impact archaeological
fieldwork and further to imagine its place in the digital archaeological practice of the future. But,
these few hundred speculative words cannot compare with the value of our collective endeavors
and especially failures in the coming decade. Our experiments to dissolve the library-fieldwork
divide will not only find the best and worst places to insert this new dataset into our practices,
but also will bargain with other activities to find the time for such insertions. New efficiencies
will be found to implement the library resources and they likely will come at the trench edge,
squeezing excavation supervisors – the middle management of archaeological fieldwork –
180
between a confrontation with the physical world into an increasingly complex digital
representation of it.

2.1. Reflections on Custom Mobile App Development for Archaeological Data Collection
Samuel Fee
Introduction
PKapp is a mobile application that facilitates the electronic collection and recording of
archaeological field data. Initially implemented during the 2012 season of the Pyla-Koutsopetria
Archaeological Project (PKAP), PKapp weds archaeological methodology with technological
innovation (see Ellis, Motz, Bria, and Poehler, this volume). Building on the widespread
adoption of tablet computers in 2010, the app turns traditional paper-and-pencil data collection
into an electronic process with improved efficiency and speed. Ultimately, the app frees up time
for researchers to devote to analysis and education.
PKapp was designed as a web app, rather than a native application. Native apps are
written for specific operating systems. Web apps are based on the HTML5 specification. The
timing was ripe for developing such an electronic data collection form – HTML5 had become a
relatively stable standard in 2011 and mobile computing devices were widespread and
inexpensive. From a development standpoint, coding in HTML5 was easier and more reliable
than working with earlier, separate versions of HTML and JavaScript (Stark, 2010; Stark et al.
2012). Also, this approach made is easy to install, test, and operate the software on tablet
computers across vast geographic distances; this was particularly important as the developers
were in the United States and the archaeologists were in Cyprus.
Tablet computing had quickly been adopted in 2010 for archaeological work (Apple,
2010). The details of that work were already available, so we could shape our vision for PKapp
from descriptions of others’ work (Ellis, 2011). Those early efforts employed apps created by
other developers. PKapp was an effort to explore the possibilities of custom software
development, and to see if there was any appreciable benefit from taking that approach to
191
software development. But most importantly, PKapp taught us how to write software for mobile
devices, while also illuminating numerous possibilities for digital workflow in field research.
The uses for the app have been detailed in a brief article that William Caraher, David
Pettegrew and I composed for Near Eastern Archeology (Fee, et al. 2013). During the 2012 field
season, William Caraher and David Pettegrew were co-directors for the project along with R.
Scott Moore. William served also served as database administrator, David served as Field
Director, and I was in charge of software development. The purpose of this current chapter is to
describe the technical planning and development behind the app, identify some of the most
challenging programming problems, and suggest current directions for app development given
the rapid advance of programing libraries and frameworks for custom mobile app development.
These tools make it easier and faster to develop a tool like PKapp today than it was in 2012.
Description of the App
PKapp represents a natural progression from traditional paper collection forms, replacing
a two-page paper document with a single electronic form for recording basic, required
information and unstructured descriptions (FIG. 1). The basic unit of excavation at PKAP is the
Stratigraphic Unit (SU). The entire electronic form is constructed around recording or recalling
data for each SU.
As we began planning the project in 2012, we identified a number of parameters that
needed to be addressed carefully during the development process:
1) There could be no data loss.
2) Data entry should follow a simple process.
3) Data validation was imperative.
192
4) The software must run locally on the device (without Internet access).
5) A simple data export mechanism was required.
6) Updates should be accessible remotely.
7) The software must be platform-agnostic, and must run on any mobile device.
We returned frequently to this list in our planning of both design and programming elements
(such as the export of data). Several of the criteria, which resulted from the needs of researchers
working in remote locations with unreliable web access, had some technical implications for our
work. We worked with the form validation abilities built into HTML5 to ensure that any data
entered was of the right type before it ever got to the primary database. We also ensured that the
app would write data directly to the device without wireless access, and that it would upload data
from the device to the primary database easily—a task easier to theorize than to implement.
Finally, our desire to access updates remotely meant we needed to develop a web app for
use outside of the app store environment. With such as approach, we could continue to test and
revise while working in the field. We could post new versions of the software overnight and have
them in use in the field the next day, which would not have been possible with the current app
store distribution model that requires a lengthy approval process. Since we were avoiding app
store distribution and developing a stand-alone web app, we could embrace fully the open-source
standards of HTML5 and ensure that PKapp would run on any device with a stable and current
web browser.
App Design
As mentioned previously, there were two pages to the paper form for recording the field
data at PKAP. The first page asked the recorder to write down information about the context
193
including name and identifiers (date, supervisor, recorder), location (area, excavation unit,
elevation, stratigraphic relationships, UTM coordinates), soil descriptors (soil type, clast size,
munsell color), associated data (features and photographs), method, and relative quantity of finds
(by bag). The second page contained identifying fields in case the second page became separated
from the first, with blank lines for narrative description and interpretation of the area.
A major advantage of the digital form is that it forces the recorder to enter data in
standardized ways (see Ellis and Bria, this volume). Some fields require the user to choose from
selectable menus, ensuring more normalized data, while in most other data entry locations the
user can only enter in the specific type of information that actually fits the way the data is
tracked in the database. For instance, since the Excavation Unit (EU) numbers are only two
digits – the user cannot enter any more than that. The same holds true for SU numbers,
elevations, or any text entry area within the form. The app thus guarantees that the data is
formatted in a way that will import directly and correctly into the primary database.
Another PKapp feature that helps with data validation is the ability to bring up the correct
numeric or alphabetic keyboard for specific entry fields, thereby reducing the number of button
clicks and saving time overall (Clark, 2010). This can be done through the use of regular
expressions. Regular expression attributes in HTML5, which were most commonly used in the
past to evoke pattern matching for searches, allow the software to check the value of the pattern
attribute against a regular expression to see if it is valid or not. For instance, this expression –
pattern="[0-9]* – included as an attribute to the input element would limit the input to numeric
values. If it is valid, the form submits; if it is not, the user is asked to correct the format of the
entry. Thus, in addition to bringing up the right keyboard in the app, regular expressions give us
another means to ensure data validation.
194
In addition to the above features, there are buttons that facilitate interaction. These
buttons enable the primary functions for interacting with the app, in addition to the data export
functions, which enable the app’s data to be exported and later incorporated into the primary
database.
Interacting with PKapp
The buttons at the top of the application allow the user not only to enter data correctly,
but also to interact with the data that is already stored locally on the device. (FIG. 2). For data
collection purposes, the Stratigraphic Unit (SU), which is the primary method of identification
for records for fieldwork at PKAP was used as the unique identifier for the local database.
From the top left, the “Load SU Data” button loads any previously entered SU data.
Since PKapp takes advantage of the local storage on the device, a user may view and edit all of
the previously collected data. In essence this function is similar to auto-completion on web forms
through PHP, except that it is loaded from the local database rather than a remote server.
The “Clear Data / Begin New SU” button removes data from the form so the user can
enter new data, though previous data can always be re-loaded using the “Load SU Data” button.
The “Record the Data” button writes the data to the local SQL database. This feature is
similar to a “Submit” button, but it is modified with specific scripts that execute additional
functions, which are discussed later in the technical difficulties section of this chapter.
The remaining interface elements within PKapp allow for the export of data. The Data
Export section at the bottom of the form contains two buttons and a text field serving as a
window for viewing the data (FIG. 3). The upper button exports the data on the device into CSV
format and displays those data in the associated window. (CSV is a simple, tab-delimited plain195
text format that is easily imported into almost any database.) This enables users of the app the
opportunity to review and validate the data once again before sending it to the database
administrator for incorporation into the primary database. The lower button simply emails the
data directly to a unique address that has been established for receiving these data for PKAP.
Technical Difficulties
Creating PKapp was especially challenging because we were implementing an innovative
but immature toolset – specifically, HTML5 on newer versions of mobile browsers. The HTML5
specification is a collection of HTML, CSS, and JavaScript along with a much more robust
support for web forms. In many ways, this makes it perfect for what we intended with PKapp: a
web app that could be easily and remotely updated even while being deployed in the field. The
app therefore consisted of highly customized HTML5, along with the jQuery Mobile library, and
specifically the jQuery Mobile JavaScript libraries that handled a lot of the look-and-feel of the
app. The customizations made to the library included the additions of form mark-up and a
number of attributes to help validate the data and eliminate a number of potential user errors in
the input of data. For the most part, this was all straightforward, and creating this type of app was
relatively easy. There were, however, three significant problems with the software that needed to
be addressed during our development process.
1. Features we wanted but could not provide – We would have liked the app to
have the ability to capture photos and attach them to the exact data record for the
SU we were recording and to record GPS coordinates for the areas under
observation. We simply could not implement these features in 2012 because the
Application Programming Interface (API)—code instructions that link into
196
preexisting programs or hardware controls—for the internal camera and GPS
were not reliable. Today such APIs, which enable us to make use of certain
hardware features we could not otherwise access without developing a native app,
are widely available and these capabilities could be incorporated within PKapp.
2. The database – Our local storage on the device consisted of a WebSQL
database implemented through JavaScript. It was a real challenge to decide which
database model to implement since WebSQL had already been deprecated from
the HTML5 specification despite the fact that the HTML5 spec had only been
published the previous year! (Deprecated elements are removed from the
specification and no longer considered “valid.”) The alternatives were
localStorage, which was being used to save data for the current form so it could
not be lost before being saved, and IndexedDB, which unfortunately still wasn’t
fully implemented in webkit browsers such as Chrome or Safari. Since WebSQL
was deprecated, support and documentation were very limited. This made the
implementation of a stable database harder to accomplish. The actual saving of
the data simply required a basic understanding of SQL – that wasn’t very difficult
– but getting the data out of the database in CSV format or back into PKapp for
viewing was more difficult.
3. Exporting the data – Given that the app was designed with HTML5, we faced
an additional problem in that webkit browsers had not implemented the
fileSystem API at the time of development. This meant that the app could not
simply write data files and access them later. This then created hurdles in
exporting the data, which were circumvented by sending the data to the screen,
197
then using a separate function to access a remote PHP script to send the data via
email. Obviously, this last function only operates when connectivity is present.
But this functionality enabled users to review the data locally even if they didn’t
have access to the remote database server.
By far the biggest problem of the three articulated above concerned the transfer of data.
Had a reliable form of wireless communication been available, the simpler solution would have
been to send the data directly to a PHP script and import it into any SQL server on the Internet.
Yet our software solution had to run locally as there was no wireless connectivity at the site at
Pyla-Koutsopetria. Thus PKapp needed to be able to view the data locally and send it out when
the Internet was accessible. To the best of my knowledge, the process of taking data from
localStorage, placing it into the app, exporting it into an email and sending it onward is an
approach that had not been tried before.
Another option would have been to write the app natively as an iOS and/or Android
application. Such an approach would have avoided the data export challenge and would have
enabled our implementation of local files. But this would have conflicted with our desire to
remain platform agnostic and accessible on any mobile device. A native app approach could
have also allowed us to work with the Dropbox API, making storage easier and allowing for
replication of data when connection was restored. But in order for us to update the app overnight,
a native app could not be used without numerous complications for the researchers collecting
data in the field.
Reflections on and Future Possibilities for Custom Mobile App Development
198
So, in many ways there were different approaches to writing the software, each with their own
pluses and minuses for the application development process (Koch, 2014). This underscores the
importance of developing a vision for the project at the outset, before ever sitting down to write
any code. Had we not collectively held that vision, we could have easily gone astray at several
development stages and ended up with an app that did not address all of the issues that we felt
were important to the project. Because the technological toolset itself was changing even as we
were developing PKapp, it would have been easy to change direction at several points – but
implementing any of those new tools might have brought innovation in one regard at the expense
of another, or even the entire project. And such technological change has only accelerated since
2012.
In 2012 we wrote PKapp with a text editor, various browser software, and the jQuery
Mobile framework. An alternative approach could have incorporated “off-the-shelf” software
and several other projects described in this volume very successfully took that approach (see
Ellis, Motz, and Bria, this volume). But we wanted the control afforded by creating our own
custom app. At that time, writing the code manually was the only real way to accomplish our
ends by developing a web form that would operate effectively on a mobile device (Wroblewski,
2011). Today there are many tools available for making that process simpler and more direct.
Furthermore, many of the technical difficulties we faced in 2012 have subsequently been
addressed through the release of more formalized JavaScript APIs which now give us access to
additional hardware in mobile devices. Finally, the simple maturation of HTML5 has brought
about increased stability for the local storage of data within the browser that provides additional
reliability for the app itself and confidence in the data integrity of the content that we receive
from the device.
199
One of the core features of HTML5 is the improved handling of forms. Prior to HTML5,
expanding the functionality of forms (particularly with data validation) required extensive and
often problematic JavaScript programing. With the incorporation of regular expressions into the
HTML5 Specification, this is now a feature provided through the simple addition of attributes to
the form elements. Since PKapp is essentially a data collection form, this aided our development
immensely. In addition, the development of JavaScript frameworks and libraries in recent years
has made more of the development work we undertook in the past easier today.
JavaScript Frameworks
While libraries, or collections of code available for integration into new programs,
typically perform a specific but limited function, frameworks refer to a larger structure, a
collection of existing libraries, or scripts, or code, that can be utilized to create custom programs.
While there are many new JavaScript libraries and frameworks today, we found the jQuery
Mobile framework was the best option at the time of development. It was particularly well suited
for handling web forms and all of the components we would likely want for a custom field data
collection tool (items such as selection menus, toggle switches, text entry areas, checkboxes,
etc.). New tools for prototyping or further developing jQuery Mobile based apps mean that not
everything must be coded manually, nor must all the hooks into the framework be created
through a text editor. Software now enables anyone with minimal coding experience to at least
build the front-end of a web app. This places the design of any custom data collection app firmly
within the hands of the archaeologist, and not necessarily a programmer.
These tools come with different approaches and business models. Some are drag-anddrop,
others are WYSIWYG (“what you see is what you get”); some are free, yet others are
200
provided at some considerable cost. “Codiqa is a preferred option. It is available in online and
desktop versions. It is also free for academic use; however, a $79 desktop version enables you to
keep local control of your files, which is something that is important for any developer. Codiqa
exports the HTML, CSS and JavaScript that you need to build your app.
Once these files are created, building the front end of the app involves simply modifying
and customizing the appearance (via CSS). To create a custom field data collection tool, one
need only to add in the regular expressions to reinforce data validity, set up the local database,
and develop an exporting feature. Some newer JavaScript APIs can further enhance the feature
set of the app.
JavaScript APIs
Since we wrote PKapp, two APIs were released of particular interest to archaeologists:
the camera API and the geolocation API. The camera API allows you to take a picture with your
device’s camera and load it to the current page. The geolocation API provides the location of the
device to the app. These APIs enable the building of a more robust app than we could manage in
2012 with PKapp, though current support for various browsers is still mixed. Nonetheless, these
represent the future capabilities for custom data collection apps, so exploring their potential is
worth the effort.
There are two caveats to keep in mind with these APIs. First, the camera API places an
image into the app, then saves it to the database (assuming the database can accept image files).
Image files will be large, so the time required for uploading the data to the primary database will
become correspondingly significant, and the overall size of the database will swell. In fact, most
databases contain a data type known as a BLOB (Binary Large Object) just for such use, but this
201
slows the process of data transfer. Second, the geolocation API defaults to a very imprecise
setting. When a mobile device cannot quickly acquire a GPS signal, the default settings of the
API try to specify location based upon wifi signal or IP address instead. Obtaining good
coordinates will require some programming work as well as a recognition that the
implementation of this feature will slow down the app. Getting good data for location will also
likely require connection to a cellular network.
These APIs would have addressed the first technical difficulty described above.
Incorporating these APIs will likely require more than a basic knowledge of HTML, but a nonprogrammer
with some considerable skill in HTML5 could complete such a project.
Database Advances
When the HTML5 specification was released in 2010 (although not “officially” released
until 2014), there were three approaches to handling client-side databases: localStorage,
IndexedDB, and WebSQL. localStorage was problematic in that it does not always indicate
insufficient storage, which raises the potential for data loss. IndexedDB was not yet recognized
by browsers and could not be implemented at the time. Therefore, we chose WebSQL—the most
broadly used implementation for databases in most browsers— in spite of the fact that it had
already been terminated in 2011. At the same time, because it was still fully functional in
programs like Safari and Chrome, we decided to use it anyway. Essentially, WebSQL was our
only real choice.
Today, the choices are largely the same, but browser support is greatly improved.
IndexedDB is now supported in Chrome and iOS 8, which means that that programs using this
technology will continue to be supported on browsers in the future. Fortunately there are even
202
JavaScript libraries that will provide WebSQL translation for older browsers (essentially iOS
before 8). This means that you can count on the work you do today to be relevant in the future,
and supported by future browsers.
The primary benefit of the changes over the past few years is that the future direction for
development is clear, so that those creating apps now do not need to be concerned with issues of
obsolescence. Also, more developers are approaching their projects through the use of
IndexedDB. So resources and information online can assist with the development of apps that
incorporate IndexedDB storage. Nonetheless, the entire database backend of any custom data
collection app is fraught with technical problems. This could very well be the most technically
complex aspect of your project should you attempt to develop one. Specifically these difficulties
revolve around the challenges of selecting the right database approach, and the lack of
documentation available for such work.
For those seeking to develop a similar app today, the recommended approach is to utilize
IndexedDB while also including a JavaScript library to provide backward compatibility for
browsers with WebSQL support. This would give the app a much broader reach in terms of
supported devices, and would also ensure the relevancy of the approach to the local database into
the future.
Export Problems
Despite the advances of the past few years, data export remains a difficult conundrum for
anyone developing a custom app designed to run without connectivity. Apple has not
implemented the Filesystem API to help address this issue, but there are other good approaches
that simply require some work. For PKapp we exported the data and emailed it so that we could
203
provide another check on the data before incorporating it into the primary database. Today, many
other “to-do list” and note-taking apps provide such functionality through Dropbox or other
similar cloud-based services. Use of a Dropbox account and the Dropbox API may be a
particularly attractive option for any apps being currently developed.
Of course, should a project enjoy reliable connectivity – even occasionally – an app could
be created that simply sends the data to a primary database on a server when connected to the
Internet. Since each entry could be given a unique timestamp, entries could be searched daily to
verify data integrity. In such a circumstance, data transfer becomes a very smooth operation that
is prone to few technical problems.
In the end both of these solutions are simpler than the one we implemented for PKapp in
2012 because an app with reliable connectivity could possess a richer feature set in this regard
than an app designed to work exclusively offline.
Conclusion
The development of PKapp taught us a number of important lessons about implementing
mobile apps for data collection in archaeological fieldwork. In their simplest forms, mobile apps
are not difficult to create – a simple one can be built based upon an RSS feed in minutes. But
when considering the collection, storage, and access of data specific to the PKAP project, there
were no pre-existing commercial tools that could accomplish our goals. In the end we
implemented an app written with HTML5 and some custom JavaScript coding.
Native apps are written for specific operating systems. Web apps are based on the
HTML5 specification. We decided on a web app approach so that we could update the app at any
time and post it online for the team to install in Cyprus almost instantaneously. We could fix
204
bugs as they appeared, or modify features based upon actual field use. We thus could actively
address our design parameters, which called for easy and quick updating of the software. We
also avoided having to write the app for multiple platforms and getting each app and each update
approved for delivery through its respective app store.
The web app development process is even easier today as a host of new tools exist to
facilitate such projects. In addition to a number of JavaScript libraries, frameworks, and APIs,
there are a plethora of tools such as Codiqa to aid the actual development of the front-end of an
app built with HTML5. The ease-of-use present in these tools means that the archaeologist can
be actively engaged in the development of the app, and the software development process
becomes truly participatory. With these tools technical support is needed primarily for
development of the local database, and eventual communication with the primary database
(wherever it may reside).
In the end, collecting data via PKapp was easy and worked remarkably well, matching
our design parameters and meeting all of our fieldwork goals. As a result of our experience using
the app successfully, we see benefits in the incorporation of mobile technologies for collecting
data in the field. There are significant improvements in efficiency and overall time saved, since
entire steps in the older process – particularly the manual process of completing paper forms,
converting that data into electronic format, and reviewing the resulting electronic data – can be
streamlined. The ability to incorporate automatic data validation into the entry process also
makes this approach an improvement over traditional methods which required additional manual
validation. This is not to say that such technical efficiencies do not come without a cost (Caraher,
2015). Indeed, any field team should weigh the benefits of efficiency as they reflect upon where
and when the analysis and interpretation occurs in the archaeological process for the project.
205
But a season of testing provided us with enough observation for our data integrity
concerns that we have great confidence in the quality of data collected via PKapp. With the
advancements and implementation of the HTML5 specification, as well as broader
implementation of JavaScript APIs, we could today even more easily produce web apps for field
data collection that run without connectivity. Consequently, this process is increasingly
accessible to most researchers, and seems worthy of consideration for most projects.
206

2.2. The Things We Can Do With Pictures: Image-Based Modeling and Archaeology
Introduction
It has been five years since Agisoft publically launched PhotoScan, the first cost efficient
and intuitive image-based modeling software…a near eternity in technology years. Further, two
years have passed since the first wave of peer-reviewed studies implementing and testing the
applicability of such software for archaeological purposes (i.e. Verhoeven 2011; Verhoeven et
al. 2012a, 2012b; de Reu et al. 2013; Olson et al. 2013). The combination of these and many
other publications with numerous colloquia, conference panels, and workshops solidify imagebased
modeling’s place as an integral tool for archaeology. The intention here is to present a
critical analysis of the technology by drawing on a set of field applications that highlight how
this technology continues to transform the discipline through a diverse set of methodological and
interpretive frameworks.
Image-Based Modeling: A Short Introduction
Three-dimensional modeling is not a new addition to the archaeological toolkit, as laser
scanners and other 3D modeling techniques, though expensive and requiring highly trained
personnel, have been available for years (Barcelo et al. 2003; Pollefeys et al. 2003). The creation
of digital 3D models from photographs using photogrammetric methods and various algorithms
such as structure-from-motion, however, is a newer innovation. The technology, referred to here
and elsewhere as image-based modeling (Olson and Caraher 2015; Roosevelt et al. 2015), is
available through a handful of commercial (Olson et al. 2013: 248) and open source software
options (Green, Bevan, and Shapland 2014), but Agisoft PhotoScan (www.agisoft.com) has
2
solidified itself as the software of choice because of its ease of operation and quality outputs. The
3D model creation process is pretty straightforward and can be used to model 3D environments
from archaeological objects to trenches and architecture (FIG.1) to even entire sites (see Wernke,
this volume; Olson et al. 2014; Roosevelt 2014). After capturing a set of digital photographs that
provides total coverage of the target, these photographs are automatically located within a locally
or geolocated rectified environment (FIG 1A). The location of the images serves to reconstruct
complex spatial information from 2D data, common points are tracked across images and their
relative positions are mathematically determined. Following the creation of the sparse point
cloud (FIG 1B), the program returns to the photographic dataset to generate a dense point cloud
(FIG 1C). The dense point cloud is in fact just that, dense. Note the visual similarities in Figures
1C (the dense point cloud) and 1E (the 3D model with photorealistic texture). The sparse and
dense point clouds are essentially the skeleton of the final model, representing known points in
the structure of the scene around which the computer can calculate the geometry of a
monochromatic 3D model (FIG 1D). Finally, remembering the relationship between the points in
the photographs and the spatial information in the geometric model, a photorealistic texture is
conformed to the 3D geometry (FIG 1E).
From the processed 3D model, several outputs are possible, the most useful for
archaeological purposes are 3D PDF, GeoTIFF, and Wavefront OBJ. The accuracy of the outputs
depends on numerous factors (resolution of the photographs, software settings, spatial extent,
etc.), but studies have shown spatial accuracy levels of 1–3 cm for areas up to 700 sq m and subcentimeter
for areas less than 25 sq m in area (Olson et al. 2013: 257; de Reu et al. 2013: 1111;
Prins et al. 2014: 193; Quartermaine et al. 2014: 116, 124; Roosevelt et al. 2015: 340).
3
Processing times vary from less than an hour to days depending on scene size, the number of
images captured, software settings, and the performance of the computer processing the model.
Object Level Analyses
Archaeology, as the study of the past via material culture, is a discipline centered on
objects (Hodder 2012; Olsen 2012). The ability to photorealistically generate a 3D model of an
object has opened up new avenues of artifactual analysis. Several scholars have commented on
the visual merits of high-fidelity photorealistic 3D models, which have recently been followed up
by studies offering critical assessments of their interpretive value (see Caraher, this volume;
Roussou et al. 2015). Olson and colleagues used image-based modeling software to create 3D
models of prehistoric handaxes (Olson et al. 2014). These models were then converted into a
printer friendly format (PLY) and three-dimensionally printed (see also McKnight et al. 2015).
Using both qualitative and quantitative methods, the authors demonstrated that a handaxe printed
in both ABS plastic and resin retained the features a lithicist would need to read and study the
object (Olson et al. 2014: 171). The authors proved that 3D models, printed from digital models
produced with an image-based approach, as opposed to laser scanning, can in theory stand in for
the original. Rabinowitz, however, cogently points out that digital renderings, and by extension
their printed outputs, are not true “surrogates” of the original because their creation, unlike linedrawings
and sketches, lacks an interpretive framework (Rabinowitz 2015: 34). Manual
illustration and recording strategies force a level of archaeological engagement and interpretation
(i.e. stratagraphic relationships, architectural associations, etc.), while digital recording does not
necessarily require such a level of preliminary interpretation (Caraher, this volume; Rabinowitz
2015). On the other hand, the handaxe modeling experiment discussed above also indicates that
4
whether the interpretive process occurs before, during, or after the crafting of a 3D model of an
object, it is clear that digital and tangible 3D models have intrinsic scholarly value.
Bevan and colleagues adopted an image-based approach to model various features of the
terracotta warriors found at Qin Shihuangdi’s mausoleum (China) (Bevan et al. 2014). The 3rdcentury
B.C. site contains life-sized replicas of an estimated 8000 soldiers, 520 chariot horses,
and 150 cavalry horses, all of which were constructed from terracotta using sets of standardized
molds (Portal 2007). Artists would also add clay to the face and ears to add a level of
individuality to each warrior. Bevan and colleagues modeled certain features to undertake a 3D
morphometric analysis of the warriors, focusing primarily on ears, but also hands and faces. In
adopting a comparative taxonomic approach, the authors are able to identify a series of microstyles
achieved through subtle variations in construction techniques (Bevan et al. 2014: 251–
254). Beyond mere visual inspection, the authors devised a method for examining a distance
matrix expressing dissimilarity of certain ear features to others within the assemblage using the
model’s dense point cloud. The method is based on the real world assumption that ear
morphology exhibits variation among humans to such a degree that it can be used as a forensic
identifier akin to dentition and finger prints (Pflug and Busch 2012; Abaza et al. 2013). Bevan
and colleagues conclude that although there are a series of core shapes, there is also abundant
subtle variation and no two ears are exactly the same (Bevan et al. 2014: 254). Their work shows
that significant resources were spent by Qin Shihuangdi and his court to individualize the
terracotta army in an attempt to mimic a real military force. This study, as well as others like it
(Clarkson, Shipton, and Weisler 2014 and Shipton and Clarkson 2015 on Hawaiian adzes;
Grosman et al. 2014 and Spring and Peters 2014 on ancient lithics), demonstrate the potential of
image-based modeling and 3D modeling in general for morphological and taxonomic analyses of
5
objects.
Landscape/Field Recording and Volumetrics
Arguably, image-based modeling has had the largest impact in the field with numerous
projects adopting the technology in various iterations at the sub-site level (Miller et al. 2014),
site level (Quartermaine, Olson, and Howland 2013; Forte 2014a; Quartermaine, Olson, and
Killebrew 2014; Roosevelt et al. 2015; Toumazou et al. 2015), in underwater contexts (Buxton
et al., this volume; Demesticha, Skarlatos, and Neophytou 2014; Jaklic et al. 2015), and across
landscapes (Wernke et al., this volume, Opitz and Cowley 2013; Smith et al. 2014; Roosevelt
2014; Opitz and Limp 2015). Of these studies, three merit special consideration here as they, in
this author’s humble opinion, will serve as benchmarks for future digital recording strategies.
The 3D Digging Project, which began at Çatalhöyük (Turkey) and spearheaded by Forte
in 2009, endeavors to record in 3D complete stratigraphic profiles from a selection of excavation
units in an attempt to reconstruct digitally the deposits as well as interact with them in a virtual
environment (Forte 2014a: 4). Under the larger umbrellas of cyberarchaeology and teleimersive
archaeology (Forte 2010, 2014b, see also Levy et al. 2012), Forte uses the orthorectified
georeferenced TIFF image (henceforth orthophoto, a photorealistic image with spatial distortion
corrected that is embedded with a real world coordinate system) to digitize and annotate features.
For Forte, the scholarly value of image-based modeling is in its ability to generate accurate and
photorealistic reproductions that aid in spatial recording and for use with other technologies,
such as laser scanning and infra-red photography, within virtual reality for education, public
outreach, and as a means to interact with archaeology in a new way (Forte 2014b: 26–28).
Underwater archaeology presents certain obstacles that terrestrial archaeology simply
6
does not have to overcome (see Buxton et al., this volume). Issues such as short underwater
study windows, limited visibility, the mobility of the ocean/river/lake bed, and the significant
financial investment necessitate a dynamic recording system. Demesticha, Skarlatos, and
Neophytou offer an image-based modeling approach at the Mazotos Shipwreck site (Cyprus) that
harnesses the dense point cloud and orthophoto, as opposed to the photorealistic model, as the
primary basis of their recording framework (2014). The authors utilize the orthophoto as the
main method for basic recording, labeling, and digitizing features. Yet their innovative use of the
dense point cloud as a collection of reference points to model and thereby record the remains
comprising the site in three dimensions is a pioneering use of image-based modeling
(Demesticha, Skarlatos, and Neophytou 2014: 146–147, see also Grøn et al. 2015). The dense
point cloud provides the outlines of individual ceramic forms and the authors’ familiarity with
Hellenistic and Roman transport shapes are combined to create an accurate, true to scale 3D
reconstruction of the underwater site. This method also allows them to approximate a ship’s
overall volume and inventory and trace the taphonomic processes following the initial wreck,
simply on the basis of a systematic photography session with good ground visibility
Any image-based modeling practitioner who has deployed this technology in the field is
aware of certain limitations, especially from a mobility standpoint. The current author
experienced two recurring problems at a number of eastern Mediterranean sites. First, depending
on the number of photographs taken, image-based modeling software tests the limits of even
better equipped computers and laptops. This will likely be a non issue in the near future, but at
present it is difficult to process a 3D model in the field owing to both environmental (heat, dust,
precipitation, etc.) and practical (interruption of workflow, onsite distractions, access to
electricity, etc.) considerations. Second, the transfer of data from the individual processing the
7
images to the field team and the manipulation of the 3D model and its 2D derivatives onsite can
be problematic on account of large files sizes and issues related to versioning and storage
location. Roosevelt and colleagues, however, have made great progress in solving these issues
with the Kaymakçi Archaeological Project (Turkey) (Roosevelt et al. 2015). Their “born digital”
(Roosevelt et al. 2015: 326, for the term see also Austin 2014) recording system is multi-faceted
and uses the following outputs for its image-based models: orthophotos (as a reference for
digitization, measuring, and the like), georeferenced digital elevation models (for spot elevation
checks and vertical control), and dense point clouds (to calculate volume) (for volumetrics, see
also Castro et al., this volume; Miller et al. 2014; Jaklic et al. 2015). To alleviate the issues
raised above, the authors devised a wireless communication system to exchange photographic
datasets and processed models between team members onsite and those at an offsite computer
lab. The wireless network was also connected to a relational database stored on a server, which
permitted secure data storage and a means to reliably access previously saved data anywhere
with an internet connection. From an image-based modeling standpoint, the project’s
infrastructure helped alleviate issues related to the mobility of the software, while the use of the
software served as an integral component to their 3D and, more importantly, volumetric
approach to recording.
The Kaymakçi Archaeological Project and the excavations at Cástulo are using dense
point clouds to create watertight volumetric renderings of stratigraphic units (Roosevelt et al.
2015: 337–339; Castro et al., this volume). Having processed dense point clouds with
PhotoScan, the projects use separate 3D modeling programs, CloudCompare for Kaymakçi and
Blender for Cástulo, to develop a closed volumetric entity representing the 3D area of the unit
modeled. Both projects acknowledged the potential of volumetric recording for ongoing
8
excavation. Onsite manual drafting is mostly replaced with image-based modeling, whereby the
software is tasked to record the tops and bottoms of all units. The records are then combined and
modeled using PhotoScan and either CloudCompare or Blender to generate volumetric records.
This process is revolutionary for onsite recording as it provides a truly accurate digital 3D record
of excavations and can take the human element out of stratigraphic recording, which as noted
above has both positive and negative implications.
Conclusions and Continued Musings on Future Directions
As the number of presentations at the Mobilizing the Past for a Digital Future: The
Potential of Digital Archaeology workshop made abundantly clear, image-based modeling in
archaeology has evolved from a simple means of visual display to a legitimate analytical tool by
means of its combination with other technologies, recording strategies, and interpretive
frameworks at site and object scales. Its deployment in the field has led to faster and more
accurate data recording with comparatively small financial investment. Yet, the technology’s
scholarly value as more than a tool for simple visualization is contingent upon its interaction
with, and ultimately assimilation into, existing modes of artifactual analysis (seriation,
taxonomy, taphonomy, etc.) and systems of recording. Its adoption as a component to larger
digital recording systems is underway and one would expect to see development in the future
along the lines of Forte (2014a), Roosevelt and colleagues (Roosevelt et al. 2015), Opitz and
Limp with High-Density Survey and Measurement (HDSM) (Opitz and Limp 2015), Castro and
colleagues (Castro et al., this volume), and the most recent iterations of Reconstruction and
Exploratory Visualization: Engineering meets Archaeology (REVEAL) (for an introduction see
Kimia 2010; Gay et al. 2010; Fabbri and Kimia 2010; Galor, Sanders, and Willis 2010). Granted,
9
these reports vary intellectually and practically, but they have a shared view in that image-based
modeling can and should be utilized in the same way as a total station, differential GPS unit, GIS
software, or digital camera. Given its many benefits, like it or not, image-based archaeological
recording appears here to stay, and in the immediate future, this question of how to integrate it
into existing or redeveloped methods and practices will likely be a subject of scholarly
discussion and debate. Ideally, such pluralist discourse often result in best practices.
On the technological side, faster processors, larger memory capacity, and more robust
graphics cards will speed up processing times in the future. Since its initial public offering in
December 2010 with version 0.7.0, Agisoft has released 45 updates to PhotoScan. Some updates
are simple bug fixes, while others are significant revamps that introduce new tools. With an
average of a new version every five weeks, companies like Agisoft make a concerted effort to
keep the technology current, which will likely continue given the demand. It is also possible that
the process itself, which consists of five steps not including exporting outputs, will be
streamlined either within the software or with the development of hardware capable of
processing models immediately after photo capture. Needless to say, the pace of change in
technology is rapid and there is nothing to suggest that image-based modeling has reached its
flourit in technological or archaeological terms.

2.3. Beyond the Basemap: Multiscalar Survey through Aerial Photogrammetry in the
Andes
Steven Wernke, Vanderbilt University
Unmanned aerial vehicles (UAVs, popularly known as “drones”) have revolutionized
archaeological mapping. More broadly, computational photography has transformed our
capabilities to capture high resolution spatial representations of archaeological phenomena in the
field, from the scale of small features within excavations (Opitz 2015; Poehler 2015; Roosevelt
et al. 2015) to large sites and encompassing landscapes (Chiabrando et al. 2011; Fallavollita et al.
2013; Mozas-Calvache et al. 2012; Wernke, Adams, and Hooten 2014; Olson et al. 2013). A
quiver of generally inexpensive and efficient photogrammetric field tools are now within the
reach of most practitioners across these scales (Figure 1). High resolution and high fidelity
orthomosaics, digital elevation models, and textured 3D models can now be captured using
consumer grade digital cameras through photogrammetric software. In just the last few years, the
use of these technologies has spread from innovators to early adopters to what is now the early
majority of the bell curve of the archaeological research and conservation communities, as
technical and cost barriers have lowered. The benefits are readily evident: richer and more
granular datasets through fast, simple, and inexpensive techniques (see also Olson, this volume).
Digital 3D and 3D-printed distribution greatly broaden the accessibility and impact of the results
to researchers, educators, descendent communities, and global publics.
Here we present a multiscalar perspective on the progress and prospects of digital aerial
photogrammetry in archaeology: at the scale of landscape prospection using a fixed wing UAV,
at the scale of large site survey using a meteorological balloon, and at the scale of individual
211
domestic architectural complexes using pole aerial photography. We illustrate how these aerial
photo systems equipped with inexpensive digital cameras can be used to rapidly acquire mass
imagery for processing into a variety of 2D and 3D digital images and models. We contend that
the efficiency, fidelity, and cost-effectiveness of these methods are of such a qualitatively
different character compared to traditional methods that they are transformative for the practice
of both research-oriented field archaeology and cultural heritage management. That is, rather
than acting as an add-on to traditional survey or excavation projects, these methods enable new
kinds of field methodologies, in large part because conventional compromises between scale and
granularity of spatial representation are greatly mitigated. This emerging field of “spatial
archaeometry” (Jesse 2014) promises to more fully and quickly “capture the complexity”
(Wernke, Adams, and Hooten 2014) of ancient settlements and landscapes.
These advances are of equal importance for cultural heritage management. With the
alarming loss of archaeological heritage around the world—including the recent specific
targeting of monumental archaeological sites for violent destruction (Danti 2015; Harmansah
2015)—the importance of capturing whole site “digital surrogates” (sensu Rabinowitz 2015)
through aerial photogrammetry transcends academic interests (see, e.g. Ioannides et al. 2012;
Hesse 2013). Archaeological patrimony in general is inexorably degrading and disappearing. It is
a one-way, entropic process with relatively rare exceptions of slow and expensive conservation
projects, usually at monumental sites. Likewise, the expense and technical barriers to earlier 3D
scanning technologies, pioneering 3D site scanning efforts were undertaken by specialized
consultancy firms such as CyArk (see http://www.cyark.org/about/). Aerial photogrammetry has
now dramatically lowered those barriers to enable the production of whole site digital surrogates
of the many “lesser” threatened sites (that is, the great majority) and landscapes.
212
With these concerns in mind, this chapter addresses both heritage management and
research-oriented problems. The first part presents a case study in rapid aerial photogrammetry
documentation of sites and landscapes along the road network of the Inka Empire in Peru. This
project was a collaborative effort between Giancarlo Marcone, director of the Proyecto Qhapaq
Ñan (Inka Royal Highway Project), and Steven Wernke. Together with the other co-authors of
this paper, we set out to document sections of the Qhapaq Ñan associated with major Inka
imperial installations from near sea level to 3900 m, along one of the main transverse highways
that connects the primary imperial highway along the Pacific coast to its counterpart in the
highlands.
While the Qhapaq Ñan case study illustrates the speed and utility of UAV-based
photogrammetry for heritage management, the second part of the paper explores its richness and
potential for integration with tablet-based architectural survey using high resolution (subdecimeter
to centimeter) balloon- and pole-based aerial orthomosaics and 3D models. This
research project, the Proyecto Arqueológico Tuti Antiguo (PATA, Ancient Tuti Archaeological
Project - PATA) was designed from the ground up to use high-resolution aerial photogrammetry
as central spatial reference data for mobile GIS-based mapping (see Wernke 2015; Wernke,
Adams, and Hooten 2014; Wernke and Siveroni Salinas 2013). PATA is directed by Wernke,
and Gabriela Oré, Carla Hernández, and Abel Traslaviña played instrumental roles in the
execution of its methodology. PATA investigates the transition from late prehispanic to Spanish
colonial times, focusing on an Inka administrative center that was converted into a planned
colonial town in the high Andes (4100 m), built as part of the Reducción General de Indios
(General Resettlement of Indians) a mass resettlement program executed throughout the
Viceroyalty of Peru in the 1570s. This large town—originally named Santa Cruz de Tuti—
213
encompasses nearly 40 ha at an elevation of 4100 m, with over 500 remarkably well-preserved
buildings in a gridded street plan. With its excellent architectural preservation, Santa Cruz de
Tuti provides an ideal context to investigate little-understood aspects of the General
Resettlement, but it also poses significant challenges given its scale, complexity, and remoteness.
Traditional mapping techniques would require major outlays in time and labor, and would result
in a relatively impoverished cartographical representations. We present a methodological
approach for mapping extensive and complex architectural remains using orthomosaics as base
imagery for tablet-based in-field digitization, with much richer attribute data registry than
possible through traditional mapping methods.
Digital Heritage Management: The Inka Royal Highway Project
The Proyecto Qhapaq Ñan (Inka Royal Highway Project), a special project of the
Ministry of Culture, Peru, faces the monumental challenge of documenting and conserving the
many thousands of kilometers of ancient roads of the Inka Empire in Peru (see
http://www.cultura.gob.pe/en/tags/proyecto-qhapaq-nan). From a heritage management
perspective, the Proyecto Qhapaq Ñan faces major challenges of scale and representation as it
encompasses much of the territory of the modern republic of Peru, with over 3,000 km of the
ancient road system documented in the field and many hundreds of associated Inka sites (Figure
2). Mapping the entirety of the ancient road network in detail would be impractical, and noncommercial
satellite imagery is not of sufficient resolution to detect important elements of the
road system or preserved architecture in archaeological settlements. Thus, UAV-based mapping
is especially attractive for the Proyecto Qhapaq Ñan for its speed and low cost, its ability to
render a variety of vector and raster-based 2D and 3D formats, and the possibility of recording
214
sites and landscapes many times, enabling seasonal or inter-annual, and long-term monitoring
(longitudinal or time series analysis). Our collaboration is part of a broader effort by the Ministry
of Culture, Peru to seek methods for using UAV photogrammetry to document its thousands of
archaeological sites (see, e.g., http://www.nytimes.com/2014/08/14/arts/design/drones-are-usedto-
patrol-endangered-archaeological-sites.html).
The Proyecto Qhapaq Ñan is also developing a new approach to managing this vast
cultural patrimony, moving away from a previous site-based framework toward one centering on
cultural landscapes and corridors around the Inka roads. This is more appropriate to the ancient
practices associated with the Inka imperial road network itself, and in terms of patrimonial
stewardship. Inka aesthetics and engineering worked at the scale of entire landscapes rather than
settlements, neighborhoods or buildings (Protzen 1993; Niles 1999; Nair 2015; Kosiba and
Bauer 2012). From a stewardship perspective, the scale of the Qhapaq Ñan far exceeds the
resources of the state and descendent communities are often literally dislocated from their
cultural patrimony through the declaration of sites as “intangible zones”. Through a cultural
landscape concept, the Proyecto Qhapaq Ñan seeks the participation of local stakeholders,
placing sites within a living, working contemporary landscape. As part of this new approach, the
Proyecto Qhapaq Ñan is organized by tramos (tracts) between major Inka imperial centers. Our
collaborative project focused on one of the major transverse Inka highways connecting the coast
and highlands: the tramo between the monumental center of Tambo Colorado, located in the
upper reaches of the coastal Pisco Valley, and Vilcashuamán in the highlands of the department
of Ayacucho.
The collaboration also enabled testing of the performance of a fixed wing UAV at
different elevations. Compared to multirotor designs, fixed wing UAVs fly faster, with longer
215
flight times, and on balance a bigger altitudinal range of operation, making them optimal for this
kind of large site and landscape prospection. The UAV used for the project was based on the
TechPod (http://hobbyuav.com/), a large fixed wing airframe. This design was chosen for its
large wingspan (2.67 m) and wing area (3903 cm2), facilitating large payload (1 kg of
battery/payload), long flight times (capable of flights in excess of 1 hour), stability and slow
cruising speed (59 km/hr). The large wingspan and wing surface are also crucial for achieving
adequate lift for takeoff and stable flight in high elevation contexts. The TechPod is an open
source and low-cost UAV.1 The TechPod was equipped with a small consumer point and shoot
camera (Canon w/Canon Elph 300 HS camera; with a 12.1 megapixel CMOS sensor) with
CHDK (Canon Hack Development Kit) installed to enable the use of an intervalometer script and
capture of images in raw format (uncompressed values from the CMOS sensor). Photos were
taken every four seconds—an interval chosen based on the relatively high flight paths we
planned for large scale landscape aerial survey. A short video of a flight at Tambo Colorado can
be downloaded.2
Case Study: Tambo Colorado
Tambo Colorado is an elaborate Inka imperial center of painted adobe palaces, plazas,
and ceremonial structures in the Pisco Valley. It is located on the main Inka highway that
connects to the highland imperial center of Vilcashuamán, and eventually on to the imperial
capital of Cuzco. Just to the northwest of Tambo Colorado, the Qhapaq Ñan turns northwest
toward the Chincha Valleyand joins the main coastal highway (see Figure 3).
1 The airframe costs $160 and a ready to fly kit (assembly required) costs $1100. Our vehicle featured a number of
customizations, including motorized doors for the camera bay and a larger than standard motor for high elevation
flights. With the radio controller, a second airframe for spare parts, extra batteries, motors, propellers, and other
parts, the total cost of the system was $3,000. Complete CAD files of its design are online.
2 http://www.vanderbilt.edu/sarl/media/Tambo_Colorado_flight03.mp4
216
With its spectacular layout and architectural preservation, Tambo Colorado has a long
history of research and archaeological mapping. German archaeologist Max Uhle mapped and
excavated there in 1901. His remarkably accurate maps remain a vital reference for researchers.
Jean Pierre Protzen and Craig Morris began a long-term investigation of the site starting in 2000.
This project included extensive 3D laser scanning by CyArk during four field seasons (2001,
2003, 2004, 2005) in several areas of the site core, providing unprecedented renderings of palace
complexes and many features, including details such as the many trapezoidal niches, windows,
and doorways (see http://www.cyark.org/projects/tambo-colorado/overview). The logistical
complexities of terrestrial laser scanning ultimately limited the coverage of these operations,
however. Our objective was to complement these previous efforts by placing the site of Tambo
Colorado in its broader landscape—mapping at mid-scale—while also providing adequate
resolution to discern architectural detail.
Our fieldwork at Tambo Colorado took only two days: one day to set ground control
points using an RTK GNSS system (Topcon GR5) with sub-centimeter accuracy (0.5 cm
horizontal, 0.9 cm vertical),3 and one day to obtain the UAV-based imagery. Two flights—one
approximately 10 minutes, the other approximately 20 minutes—were flown over the site and
surrounding landscape, following the course of the Qhapaq Ñan into and out of the site.
From the flight imagery, 467 images were selected for photogrammetric processing in
Agisoft Photoscan (version 1.1.5). Of these, 465 were automatically aligned in about two hours
of processing time on an advanced workstation.4 In-field processing on a laptop would also be
possible by dividing processing into two or three “chunks” (groups of photos covering
3 The GCPs were recorded in UTM coordinates (zone 18S), WGS 1984 datum, using Geoid EGM_Peru 2008 for
elevations.
4 Photogrammetric processing was performed in the Spatial Analysis Research Laboratory, Vanderbilt University
(http://www.vanderbilt.edu/sarl). The workstation specifications include Intel Xeon E5-1650 v3 CPU, 128 GB
RAM, and dual NVIDIA K4200 GPUs.
217
contiguous areas). The resulting orthomosaic encompasses an area of 70 hectares at a pixel
resolution of 6.8 cm (Figures 4 and 5). The DEM (Digital Elevation Model) resolved to a 13.6
cm raster grid cell size (Figure 6). The shape of the area prioritizes documentation of the ancient
road in relation to the site, which runs roughly parallel to the river and modern highway.
Compared to previous mapping efforts at the site, our UAV-based orthoimagery, DEM,
and 3D model document a much larger area, placing Tambo Colorado in its fuller landscape
context, while still at sufficient resolution to observe most architectonic details. It thus
complements the work of Uhle, Protzen, and Morris, which focused on the monumental core.
The scale and resolution of this project enable new observations and heritage management
capabilities. For instance, the orthoimagery and 3D models enable the project to evaluate risks
not only to the monumental core but also to the sections of the Inka road through the site. In the
core of the site, the primary threats are tourist foot traffic and damage from alluvial and colluvial
flows. The photographic source data for the orthomosaics facilitates monitoring of foot-traffic,
since patterns of movement through the site can be inferred from the imagery itself. To the east
of the site core, a remarkable section of the ancient road is preserved upslope of the modern
highway. There, the ancient road traverses a number of quebradas (ravines) as the road directed
traffic to and from the highlands. In these crossing points between the quebradas and the road,
the highway was reinforced with large stone-faced revetments. These revetments are variably
preserved and threatened. The orthoimagery enables monitoring of ongoing and active alluvial
and colluvial flows through these quebradas and across the ancient road, thus facilitating
prioritization of conservation efforts. Because of the low cost and time investment in this
method, site monitoring could be completed on a regular (e.g., annual) basis to monitor site
changes and erosion. The area documented can also be observed in 3D by exporting a
218
COLLADA (COLLAborative Design Activity) 3D solid model. This model has been uploaded
to Sketchfab.com (a 3d model sharing site) for viewingand downloading.5
Finally, the orthoimagery served as a base for a fast vector-based representation of the
architectural core, which was done using a CAD program (to comply with Ministry of Culture
reporting requirements) (Figure 7). Though CAD editing was done on a desktop computer, such
digitization work could also be accomplished on a mobile GIS platform on a tablet (or laptop) in
the field (using, for instance FAIMS [see Ross and colleagues, this volume], GIS Pro, or QGIS
for Android). As discussed below, this methodology offers considerable advantages in speed and
richness of attribute data registry compared to traditional total station-based approaches to
producing site architectural plans.
Case Study: Inkawasi de Huaytará
Inkawasi de Huaytará is the next major Inka imperial site inland from Tambo Colorado
on the Pisco-Vilcashuamán tramo of the Qhapaq Ñan. Located high in the western range of the
central cordillera, Inkawasi is situated at 3850 m, at the lower edge of the puna (high elevation
grassland). Inkawasi is a curious site and its basic functions remain in question. It is small and
isolated from local settlements, but other attributes point to highly exclusive elite-only access to
certain sectors of the site. Unlike Tambo Colorado, Inkawasi has been the subject of very little
systematic study. During the same 1901 expedition that produced the architectural map of
Tambo Colorado discussed above, Uhle briefly visited the site and speculated that it may have
served as a tambo (waystation) for the Inka to rest after one day’s journey inland on the Qhapaq
Ñan from Tambo Colorado (Protzen and Harris 2005:87-88). John Hyslop reconnoitered
Inkawasi de Huaytará as part of his survey of the Inka road system (Hyslop 1984:105-106), and
5 Interact with the 3d model on Sketchfab: https://skfb.ly/HwDP
219
drafted a sketch map. Given that the road climbs another 1200 vertical meters in just the 14 km
between Inkawasi and the next Inka site to the east (the site of Huaytará) (Hyslop 1984:104),
facilities for lodging, water, and food might be expected.
Inkawasi was certainly more than a waystation, however, since its architectural
complexes include features such as double-jamb trapezoidal doorways (which marked thresholds
to exclusive elite spaces) and buildings made of fine precision-fitted Inka stone masonry—
clearly the work of specialized imperial stonemasons and features found only at elite Inka
imperial sites (Protzen 1993; Gasparini and Margolies 1980; Niles 1999). It may have functioned
as a provincial estate for traveling Inka nobility and the emperor himself (Sofia Chacaltana, pers.
comm. 2015). Typical of Inka “aesthetics of alterity” (van de Guchte 1999) the site also appears
to have been emplaced in the local landscape with an eye toward fitting its highly exclusive
spaces in relation to a prominent cliff band and rock outcrop in the gorge of the Inkawasi river.
The royal highway itself passes through a cleft in this outcrop, producing a dramatic framing of
the site as travelers descend from the highlands. Rituals connecting humans to the chthonic
beings in the landscape were almost certainly central to its placement and design. Understanding
or conveying these aesthetic and functional possibilities requires something beyond a basemap:
spatial representations at finer resolution than off-the-shelf satellite based DEMs or imagery, and
richer than traditional topographic and architectural survey. UAV-based high resolution 3D
mapping meets these requirements.
Most recently, the Proyecto Qhapaq Ñan completed follow-up conservation work at the
site to check and repair earlier site conservation by the Ministry of Culture, Peru, and is working
with the local community to develop an integrated conservation, tourism, and community
development plan, which includes the site and its surrounding landscape (Antezana Ruiz 2015).
220
Our collaboration to produce UAV-based mapping was designed as an integral part of the
information that the Proyecto Qhapaq Ñan and local community authorities will use in
formulating this plan. Thus, both research and heritage management goals are addressed by the
project.
Our UAV work at Inkawasi was completed in one afternoon, following a day of work
placing the ground control points with an RTK GNSS. We used the same flight parameters,
motor, and propeller as at Tambo Colorado, and the TechPod performed well. Achieving takeoff
required throwing the UAV from a steeply sloping hilltop (see short video online),6 permitting an
initial drop in altitude to gain speed and sufficient lift. The imagery was captured over three brief
flights (all about 10 minutes). The intervalometer was again set to four seconds and the imagery
used in photogrammetric processing was captured in about 25 minutes over three flights. Of the
selected photos, 343 were aligned to produce an orthomosaic and DEM covering a 99.8 ha area.
Within this large area, the orthomosaic resolved to a pixel size of 8.6 cm (Figures 8 and 9), while
the DEM provides 17.3 cm resolution—very close to that achieved at Tambo Colorado (Figure
10).
The orthoimagery, DEM, and 3D models generated by this project will be integral to their
subsequent operations, obviating the need for costly and slow traditional topographic survey,
with much higher resolution topographic results, combined with precise color orthoimagery of
the site in its fuller landscape context (see 3d model online).7
Architectural Survey at a Planned Colonial Town
6 Download video at http://www.vanderbilt.edu/sarl/media/Inkawasi_first_flight.mp4
7 See the 3d model on Sketchfab: https://skfb.ly/HwEo
221
The speed and resolution of UAV-based photogrammetry are of obvious utility,
especially in this era of accelerating loss of archaeological patrimony. But the technological
advances in both the UAV and photogrammetry fields have been so fast that methodological
frameworks have generally not yet adapted to the new capabilities and challenges they present.
Building on previous work built on an integrated photomapping and mobile GIS excavation
workflow (Tripcevich and Wernke 2010), Wernke recently began a new archaeological project
focused on a planned colonial town with extensive well-preserved architecture in the high
reaches of the Colca Valley of southern Peru. This settlement, Santa Cruz de Tuti, is known
today as Mawchu Llacta (“Old Town”) by its descendent population in the modern community
of Tuti, who reside just a few kilometers downslope from their ancestral town.
Mawchu Llacta was built as a reducción (literally, “reduction”) town as part of the mass
forced resettlement program known as the Reducción General de Indios (General Resettlement
of Indians) in the Viceroyalty of Peru. This was one of the largest forced resettlement programs
enacted by a colonial power, affecting some 1.4 million native Andeans (Mumford 2012). The
Viceroy Francisco de Toledo, charged with establishing a new colonial order after a generation
of Spanish plunder, indirect rule, and Inka insurrection, ordered the forcible resettlement of
indigenous communities as part of a general survey of the Viceroyalty of Peru between 1570 and
1575. This massive social experiment was premised on the notion that by rebuilding indigenous
communities literally from the ground up, they would become more like model subjects and
Christians and a new social order (policia) would emerge.
A theory of built environment was at the core of the Reducción. But archaeological
research on the topic is just beginning, and surprisingly little archival research has focused on it.
Basic questions remain about how the actual resettlement and construction of these towns was
222
enacted, how decisions were made about where and how many to build in a given area, and how
domestic and public life within them was organized. Mawchu Llacta is both exceptionally wellpreserved
and exceptionally documented in written texts, providing a virtually unparalleled
opportunity to elucidate these dimensions of the resettlement. As an archaeological microhistory,
the archaeological research at Mawchu Llacta would have to begin with detailed mapping and
architectural survey and surface collections. Wernke’s project has just completed this first phase,
with the subsequent phase of excavations beginning in 2016 (see Wernke 2015).
The site is situated at 4100 m in the high puna grasslands, and is quite extensive. It is
composed of a regular checkerboard grid of urban blocks extending about half a kilometer on a
side, with a total site area of about 40 hectares. Within this gridded street plan are over 500
standing fieldstone buildings in varying states of preservation. The site is also situated in the
location of a major Inka site, which was likely the administrative center for the upper section of
the Colca Valley. The site core centers on two plazas—one of which is trapezoidal and was
likely the center of the Inka settlement, and the other rectangular with six chapels. The church,
facing the trapezoidal plaza, is very large with a 50 m long nave. The arched entry to the church
and one of its bell towers remain intact as well.
The site thus presented both major opportunities and major challenges: an accurate “base
map” was clearly required to address the core research questions, but producing one through
traditional methods (via total station survey) would be a daunting, slow, and ultimately
expensive undertaking with relatively data-impoverished results. Ideas for producing something
“beyond a basemap” during the first phase of the project developed at a time when a number of
the technologies (widely discussed in this volume) were only nascent (but quickly ramping up):
iPads and early Android tablet devices were introduced to the market in 2010; a relatively small
223
number of manufacturers and DIY hobbyists and professionals were coalescing in a burgeoning
UAV market and maker culture. It seemed opportune to design a project building on these tools
from the outset.
Technical details of the project design have been presented elsewhere (Wernke, Adams,
and Hooten 2014), but in outline, the concept for mapping and architectural survey was to
conduct UAV-based low-altitude photogrammetry combined with tablet-based mobile GIS. The
orthoimagery from the UAV would serve as the primary spatial reference for digitizing
buildings, walls, and other features directly onscreen in the field using a mobile GIS app.
Mapping and architectural survey could thus be conducted simultaneously, producing rich
datasets that combined color orthoimagery with vector based plans of building and other
architectural elements, with attribute data associated with each feature.
The project eventually succeeded in executing this methodology, but not in sequence and
not without initial setbacks, most of which were a consequence of the immature nature of the
technologies at the time of the first phase of fieldwork (during July and August of 2012 and
2013), and the difficult conditions of the site setting—especially the challenges of high altitude
atmospheric conditions for UAV flight. Experimentation with two different UAV platforms in
2012 and 2013 failed to produce reliable flight in these extreme conditions. These difficulties
were the initial impetus for moving to the TechPod and developing the collaboration with the
Qhapaq Ñan Project discussed above. Though we did capture over 2000 images with the UAVs
at the site, image quality and coverage were uneven and photogrammetric results did not meet
the project requirements. Thus, during the 2013 season, we opted to use a tethered
meteorological balloon as the photographic platform (a widely used and proven method; see
Bitelli et al. 2004; Poehler 2015; Olson et al. 2013). This technique was not without its
224
difficulties and was much slower, but it did produce virtually full-coverage orthoimagery of the
site.
The architectural survey with tablet-based mobile GIS proceeded apace despite the
challenges the project faced with the UAVs. The project was experimental in this aspect as well,
since we initially acted as alpha testers for an early version of the Android-based mobile
application for the FAIMS (Federated Archaeological Information Management System—see
chapter by Ross in this volume) Project. FAIMS is now several generations beyond this early
version and is a field proven product, but at the time we were just starting to work out issues of
user interaction, data structure, and data synchronization, so it was not yet ready to be used as a
primary data collection system. After these FAIMS field experiments, we switched to a
commercial mobile GIS for iOS—GISPro by Garafa Inc. GISPro met most requirements of the
project: the user can create point, line, and polygon themes (exported as shapefiles), which can
be generated by activating the tablet GPS (with options for using an external antenna) or by
plotting on screen. It is designed as a single-user/team system, however, with no central
database. Therefore, data synchronization to a central geodatabase was manual, requiring
considerable data management effort.
In the field, however, GISPro worked quite well, especially in terms of user interaction,
requiring minimal training (most students could learn the interface and data entry aspects in a
single day). We drew features on screen for nearly all aspects of the project, since we were
digitizing architectural features using a georeferenced airphoto as reference data. It was critical
for our teams to be able to draft directly in the field while directly observing the feature in
question to ensure proper registry of wall joins and seams and many other architectonic details
(niches, doorways with lintels intact, which are not evident in plan view, etc.). GISPro also
225
allows user specification of attributes using an intuitive form-based interface (including options
for controlled vocabularies in the form of drop down menus). For buildings, we produced an
extensive form with up to 65 attributes on building style, form, dimensions, and a range of
architectural details (niches, doorways, other features). We also made polygon themes for
miscellaneous features and for collection areas within structures, line themes for walls that define
unroofed areas (domestic compounds, corrals, blocks, and streets) and for canals, and point
themes for lichenometric specimens (we measured specimens of the Rhizocarpon lichen to date
architecture at the site), piece plotted surface collections, and dogleash surface collections. Using
this system, four survey crews moved through the site and collected all data, generally covering
1-2 blocks (depending on architectural complexity and density) per team a day. In approximately
three months of fieldwork, a draft GIS of the site was completed, with all attributes recorded in
the field.
Our balloon-based imagery capture was completed over the course of three days. The low
atmospheric pressure at this altitude requires a larger volume of helium, and thus a much larger
balloon than would be needed nearer to sea level. We used a 3 m3 latex meterological balloon to
ensure adequate lift for our camera (the same Canon Elph 300 HS). We used two tethers to help
control the balloon and to minimize the visibility of the string in the frame (by spreading the two
walkers widely). Also, the camera was strung between the tethers on a picavet to aid in
maintaining a nadir camera orientation. The balloon was generally flown 25-40 m in altitude,
with the camera intervalometer set at 10 seconds, as operators walked in a lawnmower pattern
through the site.
Over 3000 usable photos resulted from the balloon flights. Photo sequences were divided
into eight chunks for photogrammetric processing. These chunks provide virtually full coverage
226
of the site (with a few small voids). The resulting orthomosaics are quite detailed, with 5 cm
resolution in most cases. At this resolution, individual stones that make up the tops of walls are
generally clearly visible (Figures 11-13).
With the processed orthomosaic finished in 2014, we then revised the draft geometry of
the architecture digitized in the field from the coarser airphotos. The key to maintaining fidelity
in this process is that the original field data, though geometrically imprecise, was topologically
correct—that is to say, wall joins and the like were drafted as observed. These are the key data
for relationships of horizontal stratigraphy, and were preserved through the editing process. Of
course, this step would be obviated had the original workflow gone according to plan. But our
situation can be considered something of a special case, given the extreme conditions of the site
compared to most archaeological projects. In any case, now, with our larger UAV and
experiences from the Qhapaq Ñan collaboration we expect that the UAV-orthoimagery-feature
digitization/attribute registry workflow will work in future projects. Also, consumer multirotor
UAVs have emerged in just the last year that far outperform anything that was available when
we started the project: the DJI Phantom 3, DJI Inspire, and 3DR Solo are all rated to fly at least
to 4500 m (the Solo and Phantom 3 considerably higher). In short, the technical barriers that
impeded the UAV aspect of our project have been overcome.
The resulting GIS is composed of 495 structures (composed of 597 structural elements),
1258 walls, and a number of other features with all field-collected attribute data integrated in a
PostGreSQL/POSTGIS database with remote access (Figures 14 and 15). This is now the central
database for the project, which we are accessing and editing locally and remotely via QGIS.
Pole Aerial Photography for Detailed Architectural Rendering
227
Lastly, in preparation for the excavation phase of the project, we selected areas of interest
for excavation for more detailed photogrammetric survey using pole aerial photography. Polebased
photography is inexpensive, simple in execution, and enables closer and more precise
camera placement with respect to the subject matter than UAVs. We used an 11 m carbon fiber
fishing pole modified for PAP through the Public Lab (
http://store.publiclab.org/collections/mapping-kits/products/pole-mapping-kit). We set Ground
Control Points (GCPs) with RTK GNSS (~1 cm horizontal accuracy) and photomapped domestic
compounds and other areas of interest, using a Canon S110 and GoPro Hero 4, set at an interval
of 5-6 seconds.8 Three days of fieldwork produced photos of four areas of interest: three
compounds we identified as likely households of ethnic lords (kurakas) and an area adjacent to
the trapezoidal plaza that we hypothesize was a ceremonial platform or other important shrine
(huaca) in the original Inka center. A chapel is oriented in one corner of this area, its entry facing
the opposite direction, oriented toward the primary entry and façade of the main church. The
(nominal) resolution of the resulting orthomosaics is remarkable, with subcentimeter to
submillimeter pixel resolution. The three dimensional models are sufficiently detailed to view
and explore architectural details on screen. These “digital surrogates” are important for both
analytical purposes and as virtual archives of these areas before archaeological interventions.
Examples of the resulting models can be viewed and downloaded from Sketchfab.9
Closing Thoughts
The projects discussed here took place through different phases of the UAV and
photogrammetric revolution in archaeology—from an era of early adopters to the current era in
8 We inserted the base of the pole in a flag pole holster to distribute the weight of the pole/camera rig and improve
maneuverability.
9 Chapel and shrine area: https://skfb.ly/HwOn. Elite domestic compound: https://skfb.ly/JN6X)
228
which it is approaching standard fieldwork practice among an increasing number of practitioners.
As a piece on computational archaeology, this chapter plays a similarly transitional role. It is
likely that essays like this arguing for the benefits of UAVs and photogrammetry in archaeology
will become less common in the near future, as technical barriers are lowered to the point that
they are part of “standard practice.” But we have also argued that standard practice will need to
change to capitalize fully on the extended observational capabilities that these technologies
allow. We share the concern that the growing dominance of digital recording can, if used in
traditional research designs, impede observation and interaction with the actual stuff of
archaeological research: the tactile and sensory—observational—experience of primary
archaeological data collection (see Caraher, this volume). We have spent many hours with
archaeological digital surrogates in the days, weeks, and years following fieldwork. It is likely,
for example that excavation project designs will be best served to move to a more specialized
mapping/photogrammetry team model so that crew chiefs and excavators can focus on being the
primary instruments of observations rather than spending more time manipulating various digital
sensing instruments at a remove (see Wallrodt and Serrano and colleagues, this volume).
But from a heritage management perspective, the world won’t wait. The inexorable loss
of patrimony to deliberate destruction, urban sprawl, development, and a host of other threats
compels us to find new ways to rapidly document global archaeological patrimony. In this case,
however, usual compromises between speed, granularity, and accuracy do not apply. There is no
downside that we can see, as long as the digital surrogates we can produce increasingly quickly,
cheaply, and easily do not displace our continued advocacy for the importance of experiencing
ancient places.
229

2.4. An ASV (Autonomous Surface Vehicle) for Archaeology: The Pladypos at Caesarea
Maritima, Israel
Bridget Buxton, University of Rhode Island
Introduction
This paper seeks to inform the archaeological community about a robotic autonomous
surface vehicle (ASV) currently being developed for shallow-water applications in marine
sciences and archaeology (Miskovic 2011; Miskovic 2013; Vasilijevic 2015). The ASV Pladypos
(a PLAtform for DYnamic POSitioning; FIG. 1) was developed at the University of Zagreb
Faculty of Electrical Engineering and Computing, in the Laboratory for Underwater Systems and
Technologies (LABUST). Its main characteristic, from which it obtained its name, is dynamic
positioning at sea. The Pladypos uses GPS to keep a steady position at a requested location or
following transects while actively compensating for external disturbances such as wind, waves,
and currents (FIG. 3). The Pladypos can deploy with a variety of cameras and sensors to survey
submerged ancient harbors and coastal settlements, or any underwater landscape where current
digital recording strategies do not scale well beyond the size of individual shipwreck sites.
The Pladypos was originally developed to answer research needs identified by
underwater archaeologists and other marine scientists, and collaboration between the engineers
and archaeologists on real field missions was planned from the outset as a means to increase
interdisciplinary understanding and identify areas for improvement. Here we present some
preliminary results and describe the experience of an interdisciplinary team using the Pladypos to
create a georeferenced bathymetric map and integrated photomosaic of the submerged ruins at
Caesarea Maritima in Israel (FIG. 17).
247
In 2014, a three-day expedition focused on the task of mapping the submerged
breakwaters and interior of King Herod’s ancient harbor of Sebastos in Caesarea Maritima
(henceforth, we refer to the entire underwater site as “Caesarea”). In 2015, the Pladypos spent
two full days in the ancient harbor recording the area of a new shipwreck discovery. It will return
to complete its task of mapping approximately 3 sq km of Caesarea’s underwater archaeological
area in 2016. The Pladypos can potentially map 10 sq km at maximum resolution in an 8-hour
work day, and larger areas at lower resolution. The 3-year duration of our project reflects the fact
that our research goals and funding are primarily for technical development and experimental
field trials rather than to answer any specific archaeological research questions. The field trials
tested the Pladypos’ capabilities in a variety of scenarios and sea conditions for shallow-water
mapping, and an unexpected opportunity to utilize the robot on an Israel Antiquities Authority
shipwreck excavation at Caesarea in 2015 further demonstrated the robot’s versatility.
The Pladypos began the first experimental merged acoustic and photographic imaging of
Caesarea’s sunken port structures in May 2014. One archaeological goal of this ongoing mission
is to create the first fully-georeferenced underwater site map of King Herod’s famous harbor
with a level of accuracy and detail normally only seen in underwater archaeology in the
excavations of single ancient shipwrecks. Achieving centimeter levels of accuracy in recording
the architectural features of large Mediterranean terrestrial sites has been the standard for more
than a century, so this was the goal we set for the Pladypos in mapping Herod’s harbor.
Our longer-term expectation is that by collaborating on real research missions, the
archaeologists and engineers will be able to improve the Pladypos’ utility for underwater
archaeology, with a view to developing the system into an affordable, commercially viable offthe-
shelf technology. Based on the Pladypos’ performance to date, we eagerly anticipate a not248
too-distant future in which highly portable and versatile autonomous robotic vehicles like the
Pladypos are fully integrated into the underwater archaeologist’s toolkit, and the recording of
large and complex underwater inshore sites does not fall short of the established standards in
terrestrial archaeology.
Digital Archaeology Underwater
Digital site-recording strategies in underwater archaeology have developed along a
different trajectory from parallel advances in terrestrial archaeology. An appreciation of the
Pladypos’ strengths and limitations requires that we begin with an overview of the current state
of underwater site mapping, and understand some of the unique challenges of vehicle
localization and accurate site recording in marine environments.
While underwater excavation techniques using dredges and airlifts have changed little in
the last fifty years, at least on sites lying within the range of scuba divers, advances in digital
photogrammetry for site recording and acoustic sensors for landscape survey have revolutionized
the discipline. Many underwater archaeologists in the field today began excavating at a time
when digital photo-modelling was not yet considered trustworthy enough to forego slate and tape
measure. Early CAD (computer aided design) programs came into widespread use in the late 20th
century, generating digital reconstructions as an alternative to 2D site maps, but not initially
removing the need for tape measures and manual triangulation. Today, massive quantities of
spatial data can now be stored and visualized in digital formats, making the printed page
increasingly obsolete as a medium for storing and disseminating excavation and survey results.
Arguably, only a lingering resistance to digital publication continues to prevent the full potential
of the new media from being realized.
249
Photogrammetry, photo-modelling, SLAM (simultaneous localization and mapping),
structured light imaging, multibeam and various other acoustic sensing technologies have all
been utilized on Mediterranean underwater sites in the last decade (Brandon 2008; Demesticha
2011; Buxton 2012; Skarlatos 2012; Scaradozzi et al. 2013; Drap 2013). It is increasingly
common, though not universal, to find underwater archaeologists well versed in the use of CAD
and GIS (geographic information systems), and able to conduct their own underwater surveys
with off-the-shelf oceanographic sensors and imaging software. The digital revolution has had a
dramatic impact on underwater recording strategies, enabling archaeologists to think far more
ambitiously about seafloor survey. What Mediterranean underwater archaeology currently lacks
is any kind of single, widely adopted digital recording standard and toolkit for high-resolution
imaging of large sites - that is, larger than a typical ancient shipwreck, but smaller than a
landscape survey area where sidescan sonar alone might provide adequate coverage. For shallow
sites on the scale of harbors and submerged settlements, there are as yet no standard tools and
conventions equivalent to the Total stations and Filemaker databases now in widespread use in
terrestrial classical archaeology.
There are many reasons for the divergence between terrestrial and underwater
archaeological site recording technologies and strategies. Because of the unique exigencies of the
underwater environment, underwater archaeology is the only major academic specialization
within archaeology that is defined by an environmental variable rather than a cultural division or
category of evidence. This rift is exacerbated by the technological divide between the
oceanographic sciences and their terrestrial counterparts, extending even into different protocols
for basic data collection. For example, on an oceanographic expedition, the most important
organizational baseline for incoming data is often units of time, whereas recording in
250
archaeology is organized by spatial units (though time is increasingly seen as a relevant variable
for archaeological recording when site formation processes are considered; Demesticha 2011).
The incompatibility of standard scientific recording technologies and conventions on land
and sea is not problematic for most scientists, whose research questions typically exist only in
one sphere or the other. For archaeologists, on the other hand, the research questions do not
necessarily change whether we are investigating the terrestrial or submerged sections of an
ancient settlement, but the resources needed to answer those questions differ in each case. The
archaeological investigation of large, shallow coastal sites presents unique challenges that
require customized solutions adapted from oceanographic technology.
Unlike on land sites where the tradition of Wheeler squares and the locus system have
created linear frameworks for organizing spatial data, the basic measure of detail, if not
accuracy, in digital underwater site mapping is the point cloud. A point cloud is the number of
data points recorded within a given three-dimensional space defined by X, Y, and Z coordinates,
which represents the external surface of an area being recorded. Underwater, a point cloud is
typically created using acoustic sensors, which may simultaneously be collecting data to aid a
robotic vehicle’s localization. Although the term 3D is often used casually to describe the
product of this type of recording, when the point cloud is produced solely from bathymetric data
(the relative depth of each point), then it is more accurate and is gradually becoming
conventional to describe the resulting digital models as 2.5D.
The technology required to integrate point clouds and photomosaics to produce
archaeologically useful diagrams and publication-quality georeferenced 2.5D maps of
underwater sites is exclusive to underwater environments. Because archaeologists typically lack
the training or resources to own and operate oceanographic remote-sensing technology or to
251
process the data themselves, producing state-of-the-art underwater site maps can be a costly
undertaking. Oceanographic mapping tools are often developed with the budgets and
requirements of industry and deep water environments in mind. The shallow coastal regions
where archaeological material is concentrated demand different, low-cost solutions.
In these coastal underwater archaeological scenarios, marine robots are not faced with the
technical difficulty or high cost of operations in deep water, but arguably face a far greater
challenge in that they are entering direct competition with highly efficient human divers, who are
often “free” volunteers. These human advantages start to disappear, however, as the area to be
mapped gets larger or deeper, the datasets and high definition image libraries become so massive
as to be unmanageable outside a purely digital recording system. The advantage of deploying
robotic drones whenever the mapping task gets too big is also illustrated in Steve Wernke’s
chapter in this volume. The ancient port of Caesarea and its surrounding coastal and submerged
features is the perfect example of a site that is just too big to be recorded to centimeter accuracy
by human divers working alone, even with the aid of powerful imaging tools (Brandon 2004;
Brandon 2008). At the same time, shallow water and good visibility make Caesarea an ideal site
to record the seafloor from a surface vehicle.
Caesarea Maritima
The first-century A.D. Jewish writer Josephus described King Herod’s gigantic artificial
harbor at the Judean city of Caesarea Maritima as “a triumph over nature” (Jewish War I.410-
412). The name Caesarea came from the family name of Rome’s first ruling dynasty, the
Caesars. The actual harbor was technically called Sebastos, after the Greek rendering of
Augustus, the first of Rome’s emperors and an important political patron of King Herod (d. 4
252
B.C.). The maritime gateway to King Herod’s new city was the largest completely artificial
harbor in the Mediterranean world, with breakwaters encompassing over 20 hectares (FIG. 17).
Upon its completion in the last decade of the first century B.C., Caesarea Maritima’s port
provided one of the Levantine coast’s only deep water anchorages (Raban 2009).
One of the reasons that archaeologists are eager to have more accurate maps of the ruins
of Caesarea’s Roman harbor is because it was the most ambitious port construction of its day
(Hohlfelder 2007). Caesarea’s engineers used hydraulic cement in the creation of the
breakwaters, employing a special mortar composed of lime and pozzolana, a volcanic ash
imported from central Italy. The scale of the project was beyond even Herod’s abundant
resources, and reflects the power and wishes of the new imperial government in Rome. The new
port helped Caesarea to prosper and the city soon grew to be five times the size of Jerusalem; it
remained one of the most important towns on the Levantine coast until the Muslim conquest.
During this time, Caesarea appears to have been damaged by several major earthquakes and
tsunamis, though the impact of these ancient disasters on the Herodian port structures is still
being investigated (Reinhardt et al. 2006). The damage caused by natural disasters has to be set
against evidence of the port’s decline through simple lack of maintenance and flaws in the
original construction (Hohlfelder 2007). Exactly what caused the outer breakwaters of one the
ancient world’s most magnificent ancient harbors to fall into disrepair even before the end of the
first century A.D. is one of the questions that a comprehensive underwater map of the entire port
area could help us to answer.
Unlike the archaeologists of the previous century, we can now integrate a vast amount of
georeferenced bathymetric and photographic data into a GIS, so that we are no longer forced to
choose between coverage and accuracy in the underwater recording of exceptionally large sites.
253
Until recently, however, there has not been an appropriate vehicle for conducting such a largescale
systematic underwater survey at Caesarea that offered a cost-effective improvement over
simply integrating local results into a regional plan derived from aerial photographs.
We are certainly not the first team to seek a solution to the problem of how to map the
ancient harbor in its entirety. Experiments with earlier digital mapping systems based on
PhotoModeler were hampered by variable visibility and the heavily eroded, irregular surfaces of
the sunken ruins at Caesarea (Brandon 2008). Underwater site mapping techniques based purely
on visual data and photogrammetry, such as that used at the Mazotos shipwreck site, also require
the placement of calibration targets, such as plastic disks or distinctively-marked ceramic tiles
(Demesticha 2011; Santagati 2013). Even on small sites these targets get moved around in
dynamic sea conditions, and the technique is simply not practical for large port structures. Once
again, Caesarea is a good example of well-known and historically important underwater site that
has been extensively excavated and studied but never comprehensively mapped because of these
challenges.
Today Caesarea’s sunken ruins are the centerpiece of a national park, and the innermost
of the three Herodian harbor basins is covered by lawns and restaurants. The scattered remains of
the intermediate and outer harbors present an ever-changing puzzle for archaeologists, as the
open sea regularly uncovers new features and moves or reburies others (FIG. 2). Israel’s winter
storms in 2010 were powerful enough to tear down Caesarea’s modern reinforced-concrete
breakwaters, and at this point the need for a new conservation assessment of the ancient harbor
became clear. FIG. 2 shows how environmental changes over the past few years have
transformed the appearance of the underwater ruins, in some areas revealing new features that
were missed in earlier archaeological studies. Completing the first georeferenced digital imaging
254
of the entire underwater site of Caesarea will not only help us to integrate the results of previous
excavations into a unified up-to-date GIS, but it will also aid the Israel Antiquities Authority in
future planning and conservation efforts.
The 2014 mission
In 2014, the ASV Pladypos was deployed at Caesarea in a collaboration between the
Israel Antiquities Authority and researchers from the universities of Zagreb, Rhode Island, and
Louisville. Over a period of three days, the Pladypos was manually launched from the shore and
travelled under its own battery power to a series of small survey areas, where it mapped the
seabed using a combination of downward cameras and a DVL (doppler velocity log) to create a
merged georeferenced photomosaic and digital point cloud. The 2014 surveys took place both
within and beyond the modern breakwaters in the Herodian harbor, and the foundations of a
Roman pier were also mapped at nearby Sdot Yam to the south (FIG. 3). When sea conditions
allowed, the Pladypos operated out in the open sea, where the water depth and acceptable
seafloor visibility extends to approximately 10m depth in normal conditions. When the sea
became too rough, the Pladypos surveyed the ruined foundations of Roman towers in the
intermediate basin protected by the modern seawall, an area which ranges in depth from 1-3m
(FIGS. 5, 6).
Like many of Caesarea’s submerged structures, these semi-buried tower foundations are
not immediately obvious or comprehensible to a swimmer on the surface. However, the sand and
rubble transform into recognizable architecture when reconstructed as a 2.5D digital image (FIG.
5). The Pladypos generated a georeferenced microbathymetric map of this area using LABUST’s
customized MatLab-based software. The data that the Pladypos produces is less like a traditional
255
site-map and more like a scale digital reconstruction of an archaeological landscape. The results
are suitable for GIS presentation, for example using Google Earth as shown in FIG. 7. Unlike a
traditional paper map, moreover, the Pladypos reconstruction has the same ‘zoom’ functions as
the Google Earth GIS framework in which it is imbedded.
The exercise of surveying the tower foundations in the sheltered intermediate harbor,
which took little more than an hour, provided a preview of what we could expect from a high
resolution 2.5D map of the entire port. Herod’s outer harbor is more exposed and deeper (up to
10m in places), with a depth range of 3-8m in most of the area surveyed in 2014. This exposed
area out in the open sea was a greater challenge for the small Pladypos to stay on target while
buffeted by wind, waves, and a moderate 1-1.5 knot longshore current. Despite these conditions
and Caesarea’s infamous surge, the Pladypos held position and continued to collect good data.
Three missions were performed along a 250m stretch of the submerged southern breakwater, and
the results were merged to create a 2.5D reconstruction and a microbathymetry map. When the
open sea became too rough, work in the intermediate harbor continued (FIG. 9).
The Pladypos: Technical Specifications
The Pladypos utilizes a differential GPS to adhere to systematic survey patterns with far
greater precision than is possible for a human swimmer or even a submersible robotic vehicle
(satellite navigation and localization using GPS is not possible underwater). By staying on the
surface, the Pladypos can maintain a wireless link for instant communication between the robotic
vehicle and the operator on shore (FIGS. 8, 15), unlike the slow acoustic communication channel
required to link with an autonomous underwater vehicle.
256
Also appropriately called a USV (unmanned surface vehicle), the Pladypos can operate
either autonomously, following a pre-programmed mission such as a typical “mowing the lawn”
survey pattern, or maneuvering under the remote control of a human operator with a laptop (FIG.
8). The vehicle can switch between the pre-programmed task and direct control on command,
and the mission can even be changed once the vehicle is already out working on the water. This
degree of flexibility and responsiveness is a necessity for an ASV built to operate in dynamic
coastal environments where there is more likely to be marine traffic and other hazards.
The Pladypos maneuvers using four thrusters arranged in an X configuration, vaguely
though not deliberately resembling its namesake aquatic mammal, and it can move easily in any
horizontal direction. The symmetrical design makes efficient use of an onboard battery power
source. A simple lead-acid battery may be used, which also provides more options for airshipping
the vehicle. Once it arrives at its destination, another advantage of the Pladypos when
compared to many remotely operated or autonomous underwater vehicles (ROVs and AUVs) is
its portability. The Pladypos is only 0.35m high, 0.707m wide and long, and it weighs
approximately 25kg, without payload. This lightweight design allows the Pladypos to be
manually launched and recovered by two people from a beach or jetty, with no need for a winch
or a support boat (FIG. 3). In good sea conditions the Pladypos’ operations were limited only by
battery time and the schedules of the humans waiting on shore.
The basic tool set of the Pladypos includes a number of data-gathering sensors such as
mono cameras, stereo cameras, and in 2015 a high resolution ARIS multibeam sonar (Adaptive
Resolution Imaging Sonar) was added to provide higher resolution point clouds than the DVL
used in 2014. The Pladypos has a ROS-based architecture (Robot Operating System;
http://www.ros.org) for control, communication, telemetry, and acoustic and optical data
257
logging. The navigation sensors provide a level of localization accuracy within tens of
centimeters and consist of 9-axis INS (inertial motion sensor), high precision GPS, and DVL.
The 4-beam DVL (LinkQuest 600) is capable of 5H z depth sampling in shallow water, and
generates a point cloud at the rate of 20 points per second. At a cruising speed of 1 knot, the
DVL produces a non-homogeneous point cloud density of 40 points per square meter. The DVL
is used to measure speed over ground but also to provide depth measurements. For documenting
an underwater archaeological landscape extending over several square kilometers, this represents
extremely detailed coverage, though improving the point cloud resolution and the efficiency of
post-processing software continues to be a goal for the future development of the system.
The control computer (isolated from environmental disturbances inside the Pladypos hull)
is in charge of performing control and guidance tasks (dynamic positioning, path following,
diver following) and all the data processing. Apart from the compass, GPS, DVL batteries and
CPUs, the Pladypos is equipped with a mono camera for seafloor mapping, an Ultra Short
Baseline (USBL) system used to determine the position of a scuba diver relative to the robot (the
anticipated role of scuba divers in Pladypos operations is discussed further below). The USBL is
used simultaneously for localization and two-way data transmission via an acoustic link with the
scuba diver; a second modem is mounted on a scuba diver when the vehicle is operating as a
surface dive buddy. Support for Pladypos operations from the shore station, which may also be
set up on a small boat, includes the controller’s laptop and laptops for monitoring the vehicle’s
sensors, along with WiFi antennas and a wireless modem used to transmit data between the
Pladypos and the base of operations (FIG. 8).
During the initial sea trials in Israel in 2014, the Pladypos was equipped to collect two
types of data: a georeferenced point cloud of the seabed and sunken archaeological features using
258
the DVL, and visual imaging using the Bosch FLEXIDOME IP starlight 7000 VR mono camera,
in a custom-made waterproof housing. A GoPro Hero3 camera in a waterproof housing was also
taped onto the vehicle to gather additional high definition color video. The georeferenced point
cloud was acquired by following pre-programmed transects across the survey area with a certain
amount of overlap to facilitate the fusion of the data.
One of the first requirements of a robotic survey vehicle designed for shallow coastal and
underwater archaeology is that it can be ready to launch on a new mission ideally within hours,
and respond swiftly to changing weather or chance discoveries. Assuming the presence of a
trained operator, Pladypos missions can be plotted out relatively quickly using Google Earth
(FIG. 7). Since the Pladypos can be operated either manually (teleoperation mode) or
autonomously, the ability to adapt missions that are already in progress when circumstances
demand is a very convenient feature. Directing the vehicle manually is as simple as manipulating
a joystick or pointing to a GPS destination on Google Earth, and does not require specialist
training.
After the issue of cost, which we will return to, the key to integrating the Pladypos into a
digital recording system for underwater archaeology that will have widespread appeal is the
efficiency and user-friendliness of the software, especially the user interface. In 2014, the
Pladypos relied on a custom set of scripts produced by LABUST for the georeferenced
bathymetry presentation. Scripts written in MatLab were used to unpack the logged data, to fuse
navigation and depth measurements, and to generate 2.5D bathymetry images. For the
photomosaic, Microsoft Image Composite Editor (ICE) software was used to stitch together the
images, while LABUST MatLab script was used to fuse navigation data with large scale images
(FIG. 9). This data was processed off-line to create a microbathymetry map, and a 2.5D digital
259
model of the survey area was also extracted and created from the same data set. The optical data
was then merged with the telemetry data to build a photorealistic model of the seafloor along the
survey transects. The main limitation on the amount of data gathered along each transect was the
width of the visual field on the downward-facing camera, which naturally varied with the depth
of the water.
The most technical part of the operation followed the completion of fieldwork, when the
LABUST team set to work stitching together the optical data with Microsoft ICE for the final
georeferenced photomosaics. The completed images were then aligned with the telemetry data in
subsequent processing. LABUST has developed software to fuse optical and telemetry data for
both image stitching and georeferencing. On the final large-scale high resolution site map
produced from this process, information such as the absolute positions of underwater objects and
features and their dimensions can be determined within a range of centimeters. In this way, the
Pladypos achieves a centimeter-level of precision in small area maps, but it can reproduce this
performance on a scale of many square kilometers given time and appropriate conditions.
The choice of Google Earth for the GIS overlay was simple given its universality and
ease of use, and also because Google Earth does not treat the land-sea interface as a barrier. On
dynamic coastal archaeological sites where the visible remains are often changing, being able to
visualize the relationship between submerged and semi-submerged coastal features is very
important. Observing change over time around the interface of the land and underwater
landscapes can help local authorities to monitor erosion and other long-term changes that
threaten coastal archaeological sites.
The evolving site map that archaeologists work from in the field is necessarily rougher
than the site map produced for a final publication, and the Pladypos preserves this convention by
260
producing ‘rough and ready’ SLAM-generated photomosaics while collecting the data that will
eventually be transformed during post-processing into a high resolution 2.5D map. Preliminary
mosaics were produced on site at land stations set up on Caesarea’s modern breakwater,
providing real-time information to the archaeologists. At present, there is scope for improvement
in the speed of the high level post-processing, which required many hours of work by the
engineers in the weeks following the conclusion of the fieldwork (generating results illustrated in
FIGS. 10 and 11). It is not unusual to wait for weeks or months to obtain processed bathymetric
data and photomosaics on oceanographic expeditions, but as a future goal, it is obviously
preferable for the required processing from raw data to publication-ready 2.5D maps to be
automatic, or nearly so.
The 2015 mission
An important lesson of the 2014 Caesarea expedition was that having the archaeologists
and robotics scientists working collaboratively in the field resulted in a far greater mutual
understanding than if the archaeologists had simply viewed the engineers as technicians
providing a service, or the engineers viewed the archaeological mission purely as a field trial. In
this volume, the FAIMS team likewise found that ongoing dialogue between the software
developers and archaeologists was extremely helpful. Concepts such as mapping and measuring
can have surprisingly different meanings across different disciplines, and it was valuable for all
involved to have their assumptions highlighted and questioned. An ambitious ‘to do’ list to
enhance the Pladypos’ performance and utility from an archaeological perspective was another
important result of the 2014 season. One conclusion was that more precise measurement of the
depth below the Pladypos would significantly enhance the quality of the photomosaics. For that
261
reason the LABUST group integrated the high resolution ARIS multibeam sonar onto the vehicle
when it returned to Caesarea in 2015.
The Caesarea mapping project resumed in July 2015, though the vagaries of international
shipping meant that the Pladypos itself was delayed for a week in Madrid and was only available
for two full days of fieldwork on its second visit. During this brief time, however, Pladypos
surveyed or re-surveyed an estimated 60-70% of the intermediate Herodian harbor and over 25%
of the outer harbor. The ARIS multibeam system generated a high resolution 3D point cloud of
the seabed, in addition to the image mosaic produced by the survey; the results are illustrated in
FIGS 10a, 10b, 10c and 11. In 2015, the Pladypos’ mapping mission took on an unexpected
urgency, as Caesarea became the scene of an Israel Antiquities Authority rescue excavation of a
recently-exposed medieval shipwreck site.
In February 2015, winter storms exposed a scatter of gold coins lying amongst the rocks
in King Herod’s outer harbor, where they were discovered by local scuba divers. Israel
Antiquities Authority underwater archaeologists Jacob Sharvit and Dror Planer led the
subsequent recovery operation, and over 2500 coins were retrieved from the surface of the
seafloor during the following days. The coins dated from the 10th-11th centuries and were
minted by the Fatimid Caliphs of Egypt; the Fatimids were an Ishmaili Shia dynasty which ruled
the Levantine coast during the early medieval period. Israel Antiquities Authority numismatist
Dr. Robert Kool identified the name of Abu ‘Ali Mansur al-?akim bi-Amr-Allah (A.D. 996-
1021) on many of the coins. Al Hakim was the sixth Caliph to rule the Fatimid Empire, a
controversial figure revered in the traditions of Israel’s Druze community. The presence of
medieval anchors near the hoard suggested the coins came from a shipwreck which probably
occurred in the 1020s-30s.
262
The likelihood of further storms and wave action destroying the archaeological context of
the discovery posed the greatest immediate threat to the site. The accessibility of the shallow site
in an area frequented by scuba divers was also a concern. The Israel Antiquities Authority
immediately provided resources for a rescue excavation. The site presented unusual challenges,
however, as it had no obvious center or limits, and consisted primarily of scattered rubble and
sand. Such amorphous and complex shapes provide few ‘hard edges’ as spatial reference points
and are notoriously difficult to map.
In Israel and other regions of the world where the preservation of a rich inshore
archaeological heritage is complicated by a highly dynamic coastal environment, the scenario
described above is not unusual. During Israel’s winter storms, historic shipwrecks and
submerged structures can appear in the coastal surf zone and then be reburied or destroyed
within the space of a few days. An unknown number of sub-seafloor sites must experience this
fate every winter without archaeologists ever being aware of their existence. Even in the case of
the Caesarea Fatimid coin hoard discovery, which was fortuitously immediately reported and
investigated by archaeologists, the limitations of current technology for underwater site
recording and rescue excavations were highlighted. Fortuitously, the discovery also provided an
opportunity for the Pladypos to demonstrate its ability to create a large high-resolution seafloor
map in a rescue excavation scenario.
After the initial recovery effort removed the most easily accessible coins, the excavation
of the site did not begin until July 2015 – this delay was deliberate, in order to coincide with the
return of the LABUST University of Zagreb engineering team. The Pladypos now focused on
mapping the area of the coin hoard discovery (illustrated in FIG. 12). The clear, relatively
shallow water enabled the Pladypos to obtain approximately half a million high-resolution
263
photographs of the site and the surrounding seafloor in a matter of hours. These fully georeferenced
images preserve important information that may not be immediately obvious to
human divers searching the rock-strewn seafloor. Confident that no critical information would be
lost, the archaeologists were now able to remove rocks along a transect in the area of the
discovery, revealing a second substantial pocket of gold dinars in the sand underneath and
bringing the total hoard to over 3000 coins (FIGS. 13, 14). It was during this work that a 10 cm
iron spike was discovered with gold coins concreted to it, the strongest evidence yet that the
hoard came from a shipwreck. A preliminary photomosaic of the area produced in the field was
also available for immediate use by the archaeologists as the work of excavation proceeded.
The Fatimid coin hoard discovery provided the perfect illustration of the utility of a robot that
can produce a high-resolution georeferenced 2.5D site map of an area larger than a football field
in a matter of hours, enabling a rescue excavation to proceed without fear of losing critical data
in the rush to recover fragile evidence. However, the experience also highlighted the importance
of having the Pladypos on site and ready to deploy at a moment’s notice, not standing by in an
engineering lab on another continent. The Pladypos also has a long way to go before it can be an
affordable, “ownable” piece of technology that is ready to deploy off the back of a pickup truck
without needing a team of four LABUST engineers to operate it. We conclude with some
considerations and plans for the future development of the Pladypos that we believe will help
bring it closer to a commercially viable product that end users can own and operate without
specialist training.
Conclusions and Future Directions
264
The recent development of DVL and multibeam systems compact enough for deployment
on small USV / ASV platforms such as the Pladypos creates important new opportunities for the
recording and monitoring of large shallow-water coastal archaeological landscapes. Using these
capabilities of the Pladypos, we are able to meet and even surpass the high standards of accuracy
in manual site mapping established by scuba divers in the late 20th century – but this
achievement can now be replicated on a much larger scale in a very short time. The rescue
excavation of the Caesarea Fatimid coin hoard site in July 2015 demonstrated that the Pladypos
could be just as useful for the intensive recording demands of a small-scale rescue excavation as
it has been for high resolution landscape survey at Caesarea, and in other experiments conducted
on shallow archaeological sites at Colentum in Croatia (FIG. 16) and Lake Valgjärv in Estonia.
To be as effective and useful as a human diver for the management and excavation of
coastal archaeological sites, the Pladypos needs to be able to arrive on the site and be ready to go
to work with the same speed as the archaeologists. In 2015, the Pladypos was able to start work
overseen from a makeshift operation center within hours of arriving on site, and completed its
recording tasks efficiently. A maximum of two people were needed to operate the vehicle: one to
monitor the robot itself, and the other to monitor and begin processing the incoming data.
It follows that the most obvious area of improvement for future iterations of the Pladypos
is not in technical capability, or even the general compatibility of its data products with
archaeological conventions, but in “ownability”. A function of durability, ease-of-use, and cost,
ownability will determine which robotic vehicles and their dependent digital recording systems
will ultimately become an everyday part of an underwater archaeologist’s toolkit, and which will
merely hold a place in the evolutionary process. The first affordable and user-friendly off-theshelf
robotic technology to pass this threshold and come into widespread use within the realm of
265
scientific diving will reshape archaeological methodology underwater in the same way that the
evolution of IOS-based paperless systems is currently transforming terrestrial archaeology. From
the archaeologist’s perspective, the Pladypos will not achieve “ownability” until the entire
system can be purchased for under $20,000, and the GUI (graphic user interface) is intelligible to
even the most non-technical user. In addition, the data products (geo-referenced data, videos, still
images, and the DVL/sonar point cloud) must be able to be integrated into a GIS by a non-expert
user with readily available commercial software, or ideally freeware. At this stage, it is difficult
to predict when this might happen: we are still in the first phase of establishing proof-of-concept
with the Pladypos itself.
To this point we have been discussing operations in very shallow water, which may be
defined as the depth at which the seafloor is still visible from the surface for the purpose of
creating photomosaics. However, the utility of the Pladypos does not end there, and future
missions will develop and demonstrate the vehicle’s applications in deeper water. While in some
respects the Pladypos’ sphere of operations puts the vehicle into competition with human divers,
it is more appropriate to say that the vehicle is designed to complement human capabilities.
When deployed as a surface dive buddy, the Pladypos integrates human functionality to
accomplish tasks in deeper water that would be expensive, difficult, or even impossible for the
current generation of underwater robotic vehicles.
As mentioned earlier, the Pladypos is equipped with an integrated ultra-short-baseline
(USBL) localization system, which it can use to hover above and track a scuba diver with a tankmounted
transponder and battery pack. An acoustic modem maintains a low bandwidth link with
the surface, allowing the two-way transfer of email messages, photos, and GIS data between the
diver and the land base via an ordinary Android tablet in a waterproof housing designed by
266
LABUST. Currently the 2014 Samsung Galaxy Note 10.1 is the tablet best adapted for use with
the waterproof housing, and its main drawback is that the Filemaker-based applications popular
in terrestrial archaeology are not available for Android devices at the time of writing. The
popularity of IPads in terrestrial archaeology illustrated by other projects discussed in this
volume, and the appearance of a new commercially available underwater casing for IPads, the
IDive (http://idivehousing.com/), provide compelling incentives to make the next iteration of the
Pladypos compatible with IOS-based technologies.
Using the Pladypos’ current system, a diver can access most of the tablet’s applications
using a modified touch-screen pen (FIG. 16). While the archaeologist gathers data and images
from the seafloor using the tablet, the Pladypos collects multibeam data from the surface and
relays information to the diver about his or her location on the map, including transect lines and
GPS coordinates. In this way, the robot does not lose the ability to produce georeferenced
photomosaics at greater depth or in poor visibility: it simply delegates the visual part of the task
to a human diver with a tablet computer – or, in another project currently under development, a
second autonomous robotic vehicle.
The Pladypos is also intended to enhance diver safety. It can serve as a mobile surface
marker for the diver’s position (very useful when manually checking sonar targets in offshore
live-boating situations) but in future it will also be able to monitor the diver’s physical state,
duplicating the role of a dive buddy as well as a scientific assistant.
In addition to conducting archaeological research and completing the mission at
Caesarea, the over-arching goal of the Pladypos project in Israel is to develop through
interdisciplinary collaboration the first universal standard ASV customized to support digital
underwater archaeology, and to make it as versatile, robust, and affordable as possible. The brief
267
2014 and 2015 missions helped the engineering team to identify and address technical issues,
and experience first-hand a real archaeological project environment. The mission itself helped to
build mutual understanding of the needs of specialists in two very different fields, as well as
improving their ability to communicate productively and work together towards common goals.
Very importantly, the engineering team were able to leverage their resources and grants for
technological development to keep the cost to the archaeologists of the 2014 and 2015 Pladypos
deployments under $10,000 per week.
We view the ongoing Caesarea expeditions as early steps along a path to the full
integration of robotic vehicles into all aspects of the underwater archaeologist’s work, making
underwater research faster, safer, better – and ultimately much more cost-effective. Such a major
transformation will require further improvements in the technology, but the culture and
methodologies of underwater archaeologists will also need to adapt to the new, fully digital
environment. Collaborative field trials help to achieve both goals.
Acknowledgements
The research presented in this paper was performed in the framework of the ONRG funded
project ”DINARO” and EU FP7 funded project ”EUROFLEETS” (grant agreement no. 312762).
The authors express their gratitude to the Israel Antiquities Authority, the Oceangate Foundation,
Mr. Steve Phelps, Anonymous Donors, project DSO Eran Rosen, and IAA numismatist Robert
Kool. Many divers helped with the excavation of the Fatimid shipwreck site, and we thank Uzi
Dahari, Eyal Israeli, Rami Tzadok, Beverly Goodman-Tchernov, and Yigael Ben Ari from the
Israel Nature & Parks Authority, and underwater photographer Hagai Native. Special thanks are
due to Israel Hason, Director of the IAA, for providing the budget and support for the excavation
and subsequent laboratory processing, documentation, and research. ONRG VSP grants helped
268
bring the Pladypos and the LABUST team to Israel in 2014 and 2015. All photos and images
belong to the authors unless otherwise noted.

3.1. Cástulo in the 21st Century: A Test Site for a New Digital Information System
Marcelo Castro (Archaeological Ensemble of Cástulo), Francisco Arias (Archaeological
Ensemble of Cástulo), Libertad Serrano (FORVM MMX), Manuel Serrano (FORVM MMX,
Museo Arqueológico de Linares), Ana Martinez (FORVM MMX, Museo Arqueológico de
Linares), J.M. Pedrosa (FORVM MMX, Museo Arqueológico de Linares), and Justin St. P.
Walsh (Chapman University)
Introduction
The Ibero-Roman city of Cástulo, located on the right bank of the Guadalimar River, was
one of the major centers in the south of the Iberian Peninsula during antiquity, as is evident from
the extent of its walled enclosure (50 ha.) and from its strategic position at the head of the
Guadalquivir valley, which leads 250 km to the Atlantic Ocean. The city stood out as a major
hub in the road network of its time, and throughout its history it maintained privileged access to
the mineral resources of the Sierra Morena. The oppidum, or fortified settlement, of Cástulo was
initially the most important population center of the Iberian región of Oretania; later it became a
Roman municipium and finally it was an episcopal see during the late Roman imperial era (fig.
1).
Classical authors gave special recognition to the city of Cástulo. Pliny the Elder
(Naturalis Historia 3.25) described its role during the Second Punic War, and Livy (Ab Urbe
Condita XXVII), Polybius (X 38.40) and Appian (Iberia 34) each chronicled the events
surrounding the battle of Baecula (208 B.C.), located in the vicinity of Castulo, between the
Roman commander Cornelius Scipio and the Carthaginians under Hasdrubal. Polybius (III. 3.37)
and Silius Italicus also described the strategic importance of this region for mastering the Iberian
peninsula and mineral exploitation. Hannibal was aware of this importance, making a pact for
control of Cástulo’s territory by arranging a marriage between his son, Hasdrubal, and the Oretan
princess, Imilké. In 218 B.C., the Romans arrived in the peninsula under the command of the
280
brothers Publius and Gnaeus Cornelius Scipio, and by 214 they were already showing interest in
the mining area of Castulo. Publius and Gnaeus were defeated, but Cornelius Scipio (Publius’
son and Gnaeus’ nephew) won victory for the Romans at Baecula, inflicting a bloody revenge on
Cástulo’s neighbor, Iliturgi, and finally earning the surrender of Cástulo. From this point on, the
city remained under Roman rule. Strabo (Geographia III 4.2) described how, during the imperial
period when Hispania Baetica was constituted in Andalusia as a senatorial province, the border
of neighboring Hispania Tarraconensis (an imperial province) was purposely arranged so that the
emperor maintained direct control of Cástulo. Despite the city’s initial faithfulness to the
Carthaginian cause, the negotiation of its surrender and alliance with Rome allowed Cástulo to
maintain an unusual political independence and the right to coin money (CABRERO 1993: 183-
196).
In April 2011, the initiation of work to define the geographical area of the archaeological
site of Cástulo was published in the Official Journal of the Government of Andalusia (Boletín
Oficial de la Junta de Andalucía), and in July of that year a decree formally creating the
archaeological site was passed by the Andalusian regional goverment.1 At that time, the
excavation project Forvm MMX2 materialized in a precise document titled Location and first
characterization of the forum of the Roman city of Cástulo were also initiated. Our work was
extended in 2012, and also continued in 2013 and 2014, with further activity aimed at
conservation and upgrading the excavated areas for presentation to the public. These seasons of
excavation have shown that although the city’s forum was not located in the areas investigated so
far, two important public buildings from the monumental center of the Roman city have been
1 http://www.juntadeandalucia.es/boja/2011/155/26
2 Forvm MMX is a project of the Institute for Iberian Archaeological Research (University of Jaén), promoted by
the City of Linares and with funds from the Ministry of Economy, Innovation, Science and Employment of the Junta
de Andalucía, in the archaeological site of Cástulo (managed by the Regional Ministry of Education, Culture, and
Sport).
281
revealed.
Overall, the data collected so far indicate that the city built major public works between
the first and second centuries CE, including a bath complex and latrines already known from
previous excavations in the 1970s and 1980s. In addition, levels for much of the second and third
centuries are scarce, indicating a collapse in political and economic activity during which
institutions were located in the earlier public architecture. Third, the city seems to have risen
from the ashes once more during the fourth and fifth centuries, when there was an increase of
activity in the two areas explored. (BLAZQUEZ 1975) (figs. 2 and 3).
Castulo´s designation only recently as an “Andalusian Archaeological Ensemble”
(Conjunto Arqueológico de Andalucía) means that the remains recovered so far are somewhat
fewer relative to other sites with longer excavation histories3, but our efforts clearly demonstrate
the high heritage value of Cástulo and have provided a better idea of the work that remains to be
done.
Stratigraphy: registration and virtual documentation
Forvm MMX is an interdisciplinary team whose members come from a variety of
backgrounds (conservation, topography, biology, computer science, public dissemination,
education, etc.), and whose work will offer open access to the results in a digital format to other
researchers and educators who are interested in a holistic global analysis of the documentation
generated by an archaeological excavation. To hire these specialists and to develop digital
techniques, beginning in 2011 Forvm MMX received €1.1 million in funding from the Regional
Ministry of Education, Culture, and Sport of Andalusia. Our project has developed since its
3 For further information about the Andalusian Archaeological Ensembles:
http://www.museosdeandalucia.es/cultura/museos/
282
initial seasons and now uses a unique recording system called Imilké, after the princess of
Cástulo. A critical reflection on the inner workings of how archaeological information is
recorded at all phases of research was necessary to develop this system. Imilké has been designed
so that information derived from archaeological excavation is simplified and rationalized.
(CASTRO 2014: 16)
The Imilké system starts from a series of paper forms relating to different kinds of
archaeological information, including stratigraphy, objects, and locations. Working in two
computer applications, one for the real-time scanning of the paper forms to the centralized file in
the laboratory, and a second application that allows further editing of the data from the intranet,
the system was designed in collaboration with the private technology company Ayco as a
bespoke archaeological register system for Cástulo. The computerization of the data collected on
the paper forms is carried out as follows: data is recorded by hand on the forms, which are
completed with a smartpen. The pen scans the data from the paper form as it is written, sending it
to a smartphone. The phone forwards the data via cellular connection to be interpreted by OCR
and stored in the database. So, once the pen translates the text into digital form and the Android
smart phone has translated the data, all this archaeological information is instantly available from
the database for the consultation, editing and export for use in other applications (fig. 4).
The first item of note is our project’s emphasis on documentation and preservation of
data while information is recorded in the field. This is essential because of the destructive nature
of archaeological excavation and therefore the ephemerality of the information. As a result of
these problems, the permanence and accuracy required for documentation is clear. This priority
forms the basis for all of the assumptions, approaches, and interpretations which define a
particular excavation, and the recording system should therefore be designed to be as rational
283
and homogeneous as possible, and modified as often as is necessary. Using Imilké, we obtain a
highly-accurate visual description of the components that form the archaeological context
(volumes, surfaces, layers of materials and object records). This detailed recording also enables
further 3D virtual reconstruction.
Of course, our system also allows the digital capture and recording of textual and related
graphical information in the field. For this task, several special forms have been designed for
recording data such as the type of deposit, the materials recovered, and the excavation process.
The first type of unit defined is the “volume.” A volume is a three-dimensional unit defined by
horizontal coordinates (x, y) with levels associated with the vertical (z). The form distinguishes
between four different types of volumes: surface level, division by a complete construction of the
space, division of space by a wall, or, finally, a conventional and arbitrary excavated area of
space. The second type of unit defined on a form is the “stratum,” into which volumes are
divided, and which itself can contain different subunits, referred to as “levels.” For each of the
registered levels it is possible to add an image and to record its UTM coordinates (carried out
using a total station.) Later, in a Geographic Information System (GIS), those UTM coordinates
allow us to recompose the puzzle in Imilké’s virtual model, using the parts we have created: a
three-dimensional model of a volume.
Recording visual information
In our project, we use the following photogrammetric process:
DATA CAPTURE: the data capture method is fast and simple; for every area excavated it
is sufficient to take several photographs of the area. The photographer moves around the
perimeter of the trench, taking photos in sequence. The same procedure is repeated each time the
284
excavation level is changed (i.e., when a new stratum or volume is identified). The greater the
number of pictures taken, the more information the 3D model will have, but we must also bear in
mind that this will generate a larger file.
INFORMATION PROCESSING: the pictures are then processed with Agisoft Photoscan
software. During this process, the images are sent to the server and then a 3D model is generated
from them. The process can take minutes or hours, depending on the size of the photographs
taken and sent. This software also allows for previewing the generated 3D model.
The visual documentation that has been generated in the field (such as photographs taken
in a determined area and turned into a 3D model) can also produce 2D visual documentation
(such as accurate scale drawings of trench plans and stratigraphic profiles) from a 3D model of
the volume selected. This represents a quantum leap in the quality of visual information
preparation, as the usual method is the reverse (creation of 3D reconstructions from timeconsuming
excavation profile or plan drawings).
Using photogrammetry, we are thus able to create three-dimensional models of every
excavated stratigraphic unit. These are integrated into the database using a GIS, which gives
universal access to them in a virtual form and allows users to understand stratigraphic
relationships and their interpretation directly on a geographical virtual model of the
archaeological site. The UTM coordinates associated with every stratigraphic unit (inside every
volume) will facilitate the use of a site map in the Imliké’s GIS database (fig. 5).
Archaeological artifacts: registration and virtual documentation
Archaeological artifact records are divided into either three-dimensional records or
individual records. Using a form designed specifically for them, three-dimensional records are
spatially linked to the volume that contains them; this kind of form also determines the type of
285
content and treatment of materials and it is possible to add pictures of the process, details, and/or
results at any time during the excavation process.
Individual records, by contrast, are reserved for objects that are thought to be particularly
significant, such as complete vases found in situ. The form for individual records for artifacts
contains the same information as the three-dimensional records, but with the difference that in
these tables the object’s exact position has been marked in order to be able to reproduce it later;
hence, we assign x/y/z coordinates.
The artifacts are processed in various stages as they make their way through the project:
conservation, cataloguing, drawing and photography, publication, and didactic use. We have
multiple goals which are achieved through the use of 3D recreations. These models obviously
enable greater study and public dissemination of cultural heritage, but they also help us improve
our conservation activities.4 For example, they reveal the state in which the artifact appeared
during excavation and initial treatment. A model can therefore be used as a point of comparison
with the conserved object at a later date, during or after treatment, and if, by some chance,
damage to or loss of the object occurs, the model can even serve as a record of it.
Our 3D models form part of the database’s “catalogue card” as an interactive PDF
document and, like all the system’s data, they will be available for study and research by future
archaeologists. Our analysis collects all possible data about the item, starting logically from an
archaeometric and morphological definition, along with a topological analysis. Both analyses are
essential for the development of a particular and general chronology, indicating the object’s
relationship with other nearby materials and its archaeological context. We thereby enable an
exhaustive archaeological analysis of the object, including all the data needed for interpretation.
Nonetheless, we are aware of some complications related to certain kinds of data, such as
4 These are available at: http://www.europeana.eu/portal/ And at: http://3dicons-project.eu/eng/About
286
texture, weight, and measurements that are to be specified in the interactive “catalogue card.”
We have therefore not made our prototype catalogue cards public yet in the 3D PDF format,
instead waiting until we can develop them to an appropriate degree (fig. 6).
The European Commission made a recommendation to all EU member states on 27
October 2011 in which some objectives and deployment advice for digitization and preservation
of cultural heritage were included. The creation of more than 30 million digitized objects is
promoted, including great European masterpieces that are no longer restricted by copyright. In
the related documents known as the “Principles of Seville” and the “London Chapter,”
cautionary recommendations regarding the creation and use of virtualized cultural heritage were
put forward. These documents noted that the possibilities offered by visualizations for public
outreach activities which might yield "spectacular" results can, however, become opposed to the
sense of research and scientific rigor required from a digital record of archaeological items.
Following principles laid out by the London Chapter, therefore, we never edit the artifact mesh
obtained by photogrammetry in order to produce “nicer” (but ultimately inaccurate) results.5
Our working practice focuses on interdisciplinary approaches to the 3D models. The
modeling team consults with the restoration and cataloging teams to reach their conclusions
regarding the artifact before we start developing and editing the model in Blender. We decide
whether it is possible to reconstruct the artifact (and if, for example, it is an interesting
architectural component that could be worthwhile to restore as part of virtual building). We also
consider whether the 3D artifact could form part of a study of how to deploy virtual light and
shading, and whether we might be able to create a presentation in which a hypothesis for the
5 International Principles of Virtual Archaeology. Principles of Seville Accesible on: :
http://www.arqueologiavirtual.com/carta/?page_id=12
The London Charter for the Computer-based Visualisation of Cultural Heritage:
http://www.londoncharter.org/introduction.html
287
function or use of artifacts could be tested. Our public dissemination efforts are not intended to
replace an exhibition of the real artifacts in our museum in the city of Linares, but to create a
virtual experience that forms part of the museography designed for presentation in the
interpretative center at the archaeological site itself, or online as part of a website.
The ability to link literary and planimetric data, the infinite possibility of modifying
hypotheses, and the proximity and force a virtual model can exert on the public are some
advantages of virtual archaeology. But as a synthesis we share Rabinowitz’s sentiment that “a
good surrogate is not merely a copy: it is supposed to provide, in some sense, access to the
original, now made ubiquitous and opened for inspection on a level of detail that the original
itself might not allow” (OLSON AND CARAHER 2015: 29).
This is also the main advantage on restauration matter, digital visualization of
archaeological artifacts can show the possible results of restoration of a piece prior to actual
intervention on it, or different solutions for future treatment in a higher level of detail than
classical restoration methodology.6 Pablo Aparicio Resco’s writing encapsulates our ideas about
virtual restoration works: “...las reconstrucciones virtuales nos permiten planear con mayor
cuidado las reconstrucciones reales y nos dan la posibilidad, posteriormente, de imprimir en 3D
los fragmentos perdidos para incorporarlos a nuestra pieza durante la restauración real,
otorgando a este proceso una precisión mucho mayor que si fuera realizado con un modelado
manual” (“virtual reconstructions allow us to plan actual restorations more carefully, and give us
the possibility, later, to print the missing parts in three dimensions so that we can incorporate
them during the actual reconstruction, giving the process a much greater precision than if it were
done with manual modeling”) (APARICIO RESCO 2015) (fig.7).
6 Virtual models and reconstructions are indeed beneficial, as we note here, but they can never replace the ultimate
goal: the preservation and exhibition of the artifact (ROOF SEBASTIAN 2005).
288
With regard to the public dissemination of applications of “virtual archaeology,” our
process offers similar advantages of speed and accuracy as those found in our documentary
archaeological study. Data and visualizations can be publicized using different social networks,
meeting scientific expectations and entertaining at the same time, thereby awakening the interest
of the public, who, in general, enjoy and value cultural heritage. For example, we use the
Sketchfab platform for opening and displaying three-dimensional models:
https://sketchfab.com/forvm_mmx. We use YouTube to document the virtual reconstruction
process: https://www.youtube.com/user/forvm2010.
Finally, we are especially considering the possibilities represented by this format as a
powerful motivational tool for art history and archaeology students, since it allows us to
emphasize the scientific content of the virtualized artifact, depending on the educational level of
those students (fig. 8).
Augmented reality and virtual reality experiences
Overall, the virtual documentation of archaeological remains and artifacts obtained
through photogrammetric techniques has facilitated the processing of information for scientific
interpretation, while allowing the creation of a basis for public dissemination of documented
archaeological remains. Modeling with Blender or SketchUp software on the three-dimensional
documentation of the archaeological remains has allowed the development of different
hypotheses about the areas of the site under investigation, facilitating interpretation and allowing
the general public to approach them through virtual reality experiences and augmented reality.
Virtual reconstructions of archaeological remains have been exported to the FBX format for use
in Unity 3D, where reconstructed virtual environments can be developing for augmented reality
289
applications, such as using the Vuforia plugin to display different scenarios on the archaeological
remains themselves through mobile devices like tablets or smartphones (figs. 9 and 10).
We offer an immersive approach to the history of the city of Castulo using Oculus Rift.
This experience using virtual-reality applications occurs with, for example, a tour of the major
public building where the second-century "Mosaico de los Amores" was discovered in 2012.
Visitors are immersed in its extraordinary technical work and iconographic complexity. On the
other hand, the “Mosaico de los Amores” is now available for further studies with millimeterresolution
through the Gigapan web-platform.7 The other major artwork recovered by the project,
a glass paten showing Christ in Majesty, can be observed in Oculus Rift, allowing an approach to
its findspot with a virtual flight through the 3D model of it “volume”, as well as a virtual
recreation of the paten, one of the earliest and best-preserved examples of Christian art yet
known from the Iberian peninsula.
Pottery studies: pre-inventory
The Imilké Archaeological System is useful for collections management. It generates a
unique QR code for every single artifact in the database, including all pottery.8 The code is
attached to the fragment (and a context QR code is placed in and on each set of pottery or other
artifacts, in case the object code becomes detached from individual sherds) allowing for instant
identification of any object and its relationship to the site. The typology of each ceramic fragment
is documented and we calculate the total weight of the pottery set (classified by type), giving us a
comprehensive picture of it.
7 http://gigapan.com/gigapans/129300
8 QR code to document a pottery sherd and the virtual recreation of the whole form of the pottery sherd, accessible
on: https://sketchfab.com/models/ff6f7b527c1b4532b77812201615b911
290
Conclusion
Our system has a variety of benefits. In addition to its technical capabilities for research,
it is also inexpensive in economic terms. Once the system is implemented, the only requirements
are a cellular data-connection and the maintenance of computer equipment, so it can be extended
to the vast majority of archaeological operations. In short, the development and consolidation of
this system aims at creating a tool for use in the future work in the archaeological zone of
Cástulo, with the longer-term aim of achieving consistency of documentation-recording in
excavations more generally.
High technical skill is clearly a highlight of the Forvm MMX project, but we also have a
desire to continue to experiment and a focus on public outreach. Therefore, our approach in the
work of public dissemination is to create a new (virtual) experience allowing a closer approach
to the ancient city of Cástulo through archaeological objects found in it. We hope to create a
more active, participatory encounter with the past, through the online platforms Sketchfab,
YouTube, and others, and the virtual recreation of housing spaces and 3D models of artifacts and
transects have almost become sensory elements for visitors through the experience of site
reconstructions using an Oculus Rift viewer. As with the rest of the methodology outlined in this
paper, the objectives of public dissemination have been improved by new technologies, which, at
the same time, “improve” our ability to create a final documentation of the archaeological
process and the results obtained with a sufficient level of standardization to permit the use of the
same archaeological recording system by other future teams (fig. 11).

3.2. Measure Twice, Cut Once: Cooperative Deployment of a Generalized, Archaeologyspecific
Field Data Collection System
Adela Sobotkova (Macquarie University), Shawn A. Ross (Macquarie University), Brian
Ballsun-Stanton (Macquarie University), Andy Fairbairn (University of Queensland), Jessica
Thompson (Emory University), and Nathaniel Parker VanValkenburgh (Brown University)
[W]hen people use [mobile devices] they end up just using
technology to consume things instead of making things. With a
computer you can make things. You can code, you can make
things and create things that have never before existed and do
things that have never been done before.
That’s the problem with a lot of people...they don’t try to do stuff
that’s never been done before, so they never do anything, but if
they try to do it, they find out there’s lots of things they can do that
have never been done before.
-Russell Kirsch, 20th century computing pioneer1
Archaeologists face an immediate, fundamental decision once they decide to digitize field
data collection: put together a solution from several pieces of general-purpose, usually
proprietary, software aimed at the commercial market (often supplemented by continuing use of
paper), commission a bespoke mobile application tailored to their specific project, or use one of
the growing number of “generalized”, often open-source, platforms designed specifically for
archaeological fieldwork. Generalized software allows deep customization, adapting to the user’s
approach and procedures rather than requiring than the user adapt to the software, while still
being designed specifically for archaeology. Examples of open-source, generalized (or at least
highly customizable) software developed with archaeological data in mind include the
1 Joel Runyon, “An Unexpected Ass Kicking” (http://impossiblehq.com/an-unexpected-ass-kicking/).
295
Archaeological Recording Kit (ARK; http://ark.lparchaeology.com/) (see Dufton, this volume),
Heurist (http://heuristnetwork.org/), and the subject of this paper, the Federated Archaeological
Information Management Systems (FAIMS; http://faims.edu.au/) Mobile Platform. Bespoke
applications can meet the particular requirements of archaeological fieldwork, but producing and
maintaining them exceeds the resources of almost all projects or institutions. Commercial dataentry
applications offer lower barriers to entry (although it remains resource-intensive in the long
run), but they adapt poorly to the exigencies of the field and require archaeologists to make many
compromises. Generalized, open-source tools designed for field research bring the advantages of
bespoke software within reach of "typical" projects.
Perhaps more importantly, generalized tools also allow archaeologists to participate in
software development, not merely consume software. Such co-development involves a
partnership between field archaeologists and a software development team. This partnership can
ease the transitions from paper to digital fieldwork, illuminate the advantages digital approaches
offer, and ensure that software is fit-to-purpose. Its benefits and rationale are analogous to those
of Open Context’s model of “data sharing as publication”, where data editors collaborate with
data creators (Kansa, this volume). In this paper, three project directors who co-developed and
deployed a FAIMS recording system in collaboration with the FAIMS team report their
experiences. Having first-hand experience of co-development, they reflect on the challenges and
benefits of working with the FAIMS Project team to produce a customized implementation of a
generalized field recording system.
296
The FAIMS Project
The FAIMS Project is a university-based, e-research initiative launched in 2012 to
develop national, domain-wide information management infrastructure for archaeology and
related disciples (Ross et al. 2013, 2015; Sobotkova et al. 2015). It was initially based at the
University of New South Wales, Sydney, and funded by a grant from the Australian National
eResearch Collaboration Tools and Resources (NeCTAR) eResearch Tools program (RT043;
AUD $949,500). In consultation with Australian and international archaeological communities,
the FAIMS Project developed a generalized, mobile, offline, multi-user collection platform for
structured, free-text, geospatial, and multimedia data (the ‘FAIMS Mobile Platform’ discussed
below), which entered public beta release in November 2013. The project also supported
enhancements to the Heurist online data refinement and analysis service developed at the
University of Sydney, and established an Australian implementation of the Digital
Archaeological Record (tDAR), an online data archive developed by Digital Antiquity. In 2014
the FAIMS Project received an Australian Research Council (ARC) Linkage Infrastructure
Equipment and Facilities (LIEF) award (LE140100151; AUD $945,000 total ARC funding and
university co-investment), allowing a second phase of development that emphasized field
deployments of the mobile platform at partner universities, three of which are presented in this
paper. Experience from these deployments informed ongoing development of FAIMS software,
resulting in the release of FAIMS 2.0, the current production version, in November 2014 (see
Figure 1). In January 2015 the project moved to Macquarie University, Sydney.
The sustainability plan of the FAIMS Project involves iterative applications for research
infrastructure funding, primarily through the ARC LIEF program. LIEFs are matching grants
which require partner organizations (primarily universities) to contribute approximately one297
third to one-half of the total budget. Universities that commit cash to a LIEF receive a
commensurate amount of support from the FAIMS project; the two Australian projects discussed
in this paper fall into this category. This infrastructure grant income is supplemented by fees
charged for customization, field support, server hosting, and other services (a typical opensource
business model, cf. Raymond 2001, 136; Popp 2015); the US-based project discussed
here paid for services directly. To that end, we encourage research projects that plan to use
FAIMS to include an appropriate budget line in their grant applications. To date, fees have
accounted for about 5% of FAIMS budget, with infrastructure grants constituting the other 95% -
although these figures exclude in-kind contributions of time by academic staff and other
participants, which total approximately $100,000 per year at Macquarie University alone. We
envision that within five years, service fees will constitute perhaps 25% of our budget, but the
project will likely remain largely dependent upon infrastructure grants and in-kind contributions.
This funding allows the FAIMS Project to employ a professional software engineering team (as
well as student programmers), to ensure that our software meets high standards and avoids some
of the shortcomings often associated with academic software (Might 2015; Sun 2012).
The FAIMS Mobile Platform
The "core" software of the FAIMS Mobile Platform does a lot of the "heavy lifting"
required of archaeological software: automatic synchronization of data among multiple users,
maintaining record histories for review and reversion of changes, backup, data export, internal
and external sensor management, and provision of a mobile GIS. Since FAIMS is generalized,
however, it has to be customized for each project. Such a “deployment” involves tailoring the
core software by creating or modifying "definition documents," primarily Extensible Markup
298
Language (XML) files, which produce customized data collection "modules" (Ross et al., 2015).
Each module accommodates specific data and workflow requirements, as required by different
approaches to archaeological survey, excavation, and artifact processing. So, for example, the
“Boncuklu excavation module” is an implementation of FAIMS customized for single-context
recording methodology as it is practiced at the excavation of a Neolithic tell in Turkey (see
below).
FAIMS uses GitHub, an online version control tool for collaborative software
development, to publish and manage individual modules (https://github.com/FAIMS; cf. Ross et
al, 2015). Software (or other text documents) stored on GitHub can be downloaded, edited,
copied, and adapted at will. As an example, in 2013 the FAIMS team developed a "deluxe
excavation" module, which provided the foundation for the three deployments discussed here.
This module was duplicated (“forked”) and modified to meet the needs of each project. Using
GitHub not only made the definition documents for all four modules (the original plus the three
adaptations) publicly available, but also allowed the most useful changes to each of the
derivative modules to be incorporated (“pulled”) back into the original “deluxe excavation”
module. Users can now choose whichever of these four modules best fits the requirements of
their own fieldwork. It has been a guiding principle of FAIMS to build a growing library of
modules that accommodate as many archaeological activities, and variations of them, as
possible.
Customizing and deploying the FAIMS Mobile Platform
The Mobile Platform consists of an Android mobile application (available on Google Play)
and a Linux server (available on GitHub). All FAIMS Project software is free and open source
(GPLv3 license). The mobile software will run on most recent Android devices (current
299
specifications are available from https://goo.gl/aB0KqO/). The server can either be a local,
physical computer or can reside online. Users with the time and expertise can implement FAIMS
themselves, or they can purchase that service from the FAIMS team. Two small projects, both
undertaken by PhD students, have successfully customized and deployed their own systems.
Most users, however, have chosen to purchase customization and support services from the
FAIMS team; we have created 19 workflows for 17 projects and supported 11 of them in the
field since the public release of our software in November 2013. Depending on funding for
2016, this number is likely to double in the next year.
Users can establish a local or online server themselves by installing Linux (specifically, the
most recent Long Term Service release of Ubuntu) and executing a few commands to download
and install the FAIMS server software. Once in the field, the server is essentially an appliance
that synchronizes devices and performs automatic backups, requiring little attention. Users only
access the server (via a web interface from any other device on the network) to adjust controlled
vocabularies, manage users, view record histories and revert changes, export data, and perform
other administrative tasks. For those new to the system, the FAIMS Project offers temporary,
pre-configured, online servers for trials at no cost.
For users who want to purchase a pre-configured server, the FAIMS Project has
established relationships with vendors in Australia and the US who can provide and support local
or online servers. Purchasing a pre-configured local server with all necessary hardware costs
AUD $1,700-3,500 from one of these vendors (excluding tablets). Alternatively, an online or
local server can be leased for approximately AUD $150-200 per month. In the case studies
presented below, Boncuklu and MEMSAP purchased preconfigured local servers, while PAZC
used an online server (but later switched to a local server in a subsequent season).
300
After the establishment of a server, do-it-yourself users can customize the mobile
application for their own work in four ways, which require progressively more effort and
technical expertise, but also allow more nuanced control over the resulting module:
1. Reuse an existing module as is, which requires only downloading the application from
Google Play and selecting the desired module from a list;
2. Use Heurist (an online data service), which provides a graphic user interface for the
generation of definition documents suitable for relatively simple modules;
3. Use a simplified module generator, which requires writing a single XML file that
generates definition documents, again best suited for relatively simple modules; or
4. Modify an existing module, or create a new one by editing the definition documents
directly, which requires proficiency with XML and BeanShell (a scripting language).
The FAIMS Project has developed extensive documentation to assist users who want to
establish their own server and customize their modules using any of these approaches
(https://goo.gl/3UQuFF), which was improved recently through a 2015 NeCTAR grant
specifically targeted at user support. The project team provides free support on a time-available
basis.
Thus far, however, most users have approached the FAIMS team for customization
services, including those in the case studies presented here. In such cases, we employ the final
method described above, which provides the most fine-grained control over data structures, user
interfaces, and automation. When a project hires the FAIMS team to adapt an existing module or
develop a new one, this service generally costs approximately AUD $1,500-$15,000 per season
for the Mobile Platform, depending on the complexity and novelty of the recording system
required. Deployments of a module for subsequent seasons are usually less expensive, since
301
users only pay for changes and support. Customization and support work for the Boncuklu and
MEMSAP projects presented here, for example, was valued about $15,000 each for their first
year of deployment (but only $3,250 for a subsequent deployment of Boncuklu). Since the PAZC
project was willing to reuse an existing module, their first year cost only $900 (a subsequent
deployment cost $2,400, after they identified some additional modifications), illustrating the
savings that redeployment can offer. These costs include support for the duration of fieldwork
and assistance with data export (we fix bugs and other errors at no additional charge, but users
pay for significant in-field changes and priority support). As will be seen below, customization
and support costs of this magnitude can be largely recouped from later savings in data
digitization and reconciliation, aside from any other benefits of digital recording (cf. Spigelman,
this volume). Finally, the FAIMS team also offers development-in-trade for in-kind help with
testing, documentation, and other activities to students, another common practice in open-source
communities.
It is our hope that by building free and open source software to high standards using
research infrastructure funding, by providing extensive documentation and as much support as
possible for do-it-yourselfers, by building a library of modules for various activities, and by
offering customization, deployment, and support services at a reasonable cost, we can deliver
purpose-built field-recording software to projects and organizations who otherwise could not
afford it.
302
Between off-the-shelf and bespoke: generalized versus general-purpose field data collection
software
Software development strategies fall along a spectrum (see Figure 2). On one end are
consumer-grade, “general purpose”, desktop database management systems (DBMSes) with
graphical user interfaces, which put "simple" customization into archaeologists' hands. At the
other end sits bespoke software development, where archaeologist (for example) request features
they want, as they would select cloth from a high-end tailor making a custom suit, and software
developers produce a tailored mobile application from scratch.
FAIMS lies near the middle of this spectrum. Compared to a general-purpose DBMS,
FAIMS is generalized in the sense it has no predetermined data schemas or user interface,
instead offering a degree of control over data structures and forms similar to DBMSes like
Microsoft Access or FileMaker Pro. It is not general-purpose, however, in that it is built
specifically to perform well under difficult field conditions and includes functionality requested
by archaeologists (through stocktaking activities, cf. Ross et al. 2013). As a result, for a
customization effort similar to that required by a general-purpose DBMS, researchers get
software optimized for archaeological fieldwork.
For illustration, one example of a fieldwork-specific feature is the capacity of FAIMS to
synchronize across many devices in a degraded-network environment. Most DBMSes store data
on a single server that can be accessed by many clients. Mobile applications also typically use
this architecture, which is simpler and has performance advantages. These applications, however,
expect a regular – if not continuous – connection to a server. Archaeological fieldwork
frequently suffers from intermittent or disrupted network communications. To accommodate
303
these conditions, devices running FAIMS have no need for a continuous connection to maintain
data integrity; they happily operate offline and synchronize whenever a wi-fi network is
available (according to configurable rules). The FileMaker application and DBMS, conversely,
have been designed for more "normal" deployment situations and operate grudgingly in a
network-degraded field environment, requiring work-arounds when asked to collect data
simultaneously on multiple offline devices.2 It does not make sense for FileMaker to optimize for
these unusual conditions, as they require significant trade-offs in complexity and performance,
and return benefits only in specific and limited situations. FileMaker was designed for everyone;
FAIMS was developed around the expressed requirements of archaeologists to manage the highfriction
environment of fieldwork.
FAIMS offers similar optimization for other issues specific to fieldwork, such as the need
to collect a variety of data, work in multilingual settings, and promote the production of
compatible datasets for large-scale, synthetic research. FAIMS tightly binds the diverse data
fieldwork generates (e.g., structured, free text, geospatial, and multimedia), connects to internal
and external sensors, allows tracking and reverting changes to the data, supports customizable
data export in a variety of common formats, translates the interface between languages or
conceptual vocabularies, and maps local concepts to open linked data vocabularies (thus
promoting both syntactic and semantic data compatibility; cf. Wallrodt, this volume; Limp 2011,
277-279). These fieldwork-specific capabilities get inherited by each module; they need not be
newly programmed upon user request. They are all there waiting on users to take advantage of
2 E.g., regarding synchronization and offline use: “For real-time access to the most up-to-date information, host
solutions with FileMaker Server. For this option, purchase of concurrent connections is required along with access
to a local wireless or cellular network. Or to share your solutions offline, copy files to FileMaker Go using iTunes
File Sharing, email or AirDrop” (FileMaker 2015). Keeping a change history and managing geospatial data are even
more difficult.
304
them (or not). This combination of flexibility and domain-specific features is what makes
FAIMS “generalized”.
A bespoke Android or iOS app, if properly resourced and designed, may outperform
FAIMS for any single data collection task, but at considerable cost. The requirements gathering,
planning, development, and testing required to produce software reliable enough for field
archaeology are expensive and demanding. Even after development is “complete”, software has
significant maintenance costs, such as bug-fixing and keeping up with the biennial mobile OS
update cycle (not to mention updates to other components of the software “stack” that underlies
every application). These development and maintenance costs are beyond the resources of all but
the best-funded projects and organizations, such as is iDig, created by the Athenian Agora
Excavations of the American School of Classical Studies (http://idig.tips/; cf. Fee, this volume).
Because the core FAIMS software is common to all deployments, however, the fixed costs of
development and maintenance can be shared across many users, projects and institutions.
Improvements that benefit all users can be made incrementally as resources come available. This
shared core library also allows customization and deployment to be accomplished more quickly
than bespoke development. A generalized, but fieldwork-specific, application has the potential to
attract a large enough user base to sustain it (cf. Kansa, this volume).
The nature of co-development
Participating in open-source development is different from buying software from a
vendor. There are responsibilities, trade-offs, and significant benefits. Instead of purchasing a
finished product, which can either be accepted or rejected, open source tools can be re-invented
and co-developed to fit specific needs. As a generalized platform, FAIMS must be customized by
305
the researchers who use it. This co-development increases the likelihood that individual projects
will achieve their goals, but it also requires archaeologists’ active participation and willingness to
reconsider information management during fieldwork.
Developing a data capture and management system for an archaeological project using
FAIMS constitutes a miniature software deployment project. To an extent, the same is true of
development using desktop DBMSes like Access or FileMaker, but FAIMS is perhaps more
transparent about it, in that development is accomplished through editing text files rather than
manipulating a graphic user interface. The apparent ease of development provided by massmarket
DBMSes seduces users into thinking that information systems can be built and
maintained with minimal investment or technical expertise. Eventually, however, even desktop
DBMSes require considerable scripting to accommodate archaeological workflows. As a result,
the landscape is littered with half-finished or abandoned databases created using desktop systems
(including, admittedly, several built by some of this paper’s co-authors). Because the software
development looks easy, projects under-resource it.
FAIMS treats complex archaeological work with the seriousness it deserves. The FAIMS
approach, partly dictated by the nature of the software and partly by our experience, has led us to
treat the particular archaeology systems deployment as a genuine, miniature software
development project, one which requires proper “scoping” (requirements gathering, software
design, and development planning), coding, and “quality assurance” (testing at each step of
development to ensure that software works and is fit-to-purpose). As such, the authors believe
that our experience also offers lessons also to those who choose to customize commercial DBMS
software.
306
The three case studies
The three FAIMS implementation case studies presented here come from: a Neolithic tell
excavation in central Turkey, a Middle Stone Age excavation and surface survey in Malawi, and
a late Prehispanic/early Colonial excavation in coastal Peru.
Andrew Fairbairn, an Australian Research Council (ARC) Future Fellow and Associate
Professor at University of Queensland (UQ), co-directs excavations at the Neolithic tell of
Boncuklu Höyük (Boncuklu) in central Turkey (Baird et al. 2012; http://boncuklu.org/):
One peculiarity of the site is its extremely fine layering and the
complex intercutting of archaeological features, caused by
rebuilding of houses on the same site time and time again. ... [a
single context in] Boncuklu may be resolved within <5 cm of
deposit. … As a result, excavation has necessarily been finegrained,
utilising a single context recording method better to
understand the subtle interrelationships of the site's building
sequences and extra-mural areas. Single context recording
describes each deposit, cut and feature in detail, including spatial
coordinates and contexts (artefacts, samples) as well as basic
descriptives (form, size etc).
Jessica Thompson, then an ARC Postdoctoral Research Fellow also at UQ (now an
Assistant Professor at Emory University), directed the Malawi Earlier-Middle Stone Age Project
(MEMSAP) in Malawi, which included excavation and pedestrian survey (Thomson et. al. 2015;
http://memsap.org/):
MEMSAP based its excavation recording system on a singlecontext
form-based system modified from Marean et al. (2010).
Given the range of backgrounds represented on the project, it was
desirable that the recording protocols contain as many checks and
constraints as possible, but also that there was ample opportunity
to freehand any observations that may not fit into one of the predesignated
categories.
307
Parker VanValkenburgh, then an Assistant Professor at the University of Vermont (now
an Assistant Professor at Brown University), directed the Proyecto Arqueológico Zaña Colonial
(PAZC), a multidisciplinary project focusing on late Preshipanic and early colonial Peru that
includes excavation (VanValkenburgh 2012):
In our 2012 field season at Carrizales, PAZC team members
recorded data using a single-context recording system on paper
forms. We also drew orthographic illustrations on large-format
millimetric graph paper and captured digital photographs of the
tops and bottoms of each excavated context.
These three researchers generously offered to share and discuss their experiences
deploying FAIMS during 2014 fieldwork. They took the time to complete post-project
questionnaires, and also exchanged a considerable volume of email and chat messages with the
FAIMS team before, during, and after their fieldwork. These sources provide the quotations
below; their complete, unedited communications with the FAIMS project are available via the
Mukurtu digital supplement to this volume (URL). Their observations can be woven into three
themes, demonstrating common challenges, concerns, and benefits shared across all three
projects.
Theme 1: Upfront costs, backend payouts
One of the themes that emerged from these case studies involves the shift in time and
energy from digitization and cleansing of data at the end of the project, to scoping, development,
and testing of recording systems at the beginning of the project. Even considering the up-front
time requirement, however, time savings at the end of the project were substantial – even
revolutionary; an entire season’s data could be retrieved immediately, without tedious
digitization and the errors it inevitably introduces (cf. Spigelman et al., this volume).
308
Scoping and development
Requirements gathering, planning, and development is a lengthy, iterative process that
requires frequent communication, consultation, and feedback. Established projects with stable
procedures have an advantage during software customization, since they can articulate
requirements and priorities quickly and coherently. Even so, field projects with complex
workflows still require several months for development to ensure that the end product satisfy
their needs. Jessica Thompson commented on the numerous discussions and feedback loops she
engaged in during module scoping and prototype testing:
Prior to the field season, the FAIMS leadership team met with
several of its partners at UQ, including those involved in
MEMSAP. .... Several hours were spent in discussions with all
senior project personnel to ensure that all data types they wanted
recorded were represented in the modules, and then after the
workshop detailed plans for the tab layout and controls were
developed mainly by the project leader but in consultation with
other project personnel. ... Ultimately only three iterations of the
excavation module and two iterations of the survey module were
needed before a functional system could be deployed in the field.
However, this was likely because all of the data categories and
relationships had been worked out – in paper version – over the
course of previous field seasons.
Converting from paper to digital workflows is an involved and time consuming process. It
requires making the implicit knowledge embedded in paper forms explicit. Digital forms are also
more formalized and restrictive than paper forms; relationships between entities, controlled
vocabularies, and other aspects of the data model must be defined and encoded (cf. Motz, and
Gordon, this volume, who had to write full protocol manuals to ensure users understood their
data model). Paper forms can approximate the desired data collection strategy, with exceptions,
omissions, and edge cases written in the margins or on the back of the form. Despite some
309
FAIMS features like the “annotations” field embedded in all attributes where users can make
contextual notes, which reproduce the freedom of the paper page (Figure 3; cf. Ellis this
volume), digital forms must be more precise and complete, or their primary advantage - the
production of clean, consistent data - is lost. The conversion from fuzzy paper forms to sharp
digital recording often instigates a thorough review and revision of existing recording procedures
and workflows. Andrew Fairbairn noted the benefit of this revision process:
In the process of defining the parameters of the future FAIMS
module I also got the opportunity to thoroughly review and refine
the Boncuklu recording system to the last field and attribute, which
identified some redundancies and allowed better definition of the
attributes expected in the system.
The critical resource during software development is time, which may be allocated to
scoping, to developing new features, to improving performance, or to testing, bug fixing, and
ensuring fitness for purpose. Since time is a finite resource, to some extent these activities must
be traded off against one another. At some point, the archaeologist must finalize their data
model, their list of entities, attributes, and vocabularies, so that development can end and testing
may begin, with enough time to fix and finalize the module before fieldwork begins. While the
"perfect" module can be a moving target, the perfect is the enemy of the good. Sometimes we
must ship good, but imperfect, software to do fieldwork. In order to collect useful data while
controlling the time spent on scoping and development, Andrew Fairbairn recommends:
Consider your recording needs in depth well before deployment of
your module and learn to articulate those needs explicitly. Time is
money and imprecise, poorly articulated demands increased the
developers’ time on this module. Provide precise instructions and
well-articulated aims to your developers.
Parker VanValkenburgh followed this advice, and his module was produced quickly:
310
The total time that elapsed between first contact with FAIMS
leadership and deployment of the finished PAZC module was
approximately three and a half weeks.
The PAZC module also benefited from reusing the Boncuklu module with some modifications
(emphasizing the advantages of an open source, document-based customization strategy:
modules can be rapidly modified and redeployed, while each new module or modification
improves the whole system). The FAIMS team translated the Boncuklu module into Spanish and
customized it where required by editing the Boncuklu definition documents, a process that
required less than one week after requirements were fully specified. The speed of production was
possible because of Parker VanValkenburgh’s pragmatism and willingness to adapt an existing
module. As this example illustrates, a system with a generalized core can spawn new
deployments rapidly in a way that neither bespoke nor general-purpose systems can.
Testing and training
To test, or not to test - that is the question: Whether 'tis nobler in
the mind to suffer the slings and arrows of crashes and incorrectly
implemented features or to allocate development time against a sea
of trouble tickets and by opposing end them. To ship, to commit no
more - and by shipping we end normal development and the
thousand emails that development is heir to.
-Brian Ballsun-Stanton (after a late night of bug-fixing)
Software development requires that scoping, development, and testing be finite, limited,
and in balance with one another. In the FAIMS experience, archaeologists tended to prioritize the
development of new features at the expense of testing. This is hardly surprising, as feature
development is exciting and novel, as opposed to the rote, but essential, work of testing. While
feature planning is rewarding and creative, it must be kept in check, and cannot outrun the
resources available for ensuring adequate performance, and testing quality and fitness to
311
purpose: "Testing the module prior to fieldwork ensured it was technically functional, and
allowed for communication of changes that would be hard done remotely" (Jessica Thompson).
All project directors tested their modules ahead of fieldwork, but eventually they all
regretted not doing so more thoroughly, with more participants, and in more authentic situations.
Jessica Thompson realized the shortfalls of her own testing only when she was in the field:
Once in the field the use of modules revealed other usability issues
that varied across the team. Simulation of fieldwork is highly
advised here. Or better yet, training a project novice in the use of
the module is where potential misunderstandings (of the workflow)
become apparent.
Andrew Fairbairn, too, found a problem of fitness-to-purpose on the first day of fieldwork that
had slipped through his earlier testing: "A significant problem with the app design has arisen. It
is one that I flagged earlier but somehow it got through my later checks…"(email, 5 Aug 2014).
Fairbairn's module had to be updated while live in the field. Live updates, designed for situations
like this one (where a problem is identified after deployment) can be useful (cf. Fee, this
volume), but they pose risks of failure due to the lack of testing and should be avoided.
Hardware can cause its own problems, such as device-specific bugs. Software that
worked during internal testing by the FAIMS team (or even by archaeologists prior to fieldwork)
did not always work on different tablets (even if they were made by the same manufacturer).
These compatibility problems are the price paid for the wide range of devices offered within the
Android ecosystem. It therefore proved necessary to test the FAIMS Mobile Platform on each
device. Andrew Fairbairn explained the importance of specific and realistic testing:
Test your module and, if you are using multiple tablets, the server
and its system extensively before you depart for the field with real
data including every field and recording type you may use; bugs
may be hard to find and you need to be sure the system works for
your needs.
312
Several months may sound like a long time for complex module development, but in typical
software development project it is a very short timeframe. While the FAIMS approach of
customizing generalized software can produce recording systems faster than bespoke software
development (Kitchenham 2002), the modules still require extensive testing. The amount of
testing necessary is a product of the complexity of the module, the degree of automation and
flow logic it incorporates, and other features like GIS integration, translation, or multimedia file
management. The rigor of testing determines the quality of the fieldwork experience and
resultant data, which from the perspective of the FAIMS team, make it worth a significant
investment of everyone’s time.
The payoff: clean, granular, digital data
After fieldwork, the FAIMS team asked each of the project directors to reflect on the
design, development, and deployment of their module, and tell us what they found the most
worthwhile payoff for their efforts.
Fairbairn appreciated having his data available to him shortly after the end of fieldwork,
especially the ease of export into the desktop software he normally uses (Access). He received
his Comma Separated Value (CSV; a standard spreadsheet-type format) data files, and created an
Access database from them, before the paper forms (used as a backup to FAIMS as part of the
transition to digital recording) arrived to Australia:
[I have received the CSV file and] the data are present and useable.
I am now waiting for [the other project director] to send me the
forms… (excerpted from Google Hangouts between Brian and
Andrew Fairbairn, 18 September 2014)
313
Parker VanValkenburgh enjoyed the “richness and integrity” of digitally-born data:
[…] our final review of data collected by the PAZC in 2014
suggests that using FAIMS improved both the richness and
integrity of our data. Context descriptions are generally more
detailed, and the range of fields in the FAIMS default module
meant that project members recorded types of data (such as
parameters of soil matrices and inclusions) that we had formerly
treated in an inconsistent fashion.
Jessica Thompson agreed, noting the benefits to be accrued over multiple field seasons:
The FAIMS data outputs [...] required [...] much less cleaning,
organization, and streamlining for consistency than transcribed
data. [...] However, it was clear that once this initial hurdle was
overcome it would be far faster and error-free to append FAIMS
data from subsequent seasons onto these merged databases than to
return to a paper form recording system.
The data management benefits were especially clear in the MEMSAP survey team's change of
opinion over the quality of survey data when collected with tablets. Jessica Thompson
emphasized the improved consistency of data, and the value of having various types of data
(structured, geospatial, and image) automatically linked, something that is difficult to implement
with general-purpose database software:
When the survey data were examined and analysed during postseason
work, it became very clear to the survey team that the
tablets presented a huge advantage. During post-processing all the
data were tied together already and did not require the manual
integration of paper forms with separate photo logs and GPS
records – nor did they suffer from the inevitable transcription error
that in this case cost at least six person-hours to investigate and
rectify. There were fewer errors made in data recording with the
tablets, and the pre-defined categories made the data far easier to
sort, search, and analyse. When the scope of data entry, cleaning,
analysis, and archiving is considered, the tablets saved at least
eight person-days of work, although this may have been an
extreme case because one of the main post-season challenges
[during previous seasons] was the integration of both paper and
tablet data into a single database.
314
Andrew Fairbairn also quantified the time-savings and cost-benefit of clean, born-digital data to
his project:
The greatest gains in the FAIMS system were found after the
excavation season was finished with post-processing of the data
and checking taking 2-3 hours in comparison to several hundred
hours for entry of the >300 context records generated in a typical
season. This saving in paid RA time equates to c. AU$5,000-
10,000 per annum. Post-processing required specialist input by
FAIMS to extract CSV files from the data tarball [.tar, a common
Linux file archive similar to .zip], but the outcome was easily
accessible and useable data which can be uploaded to a database.
In the Boncuklu case the CSV tables did not match the legacy
database, however, some relatively quick (0.5-1 day) of time
allowed the data to be uploaded. The benefits to the excavation
project in financial/labour terms are hugely significant, equating to
a total of 1-1.5 days of handling time using FAIMS against 25-30
days when not in use per annum, in other words a 95% labour
saving.
Finally, Andrew Fairbairn discovered an unexpected benefit of having his digital data available
immediately: the timely discovery of errors. “I also can see all the inconsistent entries that were
made by people who should know better” (excerpted from Google Hangouts between Brian and
Andrew Fairbairn, 18 September 2014). His data was digital and ready for review promptly at
the end of the season, which revealed problems that would otherwise have gone undetected until
the paper forms were digitized, perhaps months later, when the errors would have been far more
difficult to correct. Even when digital data creation does not prevent errors, it exposes them.
While many projects prefer to collect data first and spend effort cleaning it later, our
partners chose to invest effort before fieldwork, in order to have cleaner, richer data for
immediate analysis. Learning the capabilities of FAIMS software and engaging in the scoping
and testing required by co-development all took more time before fieldwork than producing
315
paper forms would have. After fieldwork, however, they got rich, well-structured data at the push
of a button, while such errors and inconsistencies as there were in the data could be detected
immediately, rather than during later digitization or processing. Andrew Fairbairn and Jessica
Thompson could quantify the savings in time and resources this trade-off produced; based on
their experience, most projects would likely come out ahead.
The importance of high quality support
Exceptional support is necessary when deploying new technology in the field, especially
software purpose-built for the research community (Fisher et al., 2010). Only the availability of
high-quality and timely support can provide the peace of mind necessary for archaeologists to
risk moving from commercial software to new systems designed specifically for our domain. The
FAIMS team’s provision of such support proved crucial to the success of field deployments. To
date the FAIMS Project has provided support as part of the module development package.
Jessica Thompson makes the importance of support very clear:
The app has been such an incredible advantage in terms of
workload, data quality, and a number of other data management
issues with which archaeologists regularly have to deal. It readily
links disparate data types that are otherwise stored separately –
such as photographs, tabular logs, and context relationships. I can
see this user-friendly app being easily transferrable to other
projects, and the support team has been brilliant. The hardware
system was also quite remarkable in the way that it collected data,
then synced and backed it up daily. Even projects like ours where
we have no electricity on site can use the setup as long as there is
power back at the home base. There were the usual start-up bugs,
but the FAIMS team has already done an immeasurable amount of
work to remedy all of them. From this already very exciting start, I
can only see the FAIMS initiative becoming even more of a boon
to archaeologists everywhere (Addendum 1, 6 November 2014).
316
From the perspective of the FAIMS team, the biggest challenges were (1) communicating with
archaeologists in remote locations, and (2) reproducing software errors back at our office. The
stochastic nature of communication across time zones, often using unreliable channels, hampered
technical support. Instruction in the effective reporting of bugs and other problems was also
necessary, especially from remote locations under the stress of fieldwork. Once identified and
reproduced by the FAIMS team, bugs were quickly fixed, unclear workflows explained, and
alternative paths around design shortcomings developed - but accurately reporting problems so
that they can be reproduced is an acquired skill.
Over time and with use, software becomes more mature, so that fewer bugs and problems
arise. Developers and users can also cooperate to produce documentation that gradually replaces
live support. For the innovators and early adopters introducing new technologies to complex
projects, however, there is no substitute for patient, timely, and comprehensive support from
developers.
Theme 2: Trade-offs and Shared Lessons
The shared responsibilities of developers and researchers are perhaps clearest in the
context of the trade-offs between features and performance that must be made during the
production of a field recording system. Each of these choices can have serious consequences
when the final system is put under the stress of a full deployment. Two seemingly minor
decisions, the use of complicated autonumbering, and the choice between local and cloud-based
servers, offer examples of such trade-offs.
317
Legacy features versus performance: how to auto-generate smart context numbers
One of the major deployment challenges the FAIMS team experienced was
archaeologists’ requirement that FAIMS reproduces complicated context numbering schemes.
These numbers did more than identify a context, but also encoded multiple pieces of information
about it. Archaeologists wanted these numbers to be generated automatically and validated
against all other records in the database to ensure they were properly ordered and unique.
Some of the project directors asked for auto-generated context “numbers” (actually
alphanumeric identifiers) that would conform to legacy systems inherited from paper forms;
“Context name|HHAB” (Andrew Fairbairn) or “2228|SS|11|I|F5” (Jessica Thompson) for
example. These identifiers had to be generated according to specific rules to avoid duplication,
ensure sequential numbering, and eliminate gaps (i.e., reuse identifiers that had been deleted).
While FAIMS did automatically generate such identifiers, doing so reduced performance. Each
time a new context was opened and an identifier generated, the software had to read every record
in the database, parse related records to determine the next appropriate identifier, and write the
new number according to specific rules, all the while checking it against a growing list of
existing identifiers for duplication, omission, and sequential order. The FAIMS team anticipated
that this process would slow the software down, but it was difficult to communicate the
seriousness of the threat. Performance degradation was barely perceptible during testing, which
involved only a few records, but it worsened exponentially as the database grew (more precisely,
as a square function of the number of records). Andrew Fairbairn commented: "More serious was
the slowdown of the system halfway through its period of use. A record which initially took 20
minutes to input took over an hour due to slow syncing and updating." Parker VanValkenburgh
318
agreed: "These improvements [digital data] have come at a cost – namely, less efficient data
collection in the field. While we have yet to keep time-on-task records for either paper-based
recording or FAIMS, project members universally reported that data entry using FAIMS took
longer than using our previous analog system."
Jessica Thompson’s “2228|SS|11|I|F5” identifier, for example, encapsulates the distinct
attributes of LotID, Site Code, Context ID, AreaCode, and Grid Location Reference. Five
variables combined into one code may be easy for humans to read (although they can become
obscure to future users of the data if coding sheets are not included with the data), but it is
resource-intensive for machines to parse, especially when each variable is subject to a different
set of rules. The implementation of this five-variables-in-one-field feature was possible, but it
reduced performance and cost significant development time, which could have been better spent
on other features or on testing.
This slowdown was avoidable, since the actual information encoded in the context
identifier can be captured in ways that do not compromise performance. Those five pieces of
information did not have to be forced into the context identifier. Instead, they can be stored
normally in five separate fields. The critical part of the identifier (the context number) can be
automatically incremented from a manually assigned starting number (a “seed”). Assignment of
seeds to individual devices, combined with server-side validation after all devices synchronize,
ensures uniqueness of the critical portion of the overall identifier without performance
degradation. The five separate fields can be concatenated on export into a combined identifier to
maintain the expected output.
Context numbering illustrates a larger issue. The question of "how closely do we
duplicate our paper forms" is common to archaeological projects that are going digital. It is
319
worthwhile to step back and consider the purpose behind legacy recording approaches, and
weigh the problems and benefits of replicating them. Sometimes automation of a faithful replica
is desirable and worth the cost in development time and performance, but at other times, more
robust digital approach will capture the purpose of legacy system, save time, improve
performance, and offer additional benefits (in this case, verbose, human-readable context
information that does not require decoding a complex identifier). In 2015, both continuing
projects (Andrew Fairbairn’s and Parker VanValkenburgh’s) chose simpler context numbering
approaches.
Local versus online servers
Like most databases, the FAIMS mobile platform is a server-centered system, although
client devices are coupled more loosely than usual to the server. The FAIMS server can take
different forms. A virtualized instance of the server can run online (e.g., in the Australian
NeCTAR Research Cloud) or on client laptops, or clients can commission a customized and
preconfigured hardware package (“FAIMS-in-a-box”) with a dedicated server, network
equipment, and certified tablets. Each hardware option has its trade-offs, which project directors
will need to consider. Purchasing a FAIMS-in-a-box is more expensive than renting an online
server and a suite of tablets for short-term deployments, but it offers greater reliability and faster
synchronization, completely avoiding internet connectivity and bandwidth problems that plague
remote (and sometimes not-so-remote) locations. An online server required less attention from
archaeologists than a hardware server, and was not subject to the wear-and-tear, intermittent
electricity, and other hazards of deployment in the field. Different options are available because
320
each project has different needs. Andrew Fairbairn had the best experience using FAIMSshipped
hardware:
Also, it is worth noting that the equipment - FAIMS-on-a-box -
worked very well and with the exception of 1 tablet screen -
cracked when an item fell on it from the edge of the trench - came
through the season in great condition. This was in spite of very
dusty conditions and a somewhat unreliable electricity supply. The
server worked throughout and the [wifi] provided excellent
coverage (75-80% signal strength at 80m, the furthest excavation
trench. The server hung only once, when the UPS plug was
knocked out during a power outage, but was simply re-booted
using an external keyboard.
Andrew Fairbairn's experience with high coverage and good hardware reliability
represents our "best case scenario." Jessica Thompson encountered some problems, but still used
the FAIMS-in-the-box to great effect. Debugging her setup under field conditions proved
challenging, reinforcing the need for more authentic testing and comprehensive support for new
technologies going into the field:
Setting up the network was also much more of a challenge when in
the field than during a trial run in an office. There were several
technical difficulties with the boot-up of the server, leading to
many instances when data would not sync or when the server
required an external keyboard and monitor to troubleshoot. The
technical support provided by FAIMS was exceptional, and
through a combination of their support and the fortuitous
possession by project personnel of the needed hardware, all issues
were overcome and have now been addressed by subsequent
iterations of FAIMS hardware supply. This scenario would be
much more difficult to negotiate in a field situation where internet
is not readily available, and so in spite of the improvements that
have been made, the necessity to fully set up and field test the
entire system from start to finish before going to the field cannot
be over-emphasized.
Instead of using a dedicated hardware server, Parker VanValkenburgh attempted to install
a virtual server on his laptop. Unfortunately, the installation failed, and an online server was set
321
up instead. His subsequent problems demonstrate the unreliability of the Internet in fieldwork
settings:
We began with futile attempts to set up our own FAIMS server in
the field house, in a Ubuntu virtual machine run off of a Windows
laptop. Because we did not possess the resources to dedicate an
entire machine to serving FAIMS, the development team provided
us with access to their cloud server, and we set up a wireless access
point in our dig house by running a 100-meter network cable from
a nearby internet café and connecting it to a wireless router. Using
this system, our upload speeds consistently averaged 25 Kbps – too
slow for syncing, even when tablets were left to do so overnight.
VanValkenburgh then attempted to sync tablets on weekend trips
to a city located one hour’s drive away from Zaña. However, the
large numbers of photographs we were attaching to our data
records made complete syncs impossible. In the end, the FAIMS
development team adjusted the PAZC module to allow syncing of
our textual data alone, and we manually backed up all photographs
onto external hard drives.
The lesson from these experiences echoes other aspects of co-development: reliability
and performance require an investment from archaeologists as well as the development team.
Local, dedicated, hardware servers are more expensive than online servers, and they require that
users learn to test and maintain them, but they are faster and more robust than online servers.
Theme 3: Digital recording and archaeological interpretation - where is the benefit?
When asked to assess the direct impact of the digital recording on their research, project
directors first emphasized improvements in the quantity, quality, and availability of data. Jessica
Thompson reported: “Because FAIMS enabled data to be collected and processed so efficiently,
we were able to collect more data, and this expanded the interpretations we could make from a
field season of the same duration as when we used paper forms” (Addendum 2, 13 Dec 2015).
Likewise, Parker VanValkenburgh remarked that “the richness and integrity of our field data
322
have both increased” (Addendum 14 Dec 2015), an assessment echoed by Andrew Fairbairn “the
conversion [to digital recording] increases quality of information available and makes postexcavation
reconstruction of the site (the aim of the record) much easier…[it also] sped up
exchange of information on site between excavators and specialists” (Addendum 9 Dec 2015)
Although “efficiency” should not be the only, or perhaps the overriding, goal of digital research
(cf. Kansa this volume; Caraher, this volume), project directors nonetheless reiterated that
enhanced speed, accuracy, consistency, and granularity represent important contributions of
digital recording to archaeological interpretation.
The process of building data models and accommodating the precision of digital systems
also compels archaeologists to critically review their recording practices more generally:
[I]mportantly, the technology has opened up a broader dialogue
about the recording process, increased awareness in the excavation
group of the challenges and requirements of recording and opened
a quite fixed system to change (Andrew Fairbairn; Addendum, 9
Dec 2015).
As part of that review, Andrew Fairbairn also noted how digital recording preserved previously
undocumented interim steps of fieldwork:
[W]e have had a very archaic use of "official site photos" which
are of the cleaned up contexts. Well, now everyone can take
images as they go, including as contexts are under excavation
(rather than tidy for archive shots) and this improves the chances
of understanding the features and contexts we see (Addendum, 9
Dec 2015).
More continuous recordkeeping, including of “messy” work-in-progress, not only helps
researchers at a later time better understand what they have excavated, but may contribute
towards making workflows more transparent and towards “openly exposing the process of
323
research” (Kansa, this volume, 403), improving the reproducibility and professionalism of field
research.
Digital data collection may not immediately alter researchers’ aims or interpretive
agendas. Andrew Fairbairn began his response to questions about impact by observing that “so
far conversion [to digital recording] has not changed our substantive research goals”
(Addendum, 9 Dec 2014). Parker VanValkenburgh concurred, admitting that “I'm not sure I feel
comfortable at this point asserting that digital field recording methods led us, in linear fashion, to
a series of different conclusions about the past” (Addendum, 14 Dec 2014). It can, nevertheless,
allow researchers to follow hunches as the project progresses, and prove or disprove these
intuitions later. Parker VanValkenburgh also expects digital approaches to help separate real
relationships among his data from accidents of preservation:
[I]t's going to be much, much easier to look back at that data when
we're making sense of variation in the results of materials analysis,
including zooarchaeological, archaeobotanical, and ceramic
research. […] my speculation is that I'm going to feel much more
capable of making it clear that taphonomical differences between
the two site areas do not adequately explain the differences we're
seeing (Addendum, 14 Dec 2015).
Similarly, Jessica Thompson thought that the standardization of digital data “clarified the
analyses that were needed in order to address questions about the spatial relationships of
artifacts, landforms, and other objects of interest” (Addendum, 13 Dec 2015). The ability to
make this sort of data-driven, quantitative argument improves the explanatory power and
reproducibility of archaeological research, especially when it is combined with dissemination of
the underlying data itself.
Finally, some of the benefits of digital recording may not be realized immediately. Parker
VanValkenburgh noted that the full impact of digital recording would not be clear until after
324
post-fieldwork analysis and integration were complete (Addendum, 14 Dec 2015). Looking even
further ahead, digitally-born data makes the timely publication of datasets more likely: “the
ready availability…of our digital data is going to greatly facilitate making it publicly accessible
in approximately two years” (Parker VanValkenburgh, Addendum, 14 Dec 2015). It is perhaps at
the comparative or synthetic level, beyond individual projects, that we should seek the greatest
interpretive impact. Only after digital datasets are published and researchers start reusing and
combining them will the full potential and impact of digital methods be realized.
Conclusions
As field researchers transition to digital archaeology, they face a number of choices. They
must decide the extent to which they want to go digital, whether to pursue mass-market,
generalized, or bespoke solutions, and how involved they want to be in software development –
bearing in mind that archaeological recording is complex, heterogeneous, and idiosyncratic
enough to require significant development, regardless of the particular approach (cf. Kansa and
Bissel 2010). On one hand, giving developers sufficiently specific instructions, and making
implicit knowledge explicit, is time-consuming, tedious, and prone to failure (Segal 2005). On
the other hand, sticking with paper minimizes upfront time investments, at the cost of extensive
digitization, data cleansing, and error correction later (Roberts 2011, 147, cited in Huggett 2012,
542). "Just doing it yourself" with commercial software has a certain attraction, but it requires
significant compromises, since no mass-market software package was built with field
archaeology in mind. It also hides, but does not eliminate, much of the pain of scoping,
development, and testing. Bespoke applications, while capable of producing good outcomes, are
expensive to build and difficult to sustain.
325
The authors of this paper believe that FAIMS strikes a good balance between the redeployability
of general-purpose database software and the domain- and project-specific
capability of bespoke applications. Software co-development in a generalized framework like
FAIMS, involving a genuine partnership between archaeologists and technologists, can be a
difficult but productive process that can yield systems that are effective and fit-to-purpose.
Archaeologists know their particular projects and where they are likely to be improved by
technological intervention, but not always what can be achieved within a reasonable time and
cost. Technologists know the capabilities of their software and, in cases like the FAIMS Project,
have accumulated experience across many deployments, including both successes and mistakes
FAIMS 2.0, released in November 2014 is an example of co-development as it benefited
enormously from the three projects discussed in this paper. Successful software development,
including customization of commercial DBMSes, however, benefits from such collaboration.
In this context, our case studies revealed a number of consistent themes: (1) moving to
digital recording requires an up-front investment of time and resources balanced by a payoff of
clean digital data later in the project lifecycle, (2) co-development helps archaeologists and
technologists make appropriate decisions to balance features, reliability, and performance, and
(3) higher quantity, quality and availability of digitally-born data is a welcome immediate benefit
to the (oft painful) transition to digital workflow, ahead of potential long-term benefits, including
more rigorous analyses and dissemination of comprehensive digital datasets, which may
eventually revolutionize interpretations.
The case studies presented here offer lessons applicable to any field software
development project. Time invested up-front during development pays off with time saved
digitizing and cleansing data. Define requirements and plan carefully, but expect some
326
miscommunications that will only be resolved through iterative testing and development. Leave
time for iterating. Leave time for testing. Test early and often. Do not overemphasize features at
the expense of performance, testing, and bug fixing. Test all hardware and software again under
authentic conditions. Ensure field researchers have excellent in-field support. Developing
software that is fit-for-purpose is hard, but the benefits of doing it right are worth it.
Acknowledgments
We would like to thank the organizers of the NEH Mobilizing the Past conference and
everyone involved in the production of this volume, particularly the reviewers and editors who
provided such valuable feedback. The FAIMS Project was funded during 2012-2013 by the
National eResearch Collaboration Tools and Resources (NeCTAR) eResearch Tools program
(RT043), and from 2014 to 2016 by the Australian Research Council (ARC) Linkage Equipment,
Infrastructure, and Facilities (LIEF) program (LE140100151). The University of New South
Wales (2012-2014) and Macquarie University (2015-present) have offered the project a home
and made significant cash and in-kind contributions to the LIEF (which is a matching grant).
Other organisations providing cash and in-kind contributions to the LIEF-funded phase of the
project include: the University of Queensland, the University of Sydney, La Trobe University,
Flinders University, Southern Cross University, the University of California, Berkeley (Open
Context), the University of Chicago (OCHRE), Digital Antiquity (tDAR), and the University of
York (the Archaeology Data Service). For more project information, see
https://www.faims.edu.au/.

3.3. CSS for success? Some thoughts on adapting the browser-based Archaeological
Recording Kit (ARK) for mobile recording
Andrew Dufton, Brown University
The Archaeological Recording Kit (ARK) is an open source system for flexible, webbased
archaeological data management. Designed in 2005 to facilitate simultaneous data creation
and dissemination through a customizable web interface, ARK faces new challenges with the
growing use of tablets for on-site, paperless recording. At least two pressing questions have
emerged: how do mobile devices interact with ARK’s current codebase, which relies on a single
webserver? And is now the time for the ARK team to develop a stand-alone, offline tablet
application?
This paper looks at the first ten years of ARK’s history to situate these questions within
the wider trajectory of its development, and within broader trends of mobile computing.
Understanding the initial goals of the project, and the background of the project team, helps to
identify the underlying ideologies structuring ARK data and functionality, the projects that have
historically shaped its growth, and the likely paths for future expansion. Detailed attention will
then be given to different examples of projects which have chosen to employ ARK with
tablets—from the commercial sector, in academic research, and in community-based
archaeological practice; these case studies demonstrate some strengths and weaknesses of such
an approach for both paperless and paper/digital hybrid recording. In each example, the
customization of the Cascading Style Sheet (CSS) controlling the HTML interface for ARK
emerges as a cost-effective means of facilitating concurrent data recording and viewing on
tablet-, phone-, laptop-, and desktop-based systems without a need for changes to the existing
data framework or core functionality. Further work toward a fully responsive design, rather than
322
a focus on an offline application, is presented as one possible future for an ARK that respects the
push toward sharing data online—a commitment that remains at its ideological core.
What is ARK?
The Archaeological Recording Kit, or ARK, is a web-based toolkit for the collection,
storage, and dissemination of archaeological data (“About ARK” 2015).1 Developed using the
Apache, MySQL, and PHP stack commonly used for web applications, the system relies solely
on open source software, and is also released on an open source license—meaning the code is
freely available to download and customize by individual projects for non-commercial use. ARK
was originally released and is still maintained by L – P : Archaeology2, a commercial partnership
of archaeologists working within the United Kingdom.
ARK data is structured using an entity-attribute-value (EAV) data model, in which
fragments of data are linked to a primary key—in most cases, the context record or stratigraphic
unit (Eve and Hunt 2008). The SQL table structure abstracts these different data fragments into a
series of basic data types, such as text, attributes, dates, actions, temporal spans, or uploaded
files. These individual fragments are then pulled by a collection of PHP subforms, to be
displayed or edited within a web browser according to a series of configurable settings files. A
context record, for example, could be attached to a number of different data fragments: text
entries for color, compaction, or composition; various uploaded photographs; metadata
surrounding the record author or its date of creation; or its stratigraphic relationship with other
context records (Figure 1). The user interface for entering or viewing these data is controlled by
Cascading Style Sheets (CSS), a programming language dedicated to styling the HTML output
1 The ARK system can be downloaded at http://ark.lparchaeology.com
2 http://www.lparchaeology.com
323
of web documents and controlling things such as the font, spacing, background, or layout of a
given page.
The configuration of ARK is organized using a modular structure, where each module
represents a different type of archaeological record. The details of an individual context record,
for example, are controlled by a dedicated PHP settings file with associated fields added to a
series of MySQL tables. In the case of a pedestrian survey, contexts may be replaced by survey
units. Some form of photographic module is usually included, as are modules for drawn plans,
finds, and ceramic data. Although each module requires a single table to hold the primary record
identifiers—the unique context number, photo number, or find number common in almost all
recording systems—the core functionality and table structure is otherwise unchanged (Figure 2).
Thus ARK projects can install as many, or as few, modules as are needed simply by installing
the relevant configuration files, and can also create new custom modules or edit existing ones
according to the site conditions without additional programming (see Sobotkova et al., this
volume, for a similar take on modular application development).
ARK is entirely web-based, and requires no external software beyond a web browser to
create, view, or share data—a use of web tools for archaeological data management similar to
other browser-based systems, such as the PKapp of the Pyla-Koutsopetria Archaeological Project
(Fee et al. 2013; Fee, this volume). This does not mean that ARK requires an active internet
connection to function, but rather that ARK relies on web technologies to create and manipulate
data. The basic Apache/MySQL/PHP package required for ARK can easily be installed in any
Linux, Windows, or Apple operating system, essentially creating a local webserver on any
computer. Users can then access this local webserver on laptops, phones, or tablets, either over a
dedicated wireless network or connected directly to a wired Local Area Network (LAN). Such a
324
set-up is possible both in the lab or site museum for end-of-day data entry and also, in the case of
many long-standing excavations, over a site-wide wireless network for on-site digital recording.
How did we get here?
Much of the debate that emerged during the Mobilizing the Past workshop and
throughout this volume focuses—quite rightly—on the ways in which archaeological practice is
impacted by the technological choices we make in the field. Such a discussion is situated within
a much wider dialogue about the relationships between new digital tools and the archaeologists
who adopt them (Chrysanthi et al. 2012; Huggett 2000; Perry 2015; Zubrow 2006). A shift from
paper to tablet recording, like evolving digital data systems more generally, has great potential to
increase fieldwork efficiency and introduce new ways of thinking about and with data ‘at the
trowel’s edge’ (Berggren et al. 2015; Chadwick 2003; Dufton and Fenwick 2012). Yet without
critical and ongoing reflection, these technologies risk the kind of technological determinism and
unquestioned positivism that are described by Caraher (this volume), and that also characterized
adoption of similar ‘new’ technologies within the past 25 years, such as Geographic Information
Systems (Hacigüzeller 2012; Huggett 2004; Llobera 1996; Llobera 2012; Wheatley 2000).
An acknowledgement that the tools archaeologists use, digital or otherwise, structures our
relationships with resulting archaeological data—its creation, storage, and use in generating
wider narratives about the past—has lead Jeremy Huggett to propose a new manifesto for an
‘Introspective Digital Archaeology’ (Huggett 2015). Huggett suggests moving beyond solely the
details or justification of the application of digital methods, to a ‘third wave’ of digital
archaeology:
“which seeks to examine the ways in which digital technologies may have changed what
we do, how we do it, how we represent what we do, how we communicate what we do,
325
how we understand what we do, and how others understand what we do.” (Huggett 2015,
88)
This introspection requires, in particular, a look at the choices made during the conception and
application of various technologies. What research problem was the technology created or
adapted to address? What were the goals of the original application? Who were the developers?
These questions—and the underlying tensions between the sometimes conflicting needs of
effective data collection, use, and dissemination—are best answered with an ethnographic
examination of the development process (Huggett 2012, 546; Huggett 2015).
Any manner of deep ethnographic study of the origins and trajectories of the ARK system
are well beyond the scope of this discussion. Nevertheless, a few details surrounding the early
conception of ARK, and the backgrounds and theoretical leanings of the development team, will
suffice as an introduction to subsequent consideration of the strengths and weaknesses of the
system for tablet recording.
The initial creation of ARK, as well as the bulk of its ongoing evolution, was undertaken
by a team of archaeologists with a strong digital focus, as opposed to programmers with
specialized technical training but little archaeological experience. The ARK codebase was
compiled in 2005, drawing from existing data systems originally designed by L – P :
Archaeology for various projects: the FastiOnline database of Mediterranean excavations
produced by the International Association of Classical Archaeology (Rome); the excavations of
the Institute of Classical Archaeology (University of Texas at Austin) at the National Preserve of
Tauric Chersonesos (Rabinowitz et al. 2007); and private, developer-funded archaeology at
various sites within the UK, such as the Prescot Street Project (Hunt et al. 2008; Morgan and Eve
2012). Continuing with bespoke solutions for these unrelated projects was proving increasingly
ineffective given limited resources and manpower. A single, heavily-customizable system that
326
could be adapted to archaeological recording in research and commercial contexts, to site
gazetteers and beyond, was thus created to streamline code development (Figure 3).
The initial goals of the ARK system were fivefold: multivocality, reflexivity, data
integration, openness, and flexibility (Eve and Hunt 2008). The first two, in particular, were
heavily inspired by a sense of teamwork and camaraderie between excavators, supervisors, and
digital specialists fostered during months of excavation throughout a rainy, grey London winter.
Rather than relying solely on the supervisor during the process of synthesis, we asked how a
database system could facilitate contributions from all members of the team. How might the
ongoing process of excavation and data recording feed more directly into emerging
interpretations and site narratives? These questions from 2005 are still directly relevant to
discussions of tablet recording in 2015. In the case of ARK, the frustrations of archaeologists
working within the British commercial sector with the top-down, post-excavation analysis of
fieldwork results led to a functionality allowing multiple interpretations—each attributed to
individual team members, each informed by the latest site and laboratory findings, and each
noting the date of interpretation to keep track of how these may change throughout the course of
a project.
The other three goals for ARK revolved, at least to an extent, around more practical
concerns. The integration of drawn, photographic, spatial, and textual materials into a single
digital system mirroring the paper record saved time and resources on commercial projects.
Research projects also benefitted from a digital archive incorporating spatial data and
photographs, yet requiring no specialist software. A need by early ARK projects to
synchronically create and freely disseminate data, and to access these data from across the globe,
was best met by a web-enabled solution. Finally, developing a flexible data structure that could
327
easily be adapted by international projects without restricting those projects to a specific (usually
national) recording standard, and releasing the code for the system on an open source license,
encouraged contributions to the functionality of ARK. This flexibility and openness helped
spread the costs of new features between a larger body of stakeholders than would have been
possible with a more bespoke solution relying on proprietary software (see also Sobotkova et al.,
this volume).
Where do we go next?
The result of the early aspirations of the ARK project—to make an open, web-based
system for data entry and dissemination—is a platform that continues to evolve, now over a
decade after its initial creation. Yet ARK is also a system conceived before born-digital data
recording became increasingly common practice with the widespread accessibility of tablets. The
modification of the existing code for handheld devices, therefore, is an ongoing challenge for the
core ARK development team. In a nutshell, the team must assess how ARK can—using limited
resources and development time and causing minimal upgrade disruption for existing projects—
be adapted to allow for tablet recording.
To understand the most likely trajectory of future advances requires a consideration of
three characteristics common to those projects most invested in ARK, and therefore most willing
to contribute time or funding to its further expansion. First, the majority of projects relying on
ARK as part of their on-site practices are not making an active push toward a paperless
archaeology. Most projects instead implement a hybrid recording practice of traditional paper
records and hand-drawn plans, later digitized on laptops in the site hut or laboratory, with digital
photography and born-digital registers of basic record metadata entered on tablets. It is important
328
to remember in any discussion of tablet recording that many national or state guidelines still
recommend paper archives for written, photographic, or drawn records for both research- and
commercially-driven archaeological work (see also Spigelman et al., this volume). Furthermore,
local organizations accepting digital-only data for archiving purposes may lack the robust
infrastructure provided by centralized groups dedicated to creating stable digital resources—such
as the Digital Archaeological Record (tDAR) in the United States, or the United Kingdom’s
Archaeology Data Service (ADS). Projects should thus consider not only whether to export their
data into plaintext, Rich Site Summary (RSS), or Comma Separated Values (CSV) formats, but
also whether any of these digital formats can be sustainably archived.
Second, any changes to the ARK code to enable tablet use should respect existing and
legacy projects, maintaining the data structure that has always been central to the success of the
ARK system. The need for all new functionality to be abstract enough to work in many different
contexts can make changes to the codebase more time-consuming than would be the case in a
bespoke, single-site system. New features also require a degree of backwards compatibility with
older releases, or a suite of upgrade tools for existing projects—expansive and expensive
developments that are difficult to fund within individual project budgets. A solution to adapt
ARK for mobile recording that doesn’t require extensive changes to the existing system is
preferred.
Finally, many ARK projects currently in the field take advantage of either an established,
site-wide local wireless network, or reliable 3G access, to simultaneously enter data both on
laptops in the laboratory and on tablets in the trenches using only a standard web browser. As
such, there has been no real impetus for development of a stand-alone ARK application for
tablets to facilitate data collection in offline environments, nor a need to integrate existing
329
(largely proprietary) systems with data storage and syncing functionality into ARK’s open source
workflow. A desire to make data available as soon as possible from the field—to specialists, and
to the general public—has often been behind many projects’ choice to use ARK. These projects
already have the infrastructure needed to run ‘online’, and are unlikely to return to a model
where data publishing and dissemination occurs only when fieldwork has been completed, or
requires an additional step to convert from proprietary data formats used during field collection
to open online systems for final archiving.
Some lessons from the trenches
So where, then, does this leave the potential exportation of ARK’s browser-based
recording to mobile devices? ARK’s primary use for paper/digital hybrid recording, desire for
flexibility with minimal PHP coding, and goals of concurrent data entry and dissemination, have
thus far suppressed any great desire by the ARK user community for the development of a new,
stand-alone mobile application. The easiest and most cost-effective solution to-date has, rather,
been the modification of the HTML styling of ARK’s interface, using custom CSS, to allow for
concurrent tablet-, phone-, laptop-, or desktop-based data entry and viewing.
In a web-based system such as ARK, a combination of changes to CSS and projectspecific
configuration files can display the same data in highly different ways, while also
requiring less intensive programming knowledge than modifying the existing codebase or
creating new functionality. Creating a new theme or skin to change the display of data for
various devices on-the-fly can in fact meet the needs of many fieldwork sites, does not require
any additional software downloads beyond the web browser already included on mobile
330
equipment, and respects the existing data structure and stated development goals of the ARK
system more generally.
This discussion will now turn to three types of project relying on custom CSS for ARK,
representing the different project needs of commercial archaeology, academic research, and
community archaeology.
Commercial archaeology
A first example of the use of ARK for on-site tablet recording comes from the UK’s
commercial sector, at the site of 100 Minories in London’s East End.3 Excavations undertaken by
L – P : Archaeology over the course of a year at the site—less than 500m from the Tower of
London and the Thames River—recorded deposits up to 8 m in depth, and materials ranging in
period from the defensive circuit of the Roman city, to Medieval and Tudor housing, to a large
18th century Georgian development (“The 100 Minories Site” 2014). Fieldwork at the site was
completed in advance of the construction of a new luxury hotel and funded by the developer,
Grange Hotels. In addition to the full excavation of existing deposits the site team completed a
series of associated outreach activities, including a symposium of research talks by members of
the project team, a number of pop-up museums displaying the latest recorded finds, and the
online dissemination of live excavation data using ARK (“100 Minories Pop Up Museum” 2015;
“The 100 Symposium” 2015).
The use of the ARK system for such a commercial enterprise within London comes as no
great surprise, considering the British origins of ARK and its London-based development team.
L – P : Archaeology had previously used ARK for a similar combination of developer-funded
3 http://100minories.lparchaeology.com
331
archaeology and public engagement, at another East London site on nearby Prescot Street (Hunt
et al. 2008; Morgan and Eve 2012; “Prescot Street” 2014). Fieldwork at Prescot Street was
completed before the release of an affordable tablet robust enough to survive the archaeological
trenches, and so mobile recording was not part of the project’s digital strategy. However, Prescot
Street’s combination of a strong web presence linking contributions from individual field staff to
live archaeological data—facilitated by ARK’s web-based functionality—served as a template
informing the work at 100 Minories.
Excavations at 100 Minories were completed under the guidance of the Greater London
Archaeological Advisory Service at Historic England, and were thus subject to the archival
requirements of all British archaeological practice (for an example of similar legal restrictions in
a North American context see Spigelman et al., this volume). These dictate the need for a written
paper record on standardized recording sheets, as well as bracketed photographs of individual
contexts, and drawn plans of the same on archival quality gridded drafting film, all according to
the standards outlined in the site recording manual of the Museum of London (Spence 1993).
Tablet data entry was still possible for those items not restricted by Museum of London
standards, such as the registering of new context, photo, or small find numbers at the trench. The
100 Minories site’s central London location meant no local network or server was needed.
Tablets on site were able to upload and access ARK data held in a remote location over a 3G
wireless network—even at depths over 2m below modern street level—using standard mobile
broadband data provisions. The system’s data entry functionality was simplified and streamlined
using a custom mobile CSS, the new ‘skin’ limiting the more complex data entry or spatial tools
but allowing for quick and easy creation of new context, find, or photo records (compare Figures
4, 5).
332
The ARK system was also used to view context records and finds data from an earlier
2012 archaeological evaluation of the site. These older data, accessed on tablets in the field by
excavators, assisted the ongoing processes of excavation and interpretation, and introduced an
aspect of reflexive practice not often attempted within a commercial context (Howard 2013).
Specialists working on the cleaning and consolidation of finds, a process handled off-site by
Museum of London Archaeology, were able to view the latest excavated materials as they came
out of the ground, connecting traditionally segregated excavation and post-excavation
workflows.
The work at 100 Minories is but one example of a hybrid paper/digital system within the
context of developer-funded work (see also Gordon et al., this volume, for a research-driven
example). This hybrid approach increases the efficiency of site recording practices—taking
advantage of some of the basic benefits of a paperless system (see Wallrodt, this volume)—but
still maintaining the archival standards required of sound commercial practice in a British
context.
Academic research
Research projects have been, in many ways, the early drivers of ARK development.
ARK’s flexible parameters were designed to suit its implementation in the highly varied
circumstances of international research. Much of the current codebase was developed to meet the
needs of disparate early adopters such as the Institute of Classical Archaeology at the National
Preserve of Tauric Chersonesos (Rabinowitz, et al. 2007)4, and the joint excavations of the
University of Pennsylvania and the British School at Rome at the imperial Roman site of Villa
4 http://www.utexas.edu/cola/ica/projects/chersonesos/introduction.php
333
Magna (Dufton and Fenwick 2012).5 The freedom often afforded to academic researchers to
experiment with new methodologies or techniques is well suited to exploring novel ways to think
about data creation, use, and dissemination. It is somewhat surprising, then, that such projects
have been less instrumental in adapting ARK’s existing functionality for use with mobile
technologies (for a notable exception see Opitz et al. forthcoming). Why are research projects
already using the system not making a greater push for a paperless ARK?
There are a few reasons for this seeming discrepancy. Academic fieldwork is often
planned and initiated with a specific time period or funding cycle in mind; the two projects listed
above, for example, have moved on to a publication phase where tablet/ARK interoperability is
less of a concern than tracking the evolution and use of project data (Esteva et al. 2010; Trelogan
et al. 2013). Other projects currently in the field are content with a workflow of on-site paper
recording and daily data-entry off-site, either due to a methodological loyalty to the perceived
benefits of the paper record, or because experimenting with new digital data techniques is—quite
understandably—not part of the research agenda.
A more significant barrier, however, is the absence of a stand-alone, offline, data-syncing
alternative for ARK. ARK’s open source codebase makes it difficult to track all projects
currently using the system—at the time of writing, the latest version had been downloaded over
2300 times in the one year since its release—but a look at the distribution of some of the higherprofile
research projects using ARK shows a decidedly Mediterranean focus (Figure 6). Unlike
commercial excavations in the heart of London, rural sites in Sardinia, Tunisia, Turkey, or
Jordan still lack the reliable network connectivity needed for tablet-based data entry over mobile
broadband. Mediterranean fieldwork projects are content with data entry from paper records into
5 http://www.villa-magna.org
334
the ARK system, but demonstrate an unsurprising reluctance to rely solely on on-site, borndigital
recording when the possibility of establishing a site-wide wireless network, or the
reliability of 3G coverage, is so hard to guarantee (see for example the experiences of the
Athienou Archaeological Project, Gordon et al., this volume). This is particularly the case for
landscape survey projects covering a much wider study area—such as Brown University’s Petra
Archaeological Project—where regular 3G access to a remote server would be the only viable
option but network coverage is not yet sufficient for such an approach.6
Although individual devices can be configured to run a stand-alone system, there is at
present no method for syncing a series of disparate ARK data tables into a single database at the
end of a day’s fieldwork—a function not as important to commercial excavations at a single,
well-defined site, but essential for the use of tablets across multiple excavation areas or between
simultaneously active field survey teams, situations that characterize much academic research.
Attempts to integrate ARK with stand-alone, offline data capture systems such as Filemaker Pro
have so far resulted in unwieldy workflows lacking the efficiency benefits that draw projects to
paperless recording in the first place. Thus far, the combination of network concerns and other
priorities for existing research using ARK has resulted in a slow uptake of born-digital data
recording on many academic projects.
Public outreach
A final example from the realm of public or community archaeology provides further
insight into the use of ARK for mobile recording: the DigVentures social enterprise promoting
6 http://brown.edu/go/bupap
335
crowdfunded archaeological fieldwork.7 The DigVentures team started in 2012 with a summer
excavation season at the Bronze Age site of Flag Fen near Peterborough, UK. The project relied
on existing public interest in this well-known monument—and in archaeology more generally—
to fund the excavations, ultimately establishing a community of over 250 funders, many of
whom also participated directly in work on site (“Our Story” 2015).
In 2013, DigVentures fieldwork moved to the medieval site of Leiston Abbey, Suffolk
for a second season of crowdfunded and crowdsourced excavations. The Leiston Abbey project
also established the Digital Dig Team, an online website/ARK hybrid to provide live data from
the excavations at the moment of discovery. As with the 100 Minories example, a custom CSS
was created for ARK to streamline data entry using tablets on site, relying on existing 3G
network access to connect to a remote webserver. These largely stylistic changes to the ARK
system connected the archaeological data with broader web content, such as daily blog entries by
project participants, video updates, or news items.
Claims that this initiative should be seen as “the world’s first entirely paperless recording
system” are problematic (“Digital Dig Team” 2015; see Wallrodt 2011 and this volume for
earlier examples). Yet it does embody a very early attempt at combining paperless systems with
online dissemination tools to make, in effect, all data public data from the moment of initial
collection through analysis and interpretation. Although designed primarily as an incentive to
encourage donations to project funding, this approach also takes a valuable step towards a
greater integration between digital data and other aspects of the archaeological process, such as
documenting fieldwork practices, interpretation, and dissemination (Rabinowitz and Sedikova
2011).
7 http://digventures.com
336
The need to find effective, long-distance means of communicating archaeology has
recently been highlighted, not least since geographic, financial, or physical restrictions can
prohibit in-person involvement with archaeological sites or museums (Alcock et al. 2015). This
is particularly relevant for a project such as DigVentures that is designed for, and funded by, the
public. Web-based recording systems such as ARK provide an opportunity to connect field
practices and the excitement of discovery more directly to a population eager to participate,
directly or virtually, in the archaeological process.
Mobilizing ARK for a digital future
Advances in mobile technology within the last decade have drastically changed the way
archaeologists think about data collection. As a result, fieldwork projects now face a number of
choices with far-ranging implications: to embrace paperless recording, or maintain some degree
of traditional documentation; to develop a bespoke system, or adopt an existing archaeological
database; to use an open source platform, or licensed proprietary software; to prioritize data
dissemination and reuse, or efficiency of on-site workflows.
The examples outlined above, when understood within the context of ARK development,
provide some insight into the role of mobile recording using web-based systems, such as ARK,
in these wider debates. On the one hand, ARK’s ability to eliminate the gaps between data
collection and online dissemination has always been a major strength, and it is no surprise that
those projects best deploying the system with mobile technologies include a substantial publicfacing
component. On the other hand, research projects are proving more hesitant to rely on a
tablet system that can only function with local wireless or mobile broadband access, especially
given the lack of such connectivity in many fieldwork settings. Yet research projects are not
providing the funding for the majority of ARK development and, for better or worse, it seems
337
unlikely that a syncing, offline version of ARK will be produced in the coming years. A standalone,
paperless system is not a priority for the projects actively developing the ARK platform at
present, and existing software, such as Filemaker Pro, offers a less time-consuming alternative
for bespoke, offline mobile recording.
More generally, a shift to web-based site recording—on tablets or otherwise—also
requires a broader paradigm shift within academic practice, encouraging open data not only as an
afterthought to publication but as an active part of the fieldwork process. Advocates for the
current trend toward open data stress the potential strengths of such an approach: reduced
research costs, increased research quality, and better communication of archaeological findings
(Kansa and Kansa 2011; E. C. Kansa 2012). Open data initiatives have traditionally worked with
published or archival data sets, demonstrating the benefits of online publication for system
interoperability or Linked Open Data (LOD), text-mining, and data reuse (Atici et al. 2013;
Isaksen et al. 2010; S. W. Kansa et al. 2014). Projects have been slower to adopt these principles
for ongoing fieldwork, showing less willingness to sacrifice on-site efficiency for more unwieldy
interfaces offering future data interoperability, nor to provide open access to data prior to its reexamination,
possible correction, and traditional publication—a process which often takes years.
Academic systems of appointment and promotion further contribute to an unwillingness to go
digital by often placing a higher value on traditional print publications than collaborative, open,
and online initiatives (see Kansa, this volume). An uptake in web-based data creation on-site is
unlikely unless accompanied by a change in the distinction we make between live and archived
data, and a continued effort to make open data systems more accessible to users with all degrees
of technical competence.
338
This negative outlook does not mean that there is no potential for mobile, born-digital
data collection using ARK. Longstanding excavation projects often have the resources necessary
to establish local wireless infrastructure, and in some cases have begun using ARK for paperless
data capture (Opitz et al. forthcoming). Furthermore, the latest figures provided by the
International Telecommunication Union—the United Nations’ specialized agency for
information and communication technologies—show global access to 3G networks increased
from 45% to 69% coverage from 2007 to 2015 (“ICT Facts and Figures: The World in 2015”
2015). Industry projections suggest up to 85% 3G network coverage worldwide by 2017
(“Ericsson Mobility Report” 2012). High-speed Long-term Evolution (LTE), often referred to as
4G LTE, has shown a similar expansion in coverage over the last five years; a 2015 survey of 68
countries demonstrated that in 53 (or 78%) users had access to LTE signals for over 50% of their
total time connected to mobile networks (“The State of LTE” 2015). Of course not all projects
will be able to count on this coverage, particularly those working in highland or rural remote
locations. It is reasonable to suggest, however, that reliable 3G/LTE coverage on archaeological
sites will only become a more realistic expectation in the coming years. Future ARK
development to streamline data entry on mobile devices is possible, and much can be
accomplished with simple changes to ARK’s CSS to create a responsive interface tailored to
effectively display and enter data both on computers in the lab, and on tablets or smartphones in
the trenches.
A significant strength of open source software is that there is no single answer to the
question of “where next?” Individual ARK projects will continue to follow their own trajectories,
based on individual project needs and research aims. This discussion presents only one
perspective on the future of ARK and mobile technologies, a future where simple CSS
339
customization takes advantage of the benefits of mobile, web-based data collection while
maintaining the goals of openness and flexibility which lie at the heart of ARK’s development
history.

3.4. The Development of the PaleoWay Digital Workflows in the Context of Archaeological
Consulting
Matthew Spigelman, Theodore Roberts, and Shawn Fehrenbach (PaleoWest Archaeology)
Introduction
In this paper we present the development of PaleoWay digital workflows and offer
insight into the development of digital archaeology within the private sector in hopes that our
solutions may serve as an exemplar and model for academic and non-academic projects alike.
PaleoWest Archaeology is a full service cultural resources consulting firm, with offices across
the United States. PaleoWest’s archaeological services include archaeological resource
assessments (ARAs), literature and site file searches (Phase 1A), reconnaissance and intensive
archaeological surveys (Phase 1B), preservation and treatment plans, programmatic agreements
(PAs), memoranda of agreements (MOAs), historic architectural documentation, site testing and
evaluations (Phase 2), full-scale excavation for data recovery and mitigation (Phase 3), and
construction monitoring. We offer surveys using the full suite of geophysical instruments
commonly used in archaeological surveys: Ground Penetrating Radar (GPR), Gradiometry,
Electromagnetic Induction (both Magnetic Susceptibility and Conductivity), and Resistivity.
PaleoWest leverages the latest positioning technologies such as real time kinetic (RTK)
geographic positioning system (GPS) and Robotic Survey Stations to collect subsurface imaging
surveys quickly with precise spatial positioning. We also employ low altitude aerial photography
for the creation of high resolution ortho-mosaics as well as digital elevation models (DEM). In
fact, PaleoWest is the only archaeological firm nationwide to hold a FAA 333 exemption permit
to collect UAV (drone) data commercially. Our goal is, more broadly, to create an approach to
347
archaeology focused on born digital data, built-in quality assurance and quality control,, and
providing clear and logical paths for turning field observations into client ready deliverables.
Our needs in developing the PaleoWay digital workflows demanded they be scalable,
customizable, and able to operate both with and without cellular connectivity. Scalability, which
for our purposes was the ability to field multiple crews working simultaneously, was important
because the size of our projects vary widely. A typical survey could be as small as a single plot
being developed for residential or commercial use, a few miles of pipeline being added to a
natural gas collection network, or as large as a hundred thousand acre military base or a several
hundred mile-long water distribution system. Customizability was important because our work is
variable and occurs across the 50 states and beyond. The goals for projects differ widely based
on client needs, and the project deliverables vary across states and between government
agencies. We therefore stress that the PaleoWay is a system of digital workflows (plural) because
the variety of our projects, geographic locations, and regulatory requirements make the
development of a single, one-size-fits-all, system impractical.
The great benefit of being a successful archaeology-only consulting firm is that we have
had a large number of projects through which to develop and refine the PaleoWay digital
workflows. Since our founding in 2006 we have successfully completed over 1100 cultural
resource investigations. In this paper we present an overview of the process of developing the
PaleoWay digital workflows, provide several projects as case studies to highlight the strengths of
a digital data system, and reflect on how the position of the data and mapping specialist has
become a key position in the firm. First, however, since we are the only contributors to the
volume speaking from a cultural resources management perspective, we provide a brief overview
of the environment in which archaeological consulting is practiced within the United States. This
348
context informs all of the decisions we have made, and continue to make, in developing and
implementing the PaleoWay digital workflows.
Archaeological Consulting
As archaeological consultants our job is to help local, state, federal, and private entities
manage the cultural resources under their care. The largest of these entities are federal
organizations and agencies, such as the Bureau of Reclamation (BOR), the U.S. Forest Service
(USFS), the National Park Service (NPS), Department of Defense (DoD), Army Corps of
Engineers (USACE), and the Bureau of Land Management (BLM), each responsible for millions
of acres of land and the management of millions of archaeological sites and other historic
properties on public land. The smallest entities are developers or other landowners embarking on
a project that requires a federal, state, or municipal permit and therefore triggers historic review.
The cultural resources we are hired to record and evaluate include, but are not limited to,
archaeological sites. We are also charged with identifying other historic features on the
landscape, such as petroglyphs, irrigation canals, roads, fences, and historic buildings. Also
falling within the category are less tangible cultural resources, such as ethnographic knowledge,
natural resources of cultural significance, and traditional cultural properties (TCPs) where
important activities continue to take place.
Much of this work is federally mandated by section 106 of the National Historic
Preservation Act (NHPA), but also other parallel pieces of legislation (King 2013: Figure 1.1).
This work is mandated at the federal level, but regulated at the state level. Each state maintains a
State Historic Preservation Office (SHPO), which is responsible, among other things, for
reviewing work done to satisfy the section 106 legislation, for maintaining a statewide inventory
349
of historic properties, and for nominating historic properties to the National Register of Historic
Places (NRHP). Historic properties are typically defined as anything greater than 50 years of age
and are considered significant for what they can tell us about our collective history, both before
and after the founding of the Unites States of America (for an overview of the relevant
legislation, see King 2013:1–54).
This work typically proceeds along a three-step process of 1. identifying cultural
resources, 2. evaluation of their eligibility for inclusion on the NRHP, and 3. if construction or
other events will have a negative impact on those resources, proposing mechanisms to avoid or
mitigate those impacts (King 2013:55–82). In practical terms, this process results in our being
hired to survey archaeologically the proposed project areas (hundreds or thousands of acres),
identify archaeological sites, and assess the impacts of any proposed activities on those sites and
other identified historic properties. When negative impacts to a significant cultural resource are
unavoidable, one method of mitigating those impacts is to research and record the cultural
resource in order to gather information of importance to human and American history. Again, in
practical terms, mitigation often results in extensive site excavation, the purpose of which is to
gather data from an archaeological site or other cultural resource before it will be destroyed or
made inaccessible by construction, mining, or other activities. For this reason these projects are
typically referred to as “data recovery” excavations.
As archaeological consultants, each project we complete results in a set of deliverables
that are reviewed by SHPO. For surface (pedestrian) surveys these deliverables will typically
include a report on the work conducted and an inventory form for each archaeological site or
other historic property identified. The report allows SHPO to evaluate if the appropriate federal
requirements have been met, while the inventory forms contain all of the information necessary
350
for the SHPO to update their statewide inventory of historic places. For data recovery
excavations the deliverables also include the thousands or millions of artifacts and other material
recovered in the work, which must be catalogued and processed for long-term storage. Our job
is, therefore, to conduct archaeological research in the service of managing the historic resources
of our nation. Effective and efficient work is central to this process, both to meet the
management needs of the resource and our own needs as a private company working on
competitively priced projects with low profit margins and little tolerance of inefficiencies.
The PaleoWay Digital Workflows
The goals for the PaleoWay digital workflows are twofold: to produce higher quality data
and to do so in a more efficient and cost effective manner. The creation of all digital workflows
requires the reimagining of how we prepare for fieldwork, conduct fieldwork, collect data,
analyze data, and produce deliverables for our clients. We developed the PaleoWay as a suite of
tools that removes paper maps, paper records, and paper forms, replacing them with digital
devices and digital data.
The first phase of developing the PaleoWay digital workflows was one of research and
experimentation, as new hardware (most notably the first and second generation iPads) and a
host of new applications became available. The challenge in this phase was to create a culture
shift within our organization and industry similar to paradigm shifts occurring in academic
archaeology (see Dufton, Gordon et al., and Wallrodt, this volume). This culture shift included
encouraging and empoweringproject managers, crew chiefs, and field technicians to find new
way to conduct fieldwork and produce deliverables. In doing so, we were forced to confront
deeply engrained practices, many of which dated back to the early years of cultural resource
351
management (CRM) in the 1970s and 1980s. These paper-based workflows were well honed, but
also increasingly inefficient due to the need to digitize eventually all data for final computerized
report production, map drawing, and production of client specified deliverables (see Caraher, this
volume).
The second phase was product development. In conjunction with a period of rapid growth
in the company, many of the workflows that had been established in the first phase using a host
of standalone applications were consolidated into a single centralized database. While many
options were explored, the solution chosen was to build a customized database within the
FileMaker Pro program. This choice of an established software package has proven successful,
allowing us to focus on the development and improvement of the database itself (and to do more
archaeology), without having to worry about the fundamental software reengineering associated
with each and every hardware and operating system release (see Motz, Wallrodt, Fee, and
FAIMS, this volume for perspectives on proprietary vs. off the shelf solutions). The resulting
software is now utilized in all of our projects, ranging from survey, through testing, to large-scale
excavation.
The Old Way
The old way of conducting archaeological consulting was developed as a paper-based
workflow, with computers and other digital devices uncomfortably inserted after the fact
(Eiteljorg 2007). Field data was recorded on paper, in a manner that had changed little since the
development of CRM in the 1970s. Deliverables were also paper based, with printed reports and
site forms filled out by hand or using a typewriter. Archaeological consulting companies
introduced computers into this workflow as a means to organize data as it returned from the field
352
and produce better looking maps, but as of 2010 computers had not meaningfully changed how
fieldwork was conducted. Similarly, multi-thousand-dollar GPS units (most made by Trimble™)
and high quality digital cameras had been introduced into fieldwork, but both were inserted into
the traditional methodology (see Ellis, this volume). The crew chief, who previously recorded
site and isolated artifact locations by hand on a paper map, now recorded those locations using
the GPS unit. This initial insertion of technology only served to reinforce the hierarchical nature
of field crews, creating greater distance (and at times animosity) between field crews and their
crew chiefs and project managers.
As of 2010, computers were allowing archaeological consultants to organize better data,
render high qualitymaps, and record more accurate spatial data. These benefits, however, came at
a cost. Fieldwork now required several pieces of expensive equipment, while still producing only
paper records and hand-drawn maps as a result. Upon leaving the field, paper records now
needed to be typed into the computer before data could be tabulated and included in reports.
Hand-drawn maps needed to be scanned and loaded into Adobe Illustrator™ or AutoCAD,
where they were then re-drawn all over again. Higher quality data was being collected and higher
quality deliverables were being produced, but there were, as of yet, only efficiency losses and no
efficiency gains.
The Development of Digital Workflows for Pedestrian Survey and Site Recording (2010–
2011)
The development of the PaleoWay digital workflows took place in 2010 and 2011, a
period of tough economic times. Commercial property development had ground to a halt, taking
away a formerly lucrative source of archaeological contracts. The work that remained was
353
largely generated by government agencies, such as the USFS, BLM, BOR, and various branches
of the Military. These projects were publicly advertised and highly competitive, susceptible to
low bids by those willing to cut corners. The goal of PaleoWest was therefore to leverage
technology not just in an attempt to maintain and improve the quality of the data coming out of
the field, but also to increase efficiency and lower costs in this competitive environment.
PaleoWest bid aggressively on contracts during this time and won work throughout the
American Southwest and West, on large projects in Arizona, New Mexico, Utah, Wyoming, and
Colorado. These projects were largely extensive surveys in archaeologically rich landscapes.
Projects were usually non-collect surveys, meaning that all artifact analysis was conducted in the
field, and that only photographs, records, and maps returned to the lab. The deliverables for these
projects were a final report and the completion of Agency-specific inventory forms, typically
accompanied by appropriate pictures and maps. While core staff members (Project Manager,
Field Director, and some Crew Chiefs) remained fairly consistent from project to project, field
crews were typically hired on a per-project basis. Most projects covered 500 to 1000 acres, had
crews of 4 to 12 people, and lasted from 10 days to a month. This was an ideal environment to
test and innovate new solutions, allowing for near continuous iterative development.
The economic downturn of 2010 and 2011 ushered in a period of rapid technological
development and lowering costs of hardware and software (see Ellis, Poehler, Wallrodt, and
Motz, this volume). While the launch of the iPad was an important piece of this process, so too
were the appearance of lower cost and higher quality GPS units and digital cameras. During this
beta testing period a concerted effort was made to engage all members of the field crew to adopt
the technologies and embrace the changes in the personnel dynamic associated with going digital
354
in all stages of the archaeological process. The goal was to give everyone access to the
technology and to empower everyone to identify problems, find solutions, and spread these
results throughout the field crews and throughout the company. This was an exciting time as new
technology was adopted in real time under constant pressure to bring projects in under budget
and on schedule.
The main task in going digital was to convince everyone from the top down, and the
bottom up, to buy into the process. Previously, when new technology had been introduced it had
been jealously guarded by the crew chief (see Sayre, this volume) and this had the unfortunate
consequence of both creating hierarchy and resentment, but also of introducing inefficiency, as
able crew members sat idle while the crew chief recorded coordinates, drew maps, filled out
paperwork, or took pictures. Our goal, instead, was to put technology in each crew member’s
hands, giving everyone a job to do in parallel to one another, thereby increasing efficiency in the
process. This approach was directed at all stages of the archaeological process, replacing the
traditional archaeological tool kit with a digital one.
The system that developed to further this approach was a suite of technology and
software (see Motz and Wallrodt, this volume). A crew of four now went to the field with four
Garmin hand held GPS units, three iPads, and one Trimble high precision GPS unit. Each crew
member had their own GPS, pre-programed with their designated survey lines. Giving everyone
a GPS made field walking more efficient and also streamlined the process of recording isolated
artifact occurrences. Crew members, upon spotting an isolated artifact, could now quickly and
efficiently make their identification, note the coordinates, and call out the information to be
recorded. Paper site recording forms were now digitized into fillable pdfs, pre-loaded with
applicable information and ready for digital data collection. Because these were the same forms
355
that would later be printed and submitted to the client, fieldwork was directly producing the
project deliverables, thereby removing all of the digitization and typing that used to be required.
Similarly, site plan maps were produced directly on the iPad, using off the shelf vector mapping
programs. By pre-loading a template with an appropriate symbology, field vector mapping now
increased efficiency by removing the need for post-field digitization of paper maps, and it also
produced higher quality data by standardizing symbology, layout, and other aspects of the map
between team members and across field crews (see Motz, Ellis, and Bria, this volume).
With the introduction of the second generation iPad it became possible to bring site and
artifact photography into the fully digital realm as well. Whereas previously it was necessary to
juggle a camera, a GPS unit, and a paper photo log, now these three lines of data were brought
together within a single device (see Gordon et al., Fee, Ellis, this volume). In this first phase of
development the solution was an off-the-shelf application that digitally marked photographs with
all of the necessary information: location, direction, time, and space for a note, thereby removing
the need for a separate photo log. This too resulted in higher quality data as it eliminated the all
too common occurrence of the photo log and the camera falling out of synch, ensuring that the
location, direction, and subject of every photo was always recorded.
Lastly, going digital allowed crews to take whole libraries of information with them to
the field, and to organize that information in a usable manner. Having digital libraries in the field
pays dividends both in recording newly discovered artifacts and sites and in re-visiting and rerecording
previously identified cultural resources. Having identification libraries at hand is key
for maximizing productivity among field crews, members of which might be working one week
in Utah and the next week in Arizona; they might find a prehistoric lithic scatter in the morning
and an early 20th-century campsite in the afternoon. When revisiting sites the digital library for
356
that site could be easily consulted, forms could be pre-fill with known information and the old
site map consulted to see if subsequent changes required the drawing of a new one.
This research and development phase continued through 2010 and 2011 and reached a
mature state with the capabilities of the second generation iPads with their onboard cameras.
Using off-the-shelf hardware and applications we achieved notable productivity gains, both in
the field and in the time it took to go from field to deliverables. Utilizing all team members, each
with their own role in the process, each inputting data to their own device, the recording of a
lithic scatter went from over an hour in the paper era to under 15 minutes using the PaleoWay
digital workflow. Recording an isolated artifact went from 10 minutes to less than a minute.
Major productivity gains and quality control was gained by removing digitization entirely from
the process. The move from field records to deliverables went from two weeks to two days. This
period of research and development required overcoming technological changes, but more
importantly it required a cultural shift as people learned to trust the technology and see the
benefits of collecting digital data in the field (see Ellis and Poehler, this volume).
The Development of an Integrated Database Solution (2011–2012)
We transitioned from a phase of research and development during 2010 and 2011 to the
creation of an integrated database solution in 2011 and 2012. This transition occurred when
PaleoWest was awarded the cultural resource management component of the Navajo-Gallup
Water Supply Project (NGWSP). The NGWSP is a $1.3 billion undertaking, consisting of a 280-
mile-long system of pipelines and pumping stations that will bring water to parts of the Navajo
Nation that are currently without a clean and sustainable water supply. This cultural resource
management contract was, at the time, the largest federally funded cultural resource management
357
contract ever awarded in the United States. The NGWSP is a complex and demanding project,
requiring a digital data solution that could accommodate archaeological survey, testing, and
excavation, as well as ethnographic research (Potter, Gilpin, and Chuipka 2013). The cultural
resource portion of the project is also projected to take at least a decade to complete, and
construction estimated to extend through 2024. This complex project with an extended timeline
required the creation of a robust system that could handle all of the diverse project needs, but
also a flexible system that could be adapted and altered over time. This solution was developed
in the context of the NGWSP (cf. Chuipka 2015), and in the years since has been implemented
by PaleoWest on that project and other survey and excavations projects, both large and small.
The PaleoWay digital workflows designed and implemented for the NGWSP are based
around a collection of nested modules in a FileMaker Pro database (See also Wallrodt, Motz, and
Gordon et al., this volume). These modules create guided pathways for collecting data for
survey, excavation, and other regularized tasks. While we explored many different software
options, including customized app development and other solutions, the decision to utilize
commercial database software was made to avoid the time and expense of re-engineering
software for each hardware or operating system upgrade. We also needed the ability to work
without cellular connectivity, as much of the NGWSP runs through rural areas. However, we
also needed the ability to integrate and coordinate data in real time, such as on large and complex
excavation sites.
NRHP Eligibility Evaluations at Fort Irwin, CA
A major project for testing the PaleoWay as implemented in the FileMaker Pro database
was a large survey project at Fort Irwin, California. We were hired to evaluate 731 previously
358
identified archaeological sites, located within a 642,000 acre active military facility (Roberts et
al. 2012, 2013). This project was ideally suited to a digital approach: the archaeological sites
were previously identified, so the task was to re-locate, re-record, and evaluate their eligibility
for the NRHP in the most efficient manner possible. A digital workflow utilizing a four-person
team, with three iPads and Trimble GPS unit, was devised. One team member surveyed the site,
tallying artifacts, marked artifact positions and the site boundaries with survey flags, and
recorded coordinates with the Trimble GPS. The remaining team members all used iPads. One
took photos and completed the integrated photo log, a second filled out the site form, and the
third used a vector mapping application to draw a site map. The vector map template was
populated with current project information thus eliminating the need for redundant and repetitive
efforts. This workflow engaged all team members in the site recording process, with data
integrated after the fact through the centralized database. A digital approach also allowed for
unprecedented flexibility at Fort Irwin, as necessitated by the demands of working in an active
military facility. Field crews were empowered to shift to new sites or new areas of the base
seamlessly, as all of their background research and all necessary field forms and maps were
carried with them digitally at all times.
Large Scale Excavation at the Ironwood Village Site, AZ
The PaleoWay digital workflows have proven particularly successful at managing the
large volumes of physical and digital data produced by large-scale excavation projects. In 2013
and 2014 PaleoWest was hired to excavate the Ironwood Village site, a ca. seven acre (2.8
hectare) Hohokam settlement, located midway between Phoenix and Tucson, Arizona (Bostwick,
Mitchell, and North 2015). The project was the first all-digital large-scale excavation in the
359
nation. Excavation was conducted on an extremely tight schedule, with the goal of gaining
clearance for the construction of the Marana Center commercial development in advance of the
2015 holiday shopping season. The goals of the project were therefore efficient and high quality
excavation, followed quickly thereafter by reporting and clearance for the project to proceed.
These demands required that the excavation, data analysis, and initial technical report assembly
phases be conducted coincident with one another. The project was successful, with the technical
report submitted the day after fieldwork was complete, due to the capabilities of the PaleoWay
digital data workflows. Two aspects were particularly important: access to a centralized database
from both the field and the lab, and the use of artifact and sample tracking using Quick Response
(QR) codes.
The excavation of the Ironwood Village site utilized a centralized database hosted in the
company’s Phoenix headquarters and accessed in the field over cellular networks in real time.
This allowed full access to all field records, photographs, and other information by all members
of the project team as soon as they were created. Most importantly, records were being
continuously checked and cleaned by a full time data manager. The data manager was
responsible for maintaining standardization and identifying potential issues that could be
addressed while features, contexts, and artifacts were still fresh in excavators’ memories and
crews were still in the field. Over 500 distinct archaeological features were excavated at the site,
including a ball court and numerous houses, roasting pits, and burials. Each feature was digitally
mapped in the field using a vector drawing app and coordinated taken off of the site grid. These
maps were revised in the lab using control points taken with a total station.
A large and diverse artifact assemblage was recovered from the Ironwood Village site,
and samples for flotation, pollen, botanical, and C14 analysis were also collected. In total nearly
360
4,000 bags of artifacts were recovered in the field and transferred to the lab for analysis. Each
artifact bag was tracked throughout this journey using a unique QR code (see also Serrano, this
volume). QR codes represent a distinct advance over barcode systems (e.g. McPherron and
Dibble 2002), as QR codes require no special equipment to produce or read. They are printed on
regular paper (or waterproof Tyvek) and then attached or included in sample bags in the field.
They can be read quickly and accurately using the camera on any smartphone or tablet. The use
of QR codes within a centralized database also allows for efficient custody tracking.
The tracking of artifacts and other samples as they leave the site, enter the lab, and move
from conservation, through analysis, to storage is critical to the success of a large project.
Custody tracking is, however, mandatory and essential when dealing with human remains.
Human remains and associated funerary objects were discovered as both distinct cemeteries and
isolated occurrences at the Ironwood Village site. The methods for excavating, housing, and
repatriation of these remains were determined in consultation with the Tohono O’odham Nation
and described in the project’s Burial Agreement. A member of the Tohono O’odham Nation was
onsite during fieldwork and participated in the excavation of many burial features. A core part of
the burial agreement is an establishment of trust between PaleoWest and the Tohono O’odham
Nation that the material recovered from burial features will be handled and housed respectfully at
all times. The use of a centralized custody tracking system was an essential part of this process.
Within the framework of appropriate treatment and transport of these highly significant and
sensitive items (outlined in the Burial Agreement), the chain of custody could be demonstrated
immediately- wherever and whenever the need for access to this information arose.
The PaleoWay digital workflows are particularly useful in the context of large-scale data
recovery excavations, such as the Ironwood Village site. The use of a centralized system allows
361
for the real time coordination and control over the digital data and physical artifacts that was
impossible using paper records alone. Key to these efforts is not just the construction of a
functional and efficient database system, it is also the assignment of personnel to the
maintenance and use of such a system, thereby establishing the role of the data manager within
the archaeological consulting firm.
The Data Manager
The development, implementation, and maintenance of the PaleoWay digital data
workflows positions the data manager (and mapping specialist) as a core member of any project
team. In the paper era, data collection was the responsibility of the Field Director, data
processing the responsibility of the Lab Director, and the production of the project deliverables
was the responsibility of the Principal Investigator. The data manager and mapping specialist
now plays key roles at each stage of a project’s lifecycle. In preparation for fieldwork they
conduct site file searches of already identified sites within the project area, compile these data in
ArcGIS, and output geoPDFs for use in the field. They are also responsible for preparing a blank
database for fieldwork, customizing fields, dropdown menus, and other aspects as necessary for
the specific project. During large and complex projects they are responsible for database
integration and quality control, often allowing problems to be identified and corrected while the
team is still in the field. After fieldwork is complete they are responsible for moving data out of
the database in which it was collected and into the various formats of the project deliverables.
These typically include the project report, site forms, and associated maps and photographs. It is
becoming increasingly common for SHPOs to require that spatial data be delivered as shapefiles,
requiring that site coordinates and other information be brought back into ArcGIS for export. All
362
of this is to say that while we have created digital data workflows, removing paper from the
system, we have not removed people from the system.
Conclusions
Our goal in developing the PaleoWay digital data workflows was to produce higher
quality data and to do so in a more efficient and cost effective manner. We have found that
collecting digital data in the field produces higher quality data due to the quality assurance and
quality control (QA/QC) mechanisms built into the process. As a result, this QA/QC process
improves archaeological interpretation by eliminating redundant or bad data. For database input
we can limit choices to a predefined set of values, thereby standardizing recording across
personnel and field crews, we can also create required fields, thereby ensuring that all data is
collected before leaving a given archaeological site. Vector mapping in the field also produces a
higher quality work product, as map symbology, scale, and conventions are all built into the preloaded
template. Perhaps the greatest efficiency gains, however, have been achieved by
removing the need to digitize large volumes of field forms, decipher the handwriting of multiple
field crew members and reconstructing missing data after the fact. We now move directly from
fieldwork to the production of deliverables. This closer linking of fieldwork and reporting allows
the synthesis of results to occur much closer to when the work actually took place, again
resulting in a high quality product and efficiency gains.
The irony of our current efforts is that while our data workflows are entirely digital, our
project deliverables remain largely paper based. State and federal laws are built around the
archival stability and permanence of paper records. SHPOs are just beginning to bring site
databases online and integrated with spatial data. We expect, therefore, that the shift from paper
363
to digital deliverables is at hand and we will soon be accompanying our digital spatial data
deliverables with digital databases of our results as well. Our PaleoWay digital workflows
position us well to adapt to these changes.
The development of the PaleoWay digital workflows benefited in its early phases from
our high project throughput, allowing many new technologies to be employed. The successful
technologies were developed and refined, while the onerous or inefficient were culled. The
development of a more effective and efficient paperless system was particularly advantageous as
we operate in many areas of the country that are densely populated with a rich diversity of
archaeological sites, thereby compounding even small efficiency gains into sizeable benefits.
And more recently it has benefited from our participation in large and complex projects, which
provided the time and budget to build more integrated and robust systems and capabilities. We
have found, however, that it is not possible or desirable to produce a single application or
database that contains all the necessary functionality our system requires. Vector mapping
remains most efficiently done in an external application and we continue to utilize handheld GPS
units and total stations running their own proprietary software. Recreation grade GPS units
remain the most rugged and economical option for providing surveyors with their routes through
the project area, while we turn to professional grade GPS units for recording tasks requiring
greater accuracy.
In this paper we have reviewed the development PaleoWay digital workflows and
highlighted several projects in which they have proven particularly effective. The NGWSP
highlights the ability of the PaleoWay digital workflows to utilize a centralized database to
integrate a highly varied set of project tasks, which are simultaneously taking place over
hundreds of miles of archaeologically rich land, and which will extend over more than a decade
364
of work. The re-recording and evaluation of previously identified archaeological sites at Fort
Irwin highlights the ability of digital data workflows to efficiently collect data while maintaining
high quality over time. Efficiency was produced by designing a workflow in which all team
members were actively engaged in site recording for the duration of the time spent at each site.
Lastly, the Marana Data Recovery Project (the Ironwood Village Site) was a large-scale
excavation of a Hohokam Village site conducted in advance of commercial development. This
project was executed on an extremely tight timeline and highlights the ability of the PaleoWay
digital workflows to create an active flow of information between the field and the lab.

4.1. Slow Archaeology: Technology, Efficiency, and Archaeological Work
William Caraher, University of North Dakota
Slow archaeology is a term that I coined to describe a practical critique of recent trends in
archaeology that emphasize digital tools as a way to improve efficiency in field work. Drawing
on recent academic and popular criticism of the increasing speed of capital, technology, and
daily life, slow archaeology involves recognizing that the use of technology to increase the pace
of archaeological work has roots both in the long-term development of industrial practices within
archaeology as a discipline and in scientific practices which alternately disclose and occlude
elements of knowledge production. This chapter appeals to Bruno Latour’s concept of “black
boxing” to understand how certain efficiencies achieved by digital tools create, reinforce, or
occlude archaeological practice and methodology. These black boxes hide certain processes or
maneuvers either owing to their complexity, their routine character, or their location outside of
the expertise of disciplinary work. The chapter explores certain aspects of digital innovation in
archaeological field practices and methodology and argues that the discipline would benefit from
adapting some of the critiques offered by proponents of the slow movement.
My idea for a slow archaeology has roots in the scholarly criticism of speed that are most
frequently associated with larger critiques of modern capitalism. For David Harvey, for example,
the speed of capital in contemporary society has outstripped human conceptions of time and
space, and has led to “the annihilation of space by time” through “time-space compression”
(Harvey 1990). Marc Augé (1995) recognized the speed of the contemporary world as a
significant contributor to the serialized production of non-places which exchange the
2
distinguishing characteristic of place for the efficiency of legibility. Paul Virilio, in his concept
of dromology, has stressed the transformative aspects of speed and perhaps more importantly
acceleration in modern society. Beginning with the industrial revolution the drive to make things
and processes faster, more efficient, and more connected has become an end unto itself. For
Virilio, speed produces a distinct realm of experience and knowledge (Virilio 1995; James 2007,
31-32). A traveler in a car both experiences and produces the landscape in a way that is distinct
from the experience of the landscape on foot (Virilio 2001). Hartmut Rosa (2013), following
Virilio and Augé, argues that the rapidly shrinking present has created a kind of fluid, unstable,
and unfamiliar world.
The popular media has explored a critique of speed through concepts like “slow food,” which
celebrates the deliberate preparation of locally sourced food stuff as a challenge to the
homogenized and generic fast food experience. Initially championed by the Italian activist Carlo
Petrini (2003), the idea of slow offers a way to summarize a wide range of criticism of the speed
of contemporary life. Carl Honoré (2004) and others have extended Petrini’s idea of slow to a
wide-ranging critique of the cult of speed in the modern world. These writers have endured
criticism, of course, especially from those who see the opportunities to slow down as only
possible because of prosperity provided by the inhuman efficiency of the industrial world.
Despite these critiques, these authors have offered practical advice on how to slow down
individual engagements with the world. Petrini, for example, celebrates local food ways. Honoré
advises that we set aside time to unplug and to savor the pleasures of experience without
interruption or mediation. Absent the distractions of technology, the local environment takes on
greater significance and vividness.
3
Slow archaeology calls upon archaeologists to consider arguments that recognize the
influence of speed on archaeological practice. This paper will not call on archaeologists to
discard their digital tools or reject the remarkable benefits of technology for a romanticized past.
Instead, I will offer a critique of both certain digital practices and, perhaps more importantly, the
way in which these tools are described and promoted in the scholarly discourse. I remain
skeptical that archaeology will benefit from tools that offer greater efficiency, consistency, and
accuracy alone, and my hope is that this skepticism has particular significance at a time when a
new generation of digital tools are entering the field.
Unpacking the implications of our use of digital tools and the adoption of streamlined
practices require some attention to the intersection of scientific and industrial practices in
archaeology. The recent growth of contract, salvage, and rescue archaeology has made the
influence of speed and capital on archaeological work particularly visible. The pressures of
development and the efficient management of heritage as a resource have provided ample reason
for the enthusiastic adoption of digital tools and practices. Among academic archaeologists,
shrinking resources, pressure to “publish or perish,” increasingly intensive field methods, and
expectations of host countries have likewise put pressure on the pace of fieldwork. The goal of
slow archaeology is, on the one hand, to recognize archaeological work and the particular
emphasis on efficiency, economy, and standardization in digital practices within the larger
history of scientific and industrial knowledge production. This chapter also seeks to carve out
space within the proliferating conversation about digital archaeology for practices and tools that
embrace the complexity of archaeological landscapes, trenches, and objects. In this way, slow
archaeology recognizes that the presentation and publication of archaeological tools and
arguments tends to simplify the impact of technologies and the often-messy relationship between
4
evidence and argument. The concern for data as evidence finds common cause with Eric Kansa’s
recent interest in “slow data,” which embraces the dynamic and profoundly human character of
archaeological datasets as an element of added value rather than distracting complexity.
My position as a tenured, academic archaeologist provides a distinct professional context for
slow archaeology. I recognize that my efforts to develop slow archaeology comes from a
position of privilege. I am an academic archaeologist who relies on his research for professional
advancement, but not professional survival. I have tenure, and as a result, I can be more
deliberate in the race against the clock to produce publications. I also have the good fortune to
work on archaeological projects with the personnel, time, and funding that align closely with our
research objectives. These luxuries have allowed us to consider a wide range of archaeological
documentation processes without particular concern for efficiency. We have deployed range of
digital tools and practices from the use of iPads (Caraher, Pettegrew, Fee 2013) and structurefrom-
motion (SfM) 3D imaging (see Olson, this volume) to now standard reliance on differential
GPS units, relational databases, and GIS. This article then is not the frustrated expressions of a
Luddite outsider, but an argument grounded in familiarity with digital field practices.
The Industry of Disciplinary Knowledge Production
B. Latour has argued that in the history of science, there arose a division between nature
which was the object of scientific inquiry, and culture, which provided the tools and language for
understanding the relationship between these observations. This division between nature and
culture encouraged the development of processes that emphasized data collection as distinct from
analysis. Moreover, it also influenced how scholars present the production of knowledge and
5
separated the process of collecting observations from the analyzing and organizing these
observations (Latour 1993; Martin 2013: 69-70). Latour studied practice as a way to critique the
division between nature and culture and argued that science produces facts not through simple
observation, but as a result of a dense network of entities and actions that range from funding
agencies, governments, fellow scientists, institutional priorities and innumerable small decisions
made on the basis of assumptions about how nature works. For Latour, the inseparability of
nature and culture at the level of scientific practice is distinct from the representation of research
in publications. The former embodies a network of relationships between human and nonhuman,
animate and inanimate, institutional and individual, whereas the latter represents the data as
independent realities that support scientific arguments. In archaeology, this distinction manifests
itself in a division between “raw data” in archaeology (Gitelman and Jackson 2013) - often
presented in scientifically structured catalogues - and the narrative or expository historical
arguments. This division has provided the space for recent discussions of digital data collection
strategies that stop short of demonstrating how these changes produce new arguments or
understandings of the past.
The use of technology in archaeology is not new and, in fact, has deep roots in the
complicated intersection of the discipline, science, and industrial practice from the field’s 19thcentury
origins. Heinrich Schliemann, for example, funded his work at Troy and Mycenae
through his former life as an industrialist and brought industrial organization to his excavations.
Moritmer Wheeler and August Pitt-Rivers drew upon both their military backgrounds and
industrial practice by employing relatively unskilled workmen to excavate while leaving the
interpretative responsibilities to there more discerning eye (Lucas 2001, 8). As Bergrenn and
Hodder have noted, the workers were “replaceable tools in the machinery” (Bergrenn and
6
Hodder 2003: 422). Such hierarchical organization of the archaeological workforce persists
today. In CRM practice, “field technicians” represent a subordinate group to the archaeologists
who supervise and interpret the results of excavation for official reports (Lucas 2001, 11-12).
Most academic excavations have clear divisions between the inexperienced excavators and more
experienced trench supervisors. This coincides with the practice of separating the manual work
of excavating from the “more intellectual” work of recording and documenting, although it is
worth noting that many excavations recognize the tremendous value of local workers deeply
familiar with local conditions. In general, the organization of archaeological projects reinforces a
division between data collection and interpretation and analysis.
The division between data collection and its interpretation located practices separated the
work of removing earth, counting objects, and describing contexts from the work of analyzing
and, ultimately, publishing, archaeological conclusions. This made the former susceptible to
efforts that would both increase efficiency and improve the quality of data collected. Nowhere
are these practices more visible than in CRM practices, where streamlined data collection
methods certify that the recording of archaeological information keeps pace with development
and are efficient enough to ensure that the firms involved remain solvent. Various contributors to
the British CRM industry, in particular, have developed streamlined recording sheets (and
attendant practices) that ensure that data is recorded in a standardized way according to best
practices (Pavel 2010: 16-17). As Catalan Pavel has pointed out, the practice of documenting
archaeological sites carefully is closely tied to the official “preservation by record” policies of
the British government. These rest on the assumption that an archaeologist might be able to
reconstruct the site after its destruction from the record collected during the rescue excavation
process.
7
The rise in CRM archaeology has made the links between archaeological practice and the
pressures and pace of capitalism more explicit and has amplified a tendency toward industrial
practices present in an academic context. Academic archaeology developed as a professional
discipline alongside the emergence of industrialized academic disciplines in the modern
university (Menand 2010) as well as emerging museums (Dyson 2006, 133-171). This shared
trajectory reinforced the industrial organization of archaeological knowledge production. In this
context, industrial practice and professional archaeology are inseparable both chronologically
and institutionally. The university developed systematic ways to educate young adults with
courses arranged across disciplines to build key skills, provide professional credentials, and
produce productive contributors to American society (Menand 2010; Novick 1988). While
variation existed across universities, over the course of the late 19th and early 20th century,
many oriented their curriculum toward the challenge of providing credentials for the growing
body of professionals required by industry and our increasingly specialized society. This desire
for specialization found its most extreme manifestation in the logic of the assembly line, which
assigned individuals to perform single, exceedingly limited tasks over and over. Through
coordinating the hyper-specialized actions of dozens of individuals, the assembly line produced a
single product as efficiently as possible. Higher education employed a similar approach to
producing educated individuals by dividing up the process of education among various
specialized experts in particular disciplines.
Historically, these industrial influences on higher education have incurred resistance,
although much of resistance is not articulated as such. Disciplines like history, art history,
literature, anthropology, and archaeology have periodically used the word “craft” to describe
their undertakings (e.g. Frisch 1990 or the English translation of M. Bloch’s classic text: Bloch
8
1964), but these were rarely positioned as a countercurrent to industrial models of education and
knowledge production (Shanks and Maguire 1996; Taylor 1998). Recently there has emerged a
more consistent resistance to the “audit culture” surrounding university education, and this has
pushed cultural anthropologists to emphasized the holistic, embodied, and immersive experience
of fieldwork (Herzfeld 2007). Scholars of art and literature historians have championed the openended
and contemplative process of close reading or the patient, unhurried examination of a
work of art (Roberts 2013). All these approaches to disciplinary knowledge have a few elements
in common. They resist the fragmentation of tasks common to industrial practices and ground
disciplinary knowledge in the willingness to embrace the slow process of experience. As a result,
these disciplines have generally ignored calls for efficiency and embraced practices and
knowledge derived from careful examining, close reading, and contemplation.
Archaeologists have looked beyond contemporary practice to emphasize the roots of their
discipline’s craft practices. Michael Shanks and Matthew Johnson, for example, have explored
the roots of archaeology in 18th-century traditions of historical perambulations, landscape
painting, and literature (Johnson 2007; Shanks 2012). The historical English countryside came
alive not through the systematic treatments by specialist scholars, but through contemplative
encounters mediated through art and literature as much as efforts to describe monuments or
historical landscapes. These pre-industrial approaches to the landscape cast a long shadow across
the discipline and served as a counterweight to the influence grounded in industrial practices.
While the 18th- and 19th- century rural wanderers were members of the economic and social elite
seeking to inscribe their aristocratic vision on a landscape as a counterweight to industrialized
wealth, craft continued to embody non-aristocratic approaches to knowledge as well. Despite the
historical awareness of pre-professional practices in archaeology (and other disciplines), Shanks
9
and Marxist archaeologist Randall Maguire considered the impact of craft to be “latent” in the
field of archaeology and primarily manifest in the creativity of the archaeologist’s work where
“hand, heart, and mind are combined” (Shanks and Maguire 1996).
As Mary Leighton’s recent article (2015) has emphasized, the tension between craft elements
in archaeological practice and the ordered routine of industrial production varies widely across
the discipline. In her important study, she compares Andean archaeological practice to CRM
practices pioneered by the Winchester Research Unit in the U.K. (Pavel 2010: 27-28, 44-45) The
former had largely unskilled, local workmen supervised by a graduate student who maintained
paperwork and was overseen by project directors who coordinated efforts of field teams, the
orderly flow of artifacts, and the collection of completed forms. In the U.K., open-area, singlecontext
excavations placed the excavator at trench side “with both a pen and a trowel” (Leighton
2015: 81) and focused on the production of single-context forms. Both projects concluded with
the creation of Harris Matrices to present the archaeological contexts present in an area. Leighton
pointed out that despite the similarities of the output of these projects, significant variation exists
in archaeological practice. In the Mediterranean, for example, the hybrid system employed by
Corinth Excavations demonstrates how highly-skilled local workers can lead inexperienced
graduate student “supervisors” through the complexities of single-context excavation. In other
words, the systematic organization of archaeological labor occludes a range of trench-side
practices which preserve the “latent” impact of craft.
Process and Practice
10
The tension between practice, archaeological processes, and publication is the space where
slow archaeology and craft meet the industrial demand of efficiency and speed. For archaeology,
stratigraphic excavation embodies certain aspects of industrial practice and modes of
organization by parsing complex situations into more granular entities (McAnany and Hodder
2009; Leighton 2015). The identification and removal of discrete levels and the systematic
arrangement of these strata in relation to one another structures the archaeological record in a
way that allows for chronological and spatial descriptions of past depositional events. The work
of dividing the excavated world into distinct strata paralleled the use of fragmentation as a tool of
efficiency in industrial practice. Working from strata to strata across a trench, stratigraphic
excavation defined the complexity of time and space through distinct slices. Each stratum
received careful documentation in notebooks including textual descriptions, illustration, and
photography (with the spread of affordable photographs) (Bohrer 2011).
Some scholars have recognized Latour’s “black boxing” in the process of stratigraphic
excavation (Latour 1987; Mickel 2015). The widespread use of Harris matrices to reduce
stratigraphic levels into uniform boxes further supports this observation (Harris 1979), and
creates uniform divisions or contexts for artifacts later studied by specialists. These objects often
help to assign either relative or, in best case scenario, absolute dates to each level, to associate a
function with the space, or to describe the event that created it. As archaeology and excavation
has become more complex, it has spawned and relied upon a greater group of specialists to assist
in identifying and analyzing the material present in each stratum. The largest projects now rely
on dozens of specialists who work in parallel with excavators, wheel-barrow drivers, trench
supervisors, area supervisors, field directors, ceramicists, bioarchaeologists, and numismatists, to
produce archaeological knowledge. Both the assumptions surrounding stratigraphic excavation
11
and the specialists who support it encourage the maintenance of industrial discipline to ensure
that fragmented data set that might be re-integrated at a later point. As Leighton points out,
however, the implementation of this kind of industrial order comes at the level of practice. For
her, black boxing defines both the processes of archaeology and the way that the product of these
processes hides variations in practice.
The New Archaeology of the second half of the 20th century contributed to the interest in
processes that fragmented archaeological information recovered during field work. The interest
in quantitative analysis and studies that relied upon the precise plotting of sites across a region or
artifacts within a site required the identification and sometimes isolation of discrete objects
(Lucas 2001: 126-127; Thomas 2004, 76-77). New Archaeologists were confident that collecting
data from the field systematically was the central concern for field work, and the understanding
of this data through hypothesis testing and theory building was a secondary process which often
occurred in a separate place (Witmore 2004). Regional, intensive pedestrian survey adopted the
techniques of New Archaeology to construct palimpsests of overlapping maps produced by a
range of specialists and, ultimately, computer produced algorithms (e.g. Alcock and Cherry
2004; Gillings et al. 2000). The maps produced by rigorous fieldwork and laboratory analysis
allowed archaeologists to contextualize artifact scatters, sites, and settlements on the richly
detailed regional scales. Over the past decade, methodological debates in Mediterranean
archaeology and a growing interest in behavioral archaeology and formation processes have
increased the intensity of artifact collection and the complexity of the resulting maps, but the
basic structure of field practices and analysis remain unchanged (e.g. Bevan and Conolly 2013;
Caraher et al. 2015).
12
The development systematic practices in intensive survey paralleled the spread of Harris
Matrices in excavations. This practice reflected the growing interest in documenting vertical
spatial relationships and depositional contexts in a way that regularized the units of
archaeological interpretation. The tidy character of the Harris Matrices present stratigraphic
deposits in a formal and generalized way that allowed them to be compared over open area,
single context excavations while preserving the autonomy of individual excavators (Leighton
2015). In other words, Harris Matrices represent the product of trench-side interpretation that
form the basis for understanding the archaeological structure of the site.
Digital Tools and Practices
The intersection of science and industrial practices in archaeology produced conditions in
which archaeological research presented standardized procedures linked directly to the
production of consistent and regular results. As Leighton noted, formal descriptions of
archaeological processes obscures messy archaeological practices and complex data sets to
facilitate analysis. It is important to recognize that some normalization of archaeological results
is necessary to communicate complex situations, idiosyncratic environments, and dynamic social
and political relationships present in any archaeological process. Christopher Witmore and others
have identified mediation as a key element in archaeological work (González-Ruibal 2008;
Witmore 2009). At the same time, these processes that archaeologists use to produce consistent
data are under pressure both from within the academy and from the cultural resource
management industry. A new crop of digital tools has entered into this situation with promises to
13
reinforce and accelerate longstanding tendencies in archaeological knowledge making. Slow
archaeology asks how this acceleration has led to transformation of the discipline.
Archaeologists have largely seen the adoption of digital tools as a way to improve efficiency
(Olson et al. 2014; Wallrodt, this volume; Roosevelt et al. 2015; Spigelman et al. this volume,
Wilhelmson and Dell'Unto 2015). By doing things faster without losing accuracy or precision,
archaeological projects can collect more information, typically encoded as bits of data which
allows them to reconstruct archaeological contexts more completely in less time. Digital tools
have reinforced tactics used by archaeologists to standardize their practices and continued trends
in producing discrete bits of data useful for the kinds of studies developed in New Archaeology.
As Pavel has argued, these archaeological methodologies manifest themselves in the slow
replacement of trench diaries or notebooks with detailed forms that became widely used in the
last decades of the 20th century (Pavel 2010). While most forms preserve space for interpretation
and analysis at trench side, the dominant trend has been toward more atomized recording
designed to improve accuracy in the field, to normalize description for comparison or seriation
across a site, and to facilitate quantitative analysis.
Today’s use of iPads or other tablet computers at trench side or in the field reproduce many
aspects of paper forms while enforcing additional regularity in recording. The use of iPads by
Steven Ellis’s PARP project crystalized the potential of tablet computers to streamline trench
side data collection (see Ellis and Poehler this volume; Fee this volume; Pettegrew et al. 2013).
The best designed applications, like those used by Ellis’s and Poehler’s teams at Pompeii and
similar databases described by other authors in this volume include a combination dropdown
menus and open text fields to encourage trench supervisors to be both consistent and detailed
(Motz; Dufton; Spigelman et al. all this volume). Moreover, these databases make it possible to
14
track changes to entries through time allowing project directors to observe how trench
supervisors adjusted their data throughout the excavation process. The data recorded at trench
side eventually becomes part of the larger project database and is made available both on devices
throughout the project and to the project directors. In short, the data collection process becomes
more straightforward, consistent, transparent, and efficient.
In addition to neatly delineated recording forms and their digital versions replacing the more
free form notebooks, 3D “structure-from-motion” photography offers a method to streamline
trench and artifact illustration (Olson and Moss this volume; Olson et al. 2014; Roosevelt at al.
2015). By breaking a trench into a series of individual photographs, we can use software like
AgiSoft photoscan to produce an accurate 3D model of the trench. On a day-to-day basis, it is
possible to use these methods to document individual strata in a trench or at least capture the
spatial arrangement of various important contexts at a much greater speed than traditional trench
illustration. At the end of an excavation season, when time always seems at a premium, my
project on Cyprus - the Pyla-Koutsopetria Archaeological Project - was able to use structurefrom-
motion images that reproduce overhead trench photographs without the inconvenience of
erecting a scaffolding or hiring a lift to provide accurate overhead images of the entire trench.
The time saving possibilities and increases in efficiency are notable and real. At the same time,
by working to automate a key component of archaeological documentation, archaeologists
continue to marginalize practices that involve craft modes of production like illustration or the
skilled work of excavator (Perry 2014). Moreover, the emphasis on the efficiency of these
practices runs the risk of undermining the specialized awareness that these practices have the
potential to encourage (Morgan 2009; 2012; Perry 2014).
15
To achieve these efficiencies, both of standardized recording sheets in paper and digital form
and structure-from-motion photography transform the archaeologist and archaeological
information in similar ways. First, both techniques involve the archaeologist breaking the site
into fragments. For recording sheets, this involves dutifully filling in a series of predetermined
descriptive fields ranging from soil Munsell color to dimensions, elevations, and features. It is
hardly surprising that survey projects which developed directly from the ideas expressed in New
Archaeology relied on forms and digital recording from the start of the famed “second wave”
surveys in Greece (Bintliff, Howard, Snodgrass 1999; Cherry 2003). Structure-from-motion
photographs are likewise fragmented views of the trench that rely on computer algorithms to
reconstruct their proper relationships.
The fragmented, if more comprehensive, records created by digital practices in archaeology
almost always require reassembly after the archaeologist leaves the field. The longstanding focus
on the systematic collection of data in the field has produced a body of information that requires
reassembly according to traditional archaeological practice (Lucas 2001). As the information
collected in the field has become more granular and more digital in character, the tools and
techniques required to reassemble it have become more complex. The archaeologist is both at the
top of a system of excavators, surveyors, and specialists but also interacting with complex
hardware and software applications which range from “basic” Access and Filemaker databases,
to more complex applications like ArcGIS maps and 3D imaging suites, and intermediary
programs that allow for data to move between applications and devices. This software, as well as
the hardware used to collect data at trench side or in the survey unit, function as parts of a larger
digital ecosystem (for the use of the term “ecosystem” in the context of digital archaeology, see
Kansa 2012; Forte et al. 2010). This ecosystem requires qualified personnel and additional levels
16
of vigilance to maintain the system in which these bits of data make sense. Compared to the
relative simplicity of an excavation notebook, which requires almost no particular technology to
read and understand, the modern excavation or survey dataset is a virtually meaningless mass of
encoded data.
Our dependence on technology to reconstruct archaeological contexts becomes even more
acute when dealing with data produced by 3D imaging technologies, for example, which rely on
either bespoke or proprietary software to produce legible results. Even if we accept that the basic
data behind 3D images, such as point clouds, are actually quite simple to decode and understand,
and that it is possible to archive the photographs, point clouds, and even polygons from which a
3D model derives, the process of producing a 3D model and the 3D models itself are often the
distinct product of proprietary software. Moreover, as the contributors to this volume
demonstrate, our ability to produce 3D models has existed for quite some time, but these models
remain difficult to publish outside a few academic publishers, and remain challenging to preserve
in a reproducible way (Reinhard 2014; Opitz 2015). These limitations do not diminish their
potential utility, but reveal one side-effect of fragmenting our archaeological data in an effort to
manipulate it in more efficient (and also more dynamic) ways. Without attention to the larger
digital and social ecosystem in which they function, however, we run the risk of
decontextualizing our archaeological processes.
Just as data collection strategies that privilege a more efficient, but fragmented workflow
have separated the work of excavating or field walking from the work of analysis, so have an
increasing reliance on digital tools - some of which are proprietary and many require specialized
skill to manipulate - complicated the social organization of the interpretative process.
Archaeologists must now approach critically the digital tools that we use and recognize our
17
limited access to the structure of these tools and the technologies and code that makes them
work. While archaeologists have always relied to some extent on tools that they did not entirely
control (after all, who knows how a Marshalltown trowel is really made), digital tools are
particularly fraught because the interplay between proprietary software and hardware across a
digital ecosystem produces a network of subordinate assumptions that exist outside the
archaeologist’s direct control, but nevertheless shape the basic structure of our research.
Toward a Slow Archaeology
Slow archaeology involves the critical appreciation of the accelerated pace that digital tools
have brought to industrial practices in archaeology. New Archaeology fortified the longstanding
industrial influences in archaeology through its emphasis on methodology and adoption of neatly
organized forms which serve to standardize archaeological observation at the point of recording.
While reflexive and ethnographic treatments of archaeological practices have demonstrated that
standardized forms occlude variation in the execution of the well-defined methods (Mickel
2015), outside a few high profile examples (Bergrenn et al. 2015), most recent publications
focusing on digital tools and practices have done little to rectify this disjuncture (e.g. Citation).
As a result, the adoption of digital tools is particularly fraught because they tend to reinforce a
methodological discourse that itself already represents a Latourian “black box.” If methodology
risks occluding the range of actual practice, many digital tools actually celebrate their reliance on
obscured complexity by presenting technology “that just works.”
Slow archaeology also contends that the change in pace promised by digital practices is not
simply the continuation of a trend toward greater efficiency in the field, but a substantive change
18
in how archaeologists realize this efficiency and speed. The tendency of these new tools to
produce “black box” solutions to problems of efficiency reflects the growing pressures on both
academic archaeologists and those in the field of cultural resource management to produce
results at the pace of development and capital. In other words, as digital tools accelerate the pace
of archaeological work, more aspects of archaeological practice become obscured by technology.
In practice, slow archaeology calls for more deliberate approach to archaeological field work
and the adoption of digital technologies. This does not require a rejection of digital tools or new
techniques, but rather an adjustment in how we document the implementation of these tools in
archaeological work. Allison Mickel’s work on notebooks as a place for unstructured and
reflexive recording demonstrates how preserving traditional recording alongside more
standardized forms reproduces much of the same information in synthetic and narrative forms.
While Mickel’s study does not distinguish between digital and analogue practices - a field diary
could be in paper or digital form and more less integrated into a larger digital ecosystem - the
narrative diary nevertheless stands out as distinctly separate from field recording practices
associated exclusively with digital tools (Gordon et al. this volume). In the digital era, formbased
recording of the kind documented by Catalan Pavel operates at the intersection of New
Archaeology and digital practices geared toward efficiency. On the Western Argolid Regional
Project, we asked team leaders to stop recording their detailed forms periodically throughout the
day and to look across the landscape to understand the larger context for their work. Conversely,
David Pettegrew (a team leader on the Eastern Korinthia Archaeological Survey) discovered that
he had to return to the Corinthian landscape for several field seasons after he reassembled the
data collected from the intensive survey to understand the neatly arranged maps in the physical
landscape of the isthmus. A narrative notebook or diary provides the opportunity for synthetic
19
documentation of the fragmented data collected on a form and captures both the integrative
experience of the landscape and recursive decision making that shapes our encounter with
excavated contexts.
The emphasis on digital tools for making archaeological work more efficient also transforms
the character of archaeological practice. In earlier drafts of this paper and elsewhere, I have used
the term deskilling to characterize the change in practices brought about by “black box”
technologies in the field (Caraher 2013). For example, the basic skill of illustrating a trench is a
proficiency that some archaeologists have suggested can be replaced by more efficient 3D
imaging technology. In place of the craft of illustrating, these technologies offer the digital skill
of preparing a 3D image (Roosevelt et al. 2015). The main difference is, however, that in
traditional practice illustrating the trench involves the interpretative representation of
relationships between objects and resolving myriad small relational conflicts between the
features visible in the trench. The goal of producing a dynamic 3D image, in contrast, is to gather
as much information as accurately as possible. While the final illustration almost certainly
obscures the decision making process, it does capture the data points and features that the
archaeologist considers crucial for their conclusions. In other words, illustration is the product of
an explicitly interpretive process and reinforces careful observation and decision-making while
excavating. The removal of the time-consuming illustration process from excavation work does
not necessarily guarantee the deskilling of the excavator, but it certainly transforms a crucial step
in the documentation process from one requiring detailed and careful knowledge of the features
in a trench and conventions of illustration to one requiring the understanding of a digital camera
and software. The former is vital to the archaeological process whereas the latter is not.
20
Finally, slow archaeology, like the slow food movement, shares an emphasis on the local and
suggests that the distributive tendencies of digital practices transform the place of archaeological
knowledge production as well as the methods. To return to the example of 3D imaging,
traditional trench illustrations locate archaeological argument making at the edge of the trowel.
In contrast, the use of a digital camera and software to produce a representation of the trench,
involves the passive collection of images at trench side for later processing and study. The digital
process shifts the illustration of the trench to the lab, computer room, or office and bases the
illustration not on our physical encounter with the relationships visible in the trench, but on the
series of photographs. Intensive pedestrian survey has likewise featured the almost mechanical
collection of highly granular data from the field. This data relies upon remote processing to
produce meaningful artifactual landscapes. There is no question that these remotely-created
landscapes have added significantly to our understanding of the premodern countryside, but, at
the same time, these computer-mediated landscapes risk being divorced from the physical
encounter with the countryside. As field work becomes increasingly associated with data
collection and analysis, the space of interpretation shifts from the field to the office. The
emphasis on place in archaeology intersects with the placelessness of digital efficiency.
Slow archaeology challenges any claim that gains in efficiency through the use of digital
tools is sufficient reason alone to incorporate them into the archaeological workflow. It also
recognizes that even though technological changes in archaeology occur in tandem with changes
in method, practices, and the social organization of archaeological work, technology nevertheless
has independent consequences. As Harvey, Rosa, Virilio and even Petrini have observed, the
accelerating pace of a world saturated with technology has created new categories of experience,
economic structures, and social relationships. The Latourian blackboxes that have proliferated in
21
archaeological research and appeared regularly in archaeological methodology reflect a tendency
toward uncritical occluding of technological processes in archaeological practice. Slow
archaeology argues that the rapid pace of technological change and a critical, reflexive
archaeology requires renewed attention to the place of digital tools in both field practices and
methodology.

4.2. Click Here to Save the Past
Eric C. Kansa
Open Context and UC Berkeley
kansaeric@gmail.com
Introduction
This paper takes a critical look at how the branding, promotion and financing of digital solutions
and services impacts archaeology. Digital data obviously has much promise. It can help us
engage with wider communities, explore new research questions, and create and preserve a
vastly enriched body of archaeological documentation. Digital data also has a certain glamour,
gained in large part through its associations with the burgeoning tech industry. At conferences,
digital initiatives are often marketed like tech startups as solutions to make archaeology faster,
more efficient and cutting-edge, and . The look and feel of archaeological websites owes a great
deal to styles and user interface designs coming from the commercial Web. The quickly growing
field of “digital archaeology” brings freshness and excitement to archaeology.
While I welcome the increasing limelight cast in areas that align with my particular research
interests, I worry about the institutional context that currently surrounds digital data's growing
prominence. In Kathleen Fitzpatrick's (2011) study of the dysfunctions of scholarly monographs
as the sole route to tenure and promotion in many areas of the humanities, she notes how
scholars rarely focus critical reflection on the institutions and tacit rules that govern their own
professions. Just as we need critical focus on why scholars fail to engage with new media, we
also need critical reflection on how new media become part of our profession. If digital
archaeology is to really fulfill its promise and widen participation and opportunities for exploring
the past, we urgently need more reflection on the forces that shape the branding, management,
and financing of digital data in archaeology.
Background
Since reflection in digital archaeology is in short supply, rather than focus specifically on my
work with Open Context (http://opencontext.org), a data publishing service for archaeology, this
essay will explore some of the institutional challenges faced by Open Context in particular and
digital archaeology more generally. The perspectives offered here stem from my experience over
12 years as a dedicated “digital archaeologist,” founding and running a nonprofit endeavor to
promote the dissemination and preservation of archaeological field data. Open Context is now
referenced by the National Science Foundation (NSF) and the National Endowment for the
Humanities (NEH) for data management for archaeology and the digital humanities. Its approach
of “data sharing as publishing” emphasizes collaboration with dedicated editorial and
information specialists to make data more intelligible and usable. Open Context publishes a wide
variety of archaeological data, ranging from survey data to excavation documentation, artifact
descriptions, chemical analyses, and detailed descriptions of bones and other biological remains
found in archaeological contexts.
The range, scale, and diversity of these data require expertise in data modeling and a
commitment to continual development and iterative problem solving. Open Context (Figure 1)
has undergone several upgrades, the most recent in spring of 2015, to keep pace with technology
changes and to leverage best practices in data stewardship. With data preservation through the
University of California (the California Digital Library), Open Context now publishes more than
1.2 million archaeological records from projects worldwide1. This is on a scale comparable to
that of a major museum (for instance, the online collection of the Metropolitan Museum of New
York makes some 407,000 records available). Open Context has made this remarkable
achievement on a much more limited budget than the online collections of major museums.
Grant funding from the William and Flora Hewlett Foundation, the NEH, the Alfred P. Sloan
Foundation, NSF, and others has gone a long way largely because of the AAI’s status as an
independent non-profit organization with an overhead much, much lower than large research
institutions. The AAI and Open Context have also benefited from the growth of the Web and the
“ecosystem” of projects and individuals in similar roles—undertaking innovative work outside of
traditional academic roles. At the same time, our vantage point outside of the tenure track offers
us a different perspective on the academy and its evolution. Those perspectives inform this essay.
Branding and Sustainability in Digital Archaeology
As a relatively new area of specialization, digital archaeology has emerged during a time of
tremendous change in the academy. While we see unfolding technological transformations that
make digital archaeology possible, we also see profound and often disturbing restructuring of
wider economic and political institutions that impact university funding and governance. Simply
put, “neoliberalism” — a loosely associated bag of ideologies that emphasize fiscal austerity and
relentless competition, market transactions, and certain management techniques centered on
metrics and surveillance — now permeates academic institutions (Feller 2008; Kansa 2014).
With the notable exception of the Wikipedia, commercial players dominate much of our
interaction with World Wide Web. Most, if not all, digital archaeology projects must interface
1 Open Context now also benefits from mirror hosting and backups offered by the German Archaeological
Institute (DAI) (see: http://opencontext.dainst.org ). We are now beginning to do software development in
collaboration with the DAI.
with the commercial Web, commercial software and other commercial platforms. Search engine
optimization, marketing of digital archaeology projects on social media, and the embrace of
GitHub for software (and sometimes data) version control all illustrate cross-cutting ties with the
commercial tech sector. Much of the interface design, look and feel, and other aspects
interactivity take their cue from the commercial tech sector. Many digital archaeology websites
have familiar commercial social media icons to facilitate tweets, links to Facebook, etc. Similarly,
many of the “best practices” of digital archaeology, including project management
methodologies (agile, iterative), user centered design, and systems architectures (cloud
computing, RESTful web service design) come directly from approaches developed in
commercial settings.
At the same time, many digital archaeology projects are actually built by people working on
short-term academic computing contracts that may cycle between the academic and commercial
sector (often called “Alt-Acs” or “Alternative Academics”, see Posner 2013; Kansa and Kansa
2015). As such, Alt-Acs, typically working on short-term “soft money,” would be prudent to
look toward the commercial sector as an option of the grant money does not continue to flow.
Fluency in methodologies and skills demanded in the tech sector can offer Alt-Acs more
employment options outside academia. All of these factors come together to make the practice
and outcomes of digital archaeology seem like (low budget) commercial start-ups.
These factors make the character of digital-centered outputs very different from conventional
academic outputs. Branding for conventional research, be they books or articles, works very
differently than digital scholarship. The dominant branding factor for conventional research
outputs centers on the publisher. Certain publishers carry cache and prestige, and that branding
confers prestige to their authors. While branding matters, the connection between a conventional
scholarly work and an individual scholar is more personal and direct. Books and articles are
largely “marketed” on a researcher's CV, clearly identified as a researcher's individual
accomplishments.
The myopic focus of academic reward systems to reward individual accomplishments over
collaborative endeavors has seen wide critique among digital humanists (Fitzpatrick 2011).
Despite these critiques, digital projects usually still fall outside of normal academic recognition
and reward systems. They mainly count for tenure in promotion only indirectly, either as a
success in competitive granting, or as the subject of a conventional publication that sees
recognition and reward. For Alt-Acs that fall outside of the tenure track, recognition comes from
involvement with the project itself. As an alternative to conventional paths toward recognition,
many digital archaeological projects establish their own unique brands. As is the case with
commercial startups, digital humanities brands are expressed with domain names, logos, color
palettes, font choices, etc.
The issue of branding goes far beyond the mere fact that domain names and hosting are
inexpensive. Rather the ubiquity of branding in digital archaeology reflects its peculiar role in
the larger discipline. Although some digital projects aim to disseminate results of a specific
project, many attempt to develop and market tools or services. Thus, many digital projects,
though requiring their own research and development, aim to facilitate the research or outreach
of others. Unlike conventional archaeological scholarship where impact is usually measured
through citation, digital projects tend compete for adoption by wider communities. Branding
recognition works toward that goal.
The need to brand digital projects in large measure reflects an institutional context shaped by
neoliberalism. Digital projects largely have short term grant financing. Generating positive buzz
and recognition can improve chances for future grants. Similarly, in order to sustain digital
projects (see below), many projects have adopted some sort of fee-for-service model (for tDAR
see Kintigh and Altschul 2010, but applicable to Open Context also). Paying for useful services
harkens back to both the market orientation and instrumentalism that help to define neoliberalism.
Knowledge production has to be measurable, and ideally have practical outcomes that can be
monetized. The project focus of digital archaeology similarly emphasizes instrumentalism. Most
work aims to conceptualize, and if funded, build easily marketed “deliverables.” Practitioners
loudly trumpet accomplishments, collaborations, new features, and new funding via social media,
in a way calculated to enhance recognition for a project's brand and eventually drive sales.
Making and marketing practical tools and services is not inherently bad or damaging to
archaeology. After all, we absolutely should celebrate the creation of good tools and services that
help archaeologists achieve research, public outreach, and other goals more effectively. However,
I note the issue of branding to highlight a key concern — namely, is digital archaeology to be
scholarship in its own right or is it to be a niche area for (semi)commercial services? At what
point do marketing and branding imperatives become self-serving goals unto themselves? How
does marketing buzz impact the way we understand and evaluate the scholarship encoded in
digital archeology?
The current framing of “sustainability” centers around organizational and project continuity
made possible by clever business models that market some sort of service for fees. Ideas about
what sustainability means and how we should attain it draws very heavily from neoliberalism.
Grants can be seen as a type of no-interest venture capital loan. They get projects going, but then
it is up to the project to maintain itself. Success means a project (and its associated institution)
has enough continued income to grow via non-grant sources of support.
The clearest example of this vision of sustainability is the online journal repository, JSTOR.
JSTOR started with grant funding from the Andrew W. Mellon Foundation in 1995 and first
launched its online services in 1997. In subsequent years, JSTOR's developers founded Ithaka, a
nonprofit corporation to sustain and manage JSTOR. In many ways, JSTOR represents a singular
success. It offers invaluable services to the scholarly community (that can afford institutional
subscriptions) and now does so without depending on grant-based financing. In 2004, Donald
Waters, a Mellon Foundation program officer, discussed how JSTOR came to be such a
dominant player in digital scholarship, stating that “designing resources to take advantage of the
economies of scale inherent in the digital environment is critical to sustainability” (Waters 2004).
He also lamented the jumbled fragmentation of scholarly resources developed by many small
and one-off projects (Waters 2004).
Is this vision of sustainability always desirable? One danger may be the encouragement of
monopolies or oligarchies where “sustainability” is not just a means to an end (some sort of
public service), but an end unto itself. Dominating a market and crowding out rivals is surely
sustainable. Effectively, because JSTOR is so dominant, commands so much scholarly attention,
and has contractual agreements with so many publishers and libraries2, it would be very difficult
for others to build alternative discovery services, indexes and interfaces to the content now
delivered by JSTOR. One can imagine feminist or African American scholars developing special
discovery, presentation, and text analysis tools as alternative ways of understanding and
exploring the content now in JSTOR. However, I cannot see how such alternative JSTORs could
now be financed, launched and sustained. Thus, while JSTOR offers excellent services, these
services come with opportunity costs.
2 See this informative discussion: http://www.theawl.com/2011/08/was-aaron-swartz-stealing
I need to be clear that JSTOR does not deserve to be considered a villain in the world of
scholarly communications. The (near) monopoly power of some commercial actors, especially
Elseveir and Proquest, does far more to stifle new (and lower cost) alternatives3. Rather, I focus
on JSTOR because it started as a grant funded effort. It succeeded in dominating an important
niche and pioneered a model for other grant funded projects to emulate, and that's the center of
my concern. Another Mellon Foundation funded effort, Digital Antiquity, with its tDAR
repository is working to offer key and absolutely necessary digital preservation services for US
archaeology. Like similar large-scale, long-term projects, Digital Antiquity must develop a
sustainable business model for its services. In doing so, it has some parallels as well as some
important differences with JSTOR. First, while JSTOR relies on institutional subscription-foraccess
income4, Digital Antiquity has largely adopted “open data” policies (see below) and
charges for deposit (like Open Context). tDAR imposes some access restrictions because of the
sensitive nature of some of its data, but is otherwise very open with the content it archives.
Nevertheless, a proven method to gain sustainability would be to work toward the scale and
institutional positioning achieved by JSTOR, a strategy outlined by Waters (2004):
There is as yet on the horizon no real substitute for the vision, discipline, and
commitment needed to build digital collections at a scale and level of generality that
will attract a broad audience of users and have such an impact on scholarship that
their disappearance is not an option.
3 Thanks to Amanda French for highlighting the need to keep perspective with respect to JSTOR, see her
comments: https://github.com/ekansa-pubs/ekansa-pubs.github.io/issues/23
4 As pointed out by Ben Marwick (https://github.com/ekansa-pubs/ekansa-pubs.github.io/issues/25), JSTOR is an
excellent source of open (or at least free-of-charge) data for text mining and other analyses. However, JSTOR
has not embraced open access distribution of articles and mainly maintains fee-for-access services.
JSTOR succeeded in amassing a collection so large and comprehensive that one cannot be an
effective researcher in many fields without JSTOR access. Similarly, if Digital Antiquity
succeeds in developing a comprehensive archive of American archaeology, it will be in a
powerful position to become a similarly essential resource for the discipline.
Waters' emphasis on scale and centrality to explicitly achieve a JSTOR-like “lock-in” has
potential drawbacks. Though it probably does lead to the long-term continuity of a given effort,
it can also result in the crowding out of other programs, thereby inhibiting exploration of other
paths toward innovation and other ways of organizing and representing digital scholarship. For
example, Open Context has taken a very different (but complementary) route to managing and
disseminating archaeological data than tDAR or other repositories. Open Context publishes
digital data as granular Web resources (“one URL per potsherd”, see Figure 2). This facilitates
new opportunities to explore Linked Open Data approaches toward networking archaeological
information. But it also represents something of a challenge to interface with a digital repository,
since most repositories (including tDAR) have different expectations about data organization and
granularity. Nevertheless, we were able to collaborate with the California Digital Library (CDL)
to arrange repository services that could accommodate the granularity of Open Context's
resources. The fact that the CDL could tailor repository services to our specific needs allows us
to explore different approaches to data curation while meeting preservation responsibilities.
Fortunately, recent collaborations between Digital Antiquity, Open Context, and the Digital
Index of North American Archaeology (DINAA) project demonstrate that JSTOR like lock-in is
not inevitable in digital archaeology. The DINAA project, led by Joshua Wells and David G.
Anderson, uses Open Context to publish archaeological site file data curated by state officials
with geospatial and other sensitive information redacted (Wells et al. 2014). In close
collaboration with Adam Brin at Digital Antiquity, we recently cross-referenced the DINAA site
file records with certain metadata records in tDAR using Linked Open Data approaches. Open
data practice adopted by both Open Context and tDAR (see Figures 3 and 4), as well as
technologies such as APIs (Application Program Interfaces) and Linked Open Data that facilitate
rich exchanges of data can promote meaningful collaboration between distributed projects and
collections. These same APIs and Linked Open Data methods would similarly allow completely
new and independent projects to build upon tDAR and Open Context managed resources in
novel ways.
A diversity of perspectives and approaches to digital data should be seen as a “feature” rather
than a “bug”. Archaeological data management issues involve significant theoretical, practical
and technological challenges. These intellectual challenges are as rich and deep as any other
archaeological research question, necessitating a wide variety of perspectives and experiments.
We should not sacrifice community-wide engagement and participation in digital archaeology in
order to make one specific program “sustainable,” however worthy it may be. Thus, part of our
evaluation of digital archaeology projects should focus on how such projects promote and
facilitate new and independent approaches. Developing institutional supports that promote the
future work of others rather than our own parochial branded interests represents a key challenge
for digital archaeology in the 21st century.
Branding Solutionism
Interestingly, branding dynamics in digital archaeology not only reflect the strategies of the
creators and developers of digital projects, they also reflect performance strategies of people in
wider communities. For example, the laptops of many “digital archaeologists” are often covered
with stickers of different brands. One could have a GitHub “octocat” sticker to signal
participation in current best practice of software version control, a Mukurtu logo to signal
awareness and concern for indigenous rights issues in digital media, or a Creative Commons
logo to signal participation in “open knowledge” (see below). Though one need not seriously
engage with indigenous rights or the political economy of intellectual property to use those logos,
the logos can still serve a serious purpose. That is, branding and logos in digital archaeology are
beginning to play a role in performance, self-fashioning and identity construction (see Deuze et
al 2012). The branding of our apps serves as a signal of our commitment to public engagement,
reproducibility, and ethical practice.
This issue of branding and marketing identities within the profession raises a host of questions
about how digital archaeology works as scholarship. As noted, the value of conventional
scholarship is measured through citation impact. How does this impact work in digital
archaeology, given the complexities of how brands are marketed and worn in identity
construction? The actual substance, development history, technical characteristics, or conceptual
foundations of a given platform or project can matter less than its importance as a signal of
identity. After all, the specifics of any program are often opaque and difficult to discern,
especially to a non-expert.
How does marketing-buzz and identity-signaling correlate with recognition of a project as an
important element of archaeological practice? I argue that the issue of branding and identity
construction relates to Evgeny Morozov's (2014:5) critique of “solutionism,” a technocratic
tendency of:
…recasting all complex social situations either as neat problems with definite,
computable solutions or as transparent and self-evident processes that can be easily
optimized—if only the right algorithms are in place!—this quest is likely to have
unexpected consequences that could eventually cause more damage than the
problems they seek to address.
Solutionism is appealing in a neoliberal academic institution, since it suggests that complex and
contested problems can be made tractable with the proper technologies and management
practices. The initial (and now more tempered) enthusiasm for “Massive Open Online Courses”
(MOOCs) to cheaply deliver “educational experiences” that can scale up is illustrative of
solutionism in higher education. While it may seem obvious that education is an intensely social
and complex process, MOOC proponents were highly effective at selling the idea that learning
was a service ripe for cost-cutting disruption through digital media. It turns out that MOOCs are
not simple turn-key solutions. MOOCs can, and occasionally do, broaden access to meaningful
learning, but it takes more than simple delivery of course materials and interaction over the Web.
Making MOOCs work requires institutional commitment and dedication to understand how to
make technologies work within complex social contexts of learning (Earl 2015).
Temptations to celebrate simple branded solutions exist in digital archaeology. In the current
context of cost-cutting and pressure for high-throughput, easily recognized research outputs,
brands can unfortunately signal concern for larger research and engagement goals without
necessarily investing meaningful effort. This is akin to “green-washing,” a tactic where
institutions adopt superficially “green” measures to promote ecological branding, but continue to
follow environmentally destructive practices. A recent episode involving CyArk, a nonprofit
organization that uses 3D laser scanning and other techniques to “preserve”5 cultural heritage
5 The rationale and efficacy of “scanning as preservation” are debatable but out of scope for this paper. In
addition, it is not clear what measures CyArk takes to preserve data beyond file backups, since it does not seem
to use any recognized digital repository platforms or methods, nor does CyArk seem to partner with digital
libraries or archives.
monuments, illustrates the challenge of discerning style from substance. CyArk has a beautifullydesigned
web presence and branded itself under the banner of “open access”6. However, in
attempting to reuse CyArk data, Isenburg (2013) noted that he was blocked by severe legal
restrictions. This prompted accusations of “open washing” (a play on the phrase “green
washing”), where some claimed CyArk presented itself as an open access data provider that
highlighted Creative Commons licenses but actually maintained proprietary control over data in
far less conspicuous fine-print. CyArk has since clarified what it means by “open access” and
explained access and reuse restrictions on the basis of security issues and other sensitivities (see
Barton 2014). While such restrictions may be justified, only a careful read and immersion in
open access licensing debates (see Rocks-Macqueen 2013; Costa et al. 2012) would let one
understand that CyArk is not open access in the sense of the Wikipedia, Public Library of
Science, tDAR, Open Context, or other efforts. Nevertheless, a Google Search of recent press
coverage7, CyArk still clearly leverages “open access” branding in public promotion.
The fog of marketing and brand signaling to promote financial sustainability in digital heritage
can complicate ethical practice, even for a project like Mukurtu, designed to empower
communities to manage, share and preserve their digital cultural heritage within their own ethical,
cultural and social parameters and protocols8. Mukurtu plays a much needed and essential
complimentary role in this space. Unfortunately, it faces the same pressures and dilemmas felt by
other projects. Branding can collapse complex theoretical, policy and ethical issues into
simplistic and caricatured signaling. An extreme example could read, “Facing the complex
6 See the Internet Archive preserved webpage from 2012
(https://web.archive.org/web/20121011125856/http://archive.cyark.org/about). After the Isenburg 2013 blog
post, CyArk clarified policies on data restrictions (claiming such restrictions are passed on from site owners),
see: http://www.cyark.org/data-use-policy
7 See a Google News search for the keywords: CyArk and "open access", see:
https://www.google.com/search?q=cyark+%22open+access%22&tbm=nws
8 See: http://mukurtu.org/project/differential-access-for-the-ethical-stewardship-of-cultural-and-digital-heritageapril-
28-2015/
negotiations and ethical challenges of working with a community subjected to 500 years of
colonialism? There's a hosted solution and mobile app for that!”9. We need avoid the tendency of
branding that drifts toward glib solutionism and risks trivializing issues like cultural
appropriation. Similarly, the sustainability imperative to monetize digital archaeology can further
undermine the point of these efforts. For instance, because digital projects typically lack access
to long-term funding, they need to bring in sales. Mukurtu, as a hosted solution
(http://mukurtu.net), risks perverse incentives to achieve JSTOR-like market dominance over
long-term management of sensitive traditional cultural expressions “as a service”. While the
Murkutu team launched this hosted service in response to the needs of their partners, this
approach nevertheless raises difficult issues in governance and liability, especially since it brands
itself as a long-term “safe keeping place”10. The political economy of system architectures and
associated business models, including the power and dependency issues arguably inherent with
"software as a service", are rarely discussed in digital archives. But these issues are of key
importance in the case of Mukurtu, given its emphasis on working with communities struggling
against colonialism.
Beyond Mukurtu.net, Kim Christen has taken steps to continually maintain the open source code
base for MukurtuCMS at the Center for Digital Scholarship at Washington State University. This
long term support can promote more ethically optimal approaches as the code can deployed,
modified and managed independently and thus more clearly help empower indigenous
communities. However, realizing these outcomes requires more generalized technical
9 While drafting this paper, the exact phrase "there's an app for that", appeared in the press relating to a Mukurtu
deployment. See: https://www.adn.com/article/20151031/looking-preserve-native-culture-theres-app
10 The promise of safe-keeping forever comes from the Center for Digital Archaeology (CoDA) hosted service,
Mukurtu.net. As is the case with CyArk, I cannot find any clear documentation that specifies digital
preservation processes for Mukurtu.net nor can I find reference to partnerships with digital libraries and
repositories.
capabilities and skills, the cultivation of which requires larger and longer-term investments
directly to indigenous communities themselves, not necessarily the Mukurtu development team.
In some cases, these communities may determine they need to sometimes prioritize systems
other than Mukurtu. This is not to say the Mukurtu development team does not deserve financial
support. Of course it does. But their livelihoods should be less dependent on pushing a particular
suite of software or services. I raise this issue to highlight how scarce funding creates real
pressures and tradeoffs. The fight for money carries marketing imperatives to push one's own
branded solutions in order to win grants, generate buzz, collect service fees, and keep the servers
running. We need to articulate and explore these pressures so as to better understand how to
align the interests of Mukurtu and other digital humanities projects, with the publics they serve.
Open Context, the (branded!) system I manage, faces similar dilemmas. It seeks to broaden
participation to the research process but has to charge for its publishing services, and those
charges can exclude less-advantaged researchers (such as independent scholars and graduate
students) that lack institutional or grant support. I also face pressures to “oversell” Open Context
as “the answer” to hugely challenging semantic, technical and interoperability imperatives. Of
course Open Context cannot solve all of archaeology's information challenges. Mukurtu is
obviously a much better platform for community control and expression of their own materials,
while tDAR is a good platform for general purpose data preservation needs. Open Context serves
different needs and only makes sense as a complimentary part of a much larger landscape. But
who will finance the vast diversity of needs and niches in that landscape? Thus, digital
archaeology, even when it promotes laudable goals like indigenous rights or responsible digital
curation, faces strong commodification and solutionism pressures. If digital platforms are to
improve archaeological practice, they need to be parts of a much larger programs and
commitments to quality and ethics. Reaching these more meaningful goals requires more
understanding of the trade-offs and costs of grants with short budget cycles and institutions that
seem concerned only with cutting costs, generating buzz, and maximizing quantified research
efficiencies.
Moving beyond Solutionism
Most discussion of data management presumes and reinforces a normative institutional status
quo for the organization and conduct of research. Research data management typically focuses
on cost-cutting —“Doing More with Less” (Whyte and Tedds 2011)— by reducing waste (lost
data) and increasing efficiencies (interoperability). However, institutionalizing data management
only in terms of optimizing the business as usual status quo (but now with saving data!) sidesteps
important challenges. Research data management raises important questions about
intellectual property, evaluation, reproducibility, and quality that go far beyond concerns over
costs, efficiencies, and measurements of impact. Indeed, as discussed below, treating data as yet
another research product needing to be managed and measured undermines both intellectual
freedom and the ethical conduct of research.
As noted above, Open Context has adopted a model of “data sharing as publication.” In
recognition of the complexities of intellectual property, stakeholder engagement, and the
semantic and quality challenges inherent in archaeology, we made the explicit choice to explore
a model where data editors work in collaboration with data creators to share more meaningful
and intelligible data. Open Context's approach has helped researchers share, integrate, and
analyze datasets at a large scale, leading to significant research outcomes (Kansa et al 2014;
Arbuckle et al 2014).
A key issue with Open Context, however, is that its approach requires human collaborative effort
to drive editorial processes. Editing and integrating data require costly staffing and time
commitments that do not readily scale, leading some to call it a “boutique data publisher” (see
Kratz and Strasser 2014). Conventional publishing finances editorial and other productions costs
through subscriptions and sales predicated on commoditizing the intellectual property of the
copyright-protected content. However, Open Context very deliberately employs open access and
open data publishing models to avoid commoditizing content. In response to heavy lobbying by
the media industry (including large scholarly publishers), Congress (and other legislative bodies
outside the US) have enacted increasingly far reaching and draconian laws to protect business
models based on commoditized intellectual property. These laws not only apply to entertainment,
but also to scholarly communications. The recent tragic case of Aaron Swartz, an Internet activist
who took his own life after the collapse of plea-bargain negotiations with federal prosecutors,
illustrates the legal risks associated with commoditized intellectual property11.
The Swartz example shows how a complex thicket of contractual agreements and intellectual
property laws enforced by surveillance and the threat of draconian punishment underpin
normative academic publishing (Kansa et al 2013). Reform efforts in scholarly communications
have largely embraced the banner of “openness.” The term “open” has assumed a special kind of
valence in relation to digital technologies, especially in networking and communications. “Open”
usually means legal and practical guarantees for inspection, reuse, and adaptation of a piece of
content or a technology. Thus, the term “open” stands in opposition to “closed” or “proprietary,”
which imply legal and other restrictions that require negotiating specific permissions or licenses,
usually for a fee, for even limited kinds of access and reuse. The varieties of “open” relevant to
11 Swartz faced between 30 to 50 years of federal prison for alleged mass-downloads of papers from JSTOR. In
contrast, he would have faced 20 years of prison for human-trafficking (slavery), see:
http://www.propublica.org/article/hacktivism-civil-disobedience-or-cyber-crime
researchers include open standards, open formats, open source software, open access
publications, and open data. Integrating all of these forms of openness together, especially in the
context of “transparent” workflows, starts to approach ideals of “open” or “reproducible” science
(Lake 2012; Marwick 2014). To some (Stodden 2009), openly exposing the process of research
represents an intrinsic good, and an ideal of ethical practice and scientific professionalism.
Thus, while openness sometimes means access and permissive intellectual property frameworks,
in the research context, it increasingly means moving the knowledge creation process to more
public forums that can, in principle, support wider engagement with more communities (Beale
and Beale 2012). As I discuss below, emphasis on the research process, as opposed to neatly
packaged outcomes (peer-reviewed papers or even archived datasets), has the potential to help
digital archaeology move beyond solutionism.
Fungible Data and its Discontents
Placing more value on the process of knowledge creation can help turn back many of the worst
dysfunctions of neoliberalism in today's research institutions. Unfortunately, the language we
currently use to discuss digital data suggests that data is mainly a management or preservation
problem. After all, two agencies of the United States government, the NSF and the NEH, require
data management plans for grant funded archaeological research. This language can lead some to
consider data to be mainly a matter for bureaucratic compliance, not intellectual engagement.
Similarly, many discussions about data management frequently emphasize the central
importance of standards. Common information standards help facilitate data discovery,
interoperability and integration. Standards make use of data at large scales efficient. With
common standards can data open new research opportunities that require large scale data
analysis. However, one may also see the imposition of standards as exactly that: an imposition.
Common standards reflect a certain (and potentially contestable) set of perspectives, assumptions
and goals. Requiring the use of certain standards means requiring a certain agenda. Successfully
imposing standards that prioritize certain kinds of questions and approaches may open new
opportunities for easier, large-scale data analysis, while at the same time curtailing researcher
autonomy to organize and describe materials in new ways. Interoperability standards may
marginalize “artisanal” or “craft” (Shanks and McQuire 1996) research practices in favor of
practices that lead to the “mass-production” of interchangeable, standardized, and fungible
outputs (see also Limp 2011:278). If interoperability and efficiency become our discipline's key
concern with respect to data, we should expect pervasive and sometimes unwelcome impacts to
the practice of archaeology.
One can make similar arguments about copyright licensing and interoperability. Open science
and open data advocates note standardized liberal copyright licensing makes interoperability
easier. Combining different datasets together represents a fundamental research need in using
data. Ambiguous or incompatible licenses and access controls can complicate or preclude this
form of reuse. Therefore, open data advocates typically promote free access and attribution only
licensing (i.e. the Creative Commons Attribution license) or “entanglement-free” public domain
dedications (Creative Commons Zero)(see Volmer 2013; Costa et al. 2012).
While valuable in many circumstances, open data licensing does not represent an ethical ideal for
all cases. Ten years ago, several colleagues and I highlighted how Creative Commons licenses
reflect ethical positions and norms that are not universally applicable, particularly in contexts of
colonialism and cultural appropriation (Kansa et al 2005; Kansa 2009). Similarly, Kim
Christen’s critiques of open access motivated her to develop the Mukurtu platform. Christen
considers open access as tending toward arbitrary technocratic colonialism, at least with respect
to indigenous rights issues (Christen 2009, 2012). While I strongly agree with the vision of more
ethical practice that Chisten very articulately describes, I disagree with her characterization of
"openness" as a root problem. In my experience12, open data advocacy is not nearly so uniformly
ideological and indifferent to social context as Christen suggests. Instead, theoretical and policy
debates about “openness” can cross-fertilize debates about cultural appropriation. For instance,
our 2005 paper discussed Creative Commons-inspired “some rights reserved” models to meet a
wider range of needs for traditional cultural expressions. The paper had a large impact and, as
noted by Allison Fish (2014), Christen and colleagues implemented similar licensing and
labeling ideas with their “Local Contexts” project (Christens 2015)13. In addition, over the past
several years, representatives from Open Context and other digital practitioners have debated
cultural appropriation issues and policy concerns. We did so with iCommons (a former branch of
Creative Commons)14, the Intellectual Property in Cultural Heritage (IPinCH) project15, scholarly
debates about “open archaeology” (Kansa 2012; Lake 2012; Morgan and Eve 2012), ethics
policies for the American Library Association (Christen herself participated in this)16, and policy
recommendations for government agencies17. Moreover, Michigan State University’s MATRIX
Institute adopts different intellectual property frameworks into the practice of its collaborations.
12 I obviously have a very different set of experiences and interactions that framed my perspectives here. There are
many different issues, communities, and actors involved in this space, and my conversations about ethically
situating openness seem to have taken a different tone than what Christen describes in her 2012 publication. So
it maybe these different kinds of interactions led to very different conclusions about open advocacy.
13 N.B. Fish recognized the similarities in these approaches; however (not to sound crabby) none of the scholarly
papers about “Local Contexts” actually cite Kansa et al. 2005, a publication that led to my participation in
fruitful meetings, panel discussions, and presentations about these topics with Christen and others.
14 See example blog post and discussion hosted by iCommons:
http://web.archive.org/web/20071125100852/http://beta.icommons.org/articles/finding-common-ground-in-thedigital-
commons
15 See IPinCH reserch team (see: http://www.sfu.ca/ipinch/about/ipinch-people/research-team), also policy
outcomes for Open Context (http://opencontext.org/about/intellectual-property).
16 See the American Library Associations discussion of "traditional cultural expressions": http://wo.ala.org/tce/faq/
17 See Sarah Kansa's (Open Context's Editor) policy recommendations submitted to the White House Office of
Science and Technology Policy (OSTP) on proposed frameworks for government sponsored research data:
http://sites.nationalacademies.org/cs/groups/dbassesite/documents/webpage/dbasse_083132.pdf#page=20
While some MATRIX projects adopt open models18, depending on context, others adopt stricter
safeguards and protections for digital content19.
Public debate about mass-surveillance, online privacy, open access, open government, race and
gender issues in social media, and more highlight the complexity of current information
empowerment issues (Wells 2014:28). Rather than blindly asserting that all “information must be
free” (sic Christen 2009, 2012), even (non-anthropologically informed) advocates for openness
often protest against ubiquitous data collecting and surveillance by government agencies and
corporations. For instance, the Electronic Frontier Foundation seeks less severe copyright
restrictions and penalties20 and greater openness in science21 and government22, while at the same
time promoting civil liberties protections through public use of strong cryptography23 and
communication networks free from corporate or government surveillance24. If one recognizes the
central importance of power relations in information management, one can support both open
data and privacy safeguards and other protections, depending on the context.
I agree with Christen (2012) that openness is not some sort of inevitable end-stage of
technological progress (see also Kansa 2009). Rather, openness reflects choices motivated by
ideologies, ethics, practicalities, and other factors, especially how people navigate identity and
power relations. If openness is to make meaningful positive contributions to the practice of
archaeology, it needs to be situated within engaged research processes. Informed by
anthropology and recent scholarship on privacy (e.g. Nissenbaum 2004), we should expect
18 See the “Digital Archaeology Institute” ("ethic of openness") led by Ethan Watrall and Lynne Goldstein:
http://digitalarchaeology.msu.edu/about/
19 See an example collection with “all rights reserved” copyright: http://aodl.org/islamicpluralism/
20 See an example:https://www.eff.org/wp/collateral-damages-why-congress-needs-fix-copyright-laws-civilpenalties
and especially: https://www.eff.org/issues/tpp
21 See an example: https://www.eff.org/document/student-activism-open-access
22 See an example: https://www.eff.org/deeplinks/2009/03/foia
23 See an example: https://www.eff.org/encrypt-the-web
24 See an example: https://www.eff.org/wp/who-has-your-back-2014-protecting-your-data-government-requests
privacy, security, and cultural mores about information to vary across different historical and
cultural contexts and social situations (Chander and Sunder 2004; Kansa et al 2005; Hollowell
and Nicholas 2008). Deep understanding of culture, history, and social context (not to mention a
willingness to listen, learn and take "no" for an answer) are required to negotiate issues about
what information needs to be considered private, sensitive, sacred, or damaging if released and
even what information may need to be shared with urgency through certain channels.
Building these deep understandings necessarily requires the kinds of wider engagement and
partnerships promoted by “community archaeology.” This is the approach, explicitly advocated
in Open Context's intellectual property policies25. These quiet and behind-the-scenes approaches
also underlie the core value of Mukurtu's collaborative work. The same holds true for the
decades long partnerships developed between MATRIX and heritage institutions in West Africa,
or the years invested in partnership between First Nation communities and museums with the
Reciprocal Research Network (https://www.rrncommunity.org/). While exemplary, sadly, such
deep and long term investments in engagement are the exceptions and not the norms. Most
researchers, including archaeologists, face tremendous pressures to “publish or perish” via
venues that have business models explicitly centered on commercial appropriation. Open data
and open science advocacy still lies at the margins of scientific practice and research norms. By
far, most money and effort invested in scholarly communications flows into channels of
commercial appropriation (conventional journals) rather than open data systems or noncommercial
archives with privacy safeguards26. In a context of cut-throat job competition, many
25 See: http://opencontext.org/about/intellectual-property
26 The 5 largest University of California campuses spend more than $90 million annually on commercial
acquisitions and subscriptions in 2013-14 (see: http://arlstatistics.org/analytics). In contrast, during the same
period the CDL allocated only about $3.5 million on digital repository services of the type supporting open
access, open data, and protected research data (see:
http://www.cdlib.org/about/docs/CDLAnnualReport_2013_2014.pdf).
archaeologists feel they cannot invest the great effort needed to make their research processes
more open for wider engagement.
Thus, rather than seeing the main threats to ethical research practice in open access or open data
advocacy (Christen 2012), I see pervasive academic Taylorism as a far greater concern. The
bureaucracies that govern research largely see value only in productivity and impact. Academic
institutions ignore or even punish effort invested in more thoughtful and ethical practice when
only a few types of research outcomes “count” in job performance metrics. Indeed, use of
metrics to evaluate scholarship is simple and easy to administer, since it requires no deep insight
in the context and process behind that scholarship. These neoliberal practices are corrosive to
ethics, regardless if the outcomes are open or closed. The thought and effort required for
meaningful and ethical data curation is largely invisible and unrewarded by most research
institutions. Thus, we should avoid caricatures where different digital humanities brands signal
false dichotomies in prioritizing either open data or the self-determination rights of local and
indigenous communities. Instead, we need institutions that encourage more thoughtful and
ethical day-to-day practices so that researchers have the time and intellectual freedom to navigate
complex realities and trade-offs27.
Open data and reproducible research advocacy has raised important questions about relationships
between commercial appropriation, academic reward systems, and research conduct (Kansa
2014a; 2014b). Rather than celebrating “big data” of a type and scale valued and (factory)
farmed largely through corporate and government surveillance, we should highlight the value of
small and properly contextualized data. Our community needs institutional supports that offer
27 Christen (2012) argues for exactly such culturally aware mindfulness. Again, my main focus of disagreement
with her centers not on her vision for better ethical practice (where I absolutely agree); instead, I have a different
diagnosis of the root problems in that I think neoliberal institutions and reward systems cause far more harm
than advocacy for research "openness".
more space for thoughtful digital curation, or “slow data.” The most important value of research
data does not center on its scale, efficient collection, or even efficient interoperability. Rather, a
slow data approach can highlight how data collection, management, and dissemination practices
need to be considered as integral to the larger ethical and professional conduct of research.
Conclusions
The idea of “slow data” introduced above owes much to Bill Caraher's notion of “slow
archaeology” (Caraher 2013; this volume). Slow archaeology captures the notion that we as a
professional community should emphasize excellence in the research process, including taking
time for thoughtful consideration, not simply high-throughput and efficient production of
tangible research outcomes. Slow data is basically the digitized aspects of slow archaeology.
In the case of Open Context, we emphasize that making sense of aggregated data requires
dedicated professionalism and thoughtful effort (Kansa et al. 2014). Minimal efforts to comply
with grant data management requirements by depositing messy and undocumented spreadsheets
into a repository may not be sufficient to enable future reuse. Since such data curation is integral
to the process of research, we need more policy emphasis on recognizing and rewarding the
research process as a whole (see also Dallas 2015; Huggett 2015). The continued domination of
fast-paced “publish or perish” expectations will perpetuate perverse incentives to badly curate
data and to ignore the ethical context of those data.
Slow archaeology can help us articulate more humane and insightful approaches to the
“datafication” of archaeology. Simply adding digital technologies, platforms and services to a
disciplinary context of zero-sum competition and dwindling short-term finances will not promote
ethical practice or more nuanced understandings of the past. Digital archaeology currently has a
growing array of branded projects, many struggling with short-term financing, and all
desperately competing for attention and market share. In the name of economies of scale and
narrowly defined notions of sustainability, this could drive centralization and lock-in, making it
much harder for new ideas and approaches to see experimentation.
It does not have to be like this. We can and should advocate for institutional and financial
mechanisms that are more long-term and offer more opportunity for reflection. Our memory
institutions, namely libraries and museums, may offer some of the best organizational templates
to sustain more reflective digital efforts. Though now also struggling with fiscal austerity and
neoliberalism, in many cases such organizations have provided invaluable public services for
decades. Many of us participate in digital archaeology because we were dissatisfied with the
status quo of conventional archaeology. Now that our area of practice has finally achieved some
recognition, it is time to work toward a better institutional foundation to sustain our efforts in a
manner that promotes and does not subvert our ethics and goals.
Acknowledgments
While this paper benefited from the tremendous generosity and review of many colleagues,
needless to say, any I am solely responsible for any errors, omissions, or other problems with
text. First of all, I want to thank Sarah Whitcher Kansa for her tireless edits, frank discussions,
and her collaboration in crafting the programs and ideas presented in this paper. Also, in an
experiment in “open peer-review”, I posted a draft of this paper on GitHub and made revisions
documented in its version control system. I am grateful for the thoughtful public reviews and
comments made by Dagmar Riedel, Amanda French, Raymond Yee, and Ben Marwick. I also
received private comments via the “back-channel” of email. While I'm keeping the identity of
these people in confidence (because they chose to respond via a more private channel), I am also
indebted for their helpful comments and suggestions. I am also grateful for the insightful
comments and guidance from the anonymous peer-reviewers organized by this volume's
dedicated and highly effective editorial team. Through these various channels, I received thought
provoking and varied ideas about how to improve this paper, and I could only incorporate some
of these suggestions into this current paper. Future publications will more fully address the
feedback so generously offered by colleague who responded to this contribution. And finally, I
am grateful for the financial support of the German Archaeological Institute, the Harvard Center
for Hellenic Studies and the National Endowment for the Humanities (grants #HK-50037 and
#PR-234235).
